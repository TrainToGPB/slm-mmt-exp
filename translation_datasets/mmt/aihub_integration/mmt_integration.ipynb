{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/ubuntu/sehyeong/tmax-enko-mt/translation_datasets/mmt/aihub_integration/integrated_subsets'\n",
    "data_nums = [127, 128, 129, 546, 71262, 71263, 71411, 71493, 71496, 71498, 71524, 71591, 71593]\n",
    "train_suffix, eval_suffix = 'train', 'validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ja = {'ko': [], 'ja': [], 'source': []}\n",
    "df_zh = {'ko': [], 'zh': [], 'source': []}\n",
    "# df_ja, df_zh = pd.DataFrame(df_ja), pd.DataFrame(df_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_eval_df(data_num):\n",
    "    root_dir = '/home/ubuntu/sehyeong/tmax-enko-mt/translation_datasets/mmt/aihub_integration/integrated_subsets'\n",
    "    train_path = os.path.join(root_dir, f'train_{data_num}.csv')\n",
    "    eval_path = os.path.join(root_dir, f'validation_{data_num}.csv')\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    eval_df = pd.read_csv(eval_path)\n",
    "    return train_df, eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>관리번호</th>\n",
       "      <th>분야</th>\n",
       "      <th>한국어</th>\n",
       "      <th>일본어</th>\n",
       "      <th>한국어_어절수</th>\n",
       "      <th>일본어_글자수</th>\n",
       "      <th>길이_분류</th>\n",
       "      <th>출처</th>\n",
       "      <th>수행기관</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KO-JA-2020-PATE-000501</td>\n",
       "      <td>특허/기술</td>\n",
       "      <td>본 고안의 목적은 고정력 스프링에 의해 파손이 발생하지 않는 보강된 인너도어 샤프트...</td>\n",
       "      <td>本考案の目的は、固定力スプリングによる破損が発生しない補強されたインナードアシャフトを提供す...</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>http://kpat.kipris.or.kr/kpat/biblioa.do?metho...</td>\n",
       "      <td>플리토</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KO-JA-2020-PATE-000502</td>\n",
       "      <td>특허/기술</td>\n",
       "      <td>본 발명은 컴팩트한 구성에 의해 부품의 펀칭과 흡착이송이 가능하도록 구비되어 제조공...</td>\n",
       "      <td>本発明は、コンパクトな構成により部品のパンチングと吸着移送ができるように具備され、製造工程上...</td>\n",
       "      <td>22</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>http://kpat.kipris.or.kr/kpat/biblioa.do?metho...</td>\n",
       "      <td>플리토</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KO-JA-2020-PATE-000503</td>\n",
       "      <td>특허/기술</td>\n",
       "      <td>본 발명은 휴대단말기용 메탈케이스에 관한 것으로서, 특히 금속으로 이루어진 휴대단말...</td>\n",
       "      <td>本発明は、携帯端末機用メタルケースの製造方法に関するもので、特に金属からなる携帯端末機のケー...</td>\n",
       "      <td>25</td>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "      <td>http://kpat.kipris.or.kr/kpat/biblioa.do?metho...</td>\n",
       "      <td>플리토</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KO-JA-2020-PATE-000504</td>\n",
       "      <td>특허/기술</td>\n",
       "      <td>그리고 상기 인덕턴스의 등가 저항값이 변화됨에 따라 인덕턴스의 통하여 흐르는 전류가...</td>\n",
       "      <td>そして、上記のインダクタンスの等価抵抗値が変化することによって、インダクタンスを通じて流れる...</td>\n",
       "      <td>20</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>http://kpat.kipris.or.kr/kpat/biblioa.do?metho...</td>\n",
       "      <td>플리토</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KO-JA-2020-PATE-000505</td>\n",
       "      <td>특허/기술</td>\n",
       "      <td>본 고안은 인쇄회로기판의 착탈 고정 장치에 관한 것이다.</td>\n",
       "      <td>本考案は、印刷回路基板の着脱固定装置に関するものだ。</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>http://kpat.kipris.or.kr/kpat/biblioa.do?metho...</td>\n",
       "      <td>플리토</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     관리번호     분야  \\\n",
       "0  KO-JA-2020-PATE-000501  특허/기술   \n",
       "1  KO-JA-2020-PATE-000502  특허/기술   \n",
       "2  KO-JA-2020-PATE-000503  특허/기술   \n",
       "3  KO-JA-2020-PATE-000504  특허/기술   \n",
       "4  KO-JA-2020-PATE-000505  특허/기술   \n",
       "\n",
       "                                                 한국어  \\\n",
       "0  본 고안의 목적은 고정력 스프링에 의해 파손이 발생하지 않는 보강된 인너도어 샤프트...   \n",
       "1  본 발명은 컴팩트한 구성에 의해 부품의 펀칭과 흡착이송이 가능하도록 구비되어 제조공...   \n",
       "2  본 발명은 휴대단말기용 메탈케이스에 관한 것으로서, 특히 금속으로 이루어진 휴대단말...   \n",
       "3  그리고 상기 인덕턴스의 등가 저항값이 변화됨에 따라 인덕턴스의 통하여 흐르는 전류가...   \n",
       "4                    본 고안은 인쇄회로기판의 착탈 고정 장치에 관한 것이다.   \n",
       "\n",
       "                                                 일본어  한국어_어절수  일본어_글자수  길이_분류  \\\n",
       "0  本考案の目的は、固定力スプリングによる破損が発生しない補強されたインナードアシャフトを提供す...       14       50      2   \n",
       "1  本発明は、コンパクトな構成により部品のパンチングと吸着移送ができるように具備され、製造工程上...       22       87      4   \n",
       "2  本発明は、携帯端末機用メタルケースの製造方法に関するもので、特に金属からなる携帯端末機のケー...       25       95      5   \n",
       "3  そして、上記のインダクタンスの等価抵抗値が変化することによって、インダクタンスを通じて流れる...       20       91      4   \n",
       "4                         本考案は、印刷回路基板の着脱固定装置に関するものだ。        8       24      1   \n",
       "\n",
       "                                                  출처 수행기관  \n",
       "0  http://kpat.kipris.or.kr/kpat/biblioa.do?metho...  플리토  \n",
       "1  http://kpat.kipris.or.kr/kpat/biblioa.do?metho...  플리토  \n",
       "2  http://kpat.kipris.or.kr/kpat/biblioa.do?metho...  플리토  \n",
       "3  http://kpat.kipris.or.kr/kpat/biblioa.do?metho...  플리토  \n",
       "4  http://kpat.kipris.or.kr/kpat/biblioa.do?metho...  플리토  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_127_train, df_127_eval = get_train_eval_df(127)\n",
    "display(df_127_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_data(df_old, df_new, tgt_lang, df_new_ko_col, df_new_tgt_col, source_num):\n",
    "    len_old = len(df_old['ko'])\n",
    "    df_old['ko'] += df_new[df_new_ko_col].tolist()\n",
    "    df_old[tgt_lang] += df_new[df_new_tgt_col].tolist()\n",
    "    df_old['source'] += [f'aihub-{source_num}'] * len(df_new)\n",
    "    len_new = len(df_old['ko'])\n",
    "    print(f'Added {len_new - len_old} new data from aihub-{source_num}: {len_old} -> {len_new}')\n",
    "    return df_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1200000 new data from aihub-127: 0 -> 1200000\n"
     ]
    }
   ],
   "source": [
    "df_ja = add_new_data(df_ja, df_127_train, 'ja', '한국어', '일본어', 127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 150000 new data from aihub-127: 1200000 -> 1350000\n"
     ]
    }
   ],
   "source": [
    "df_ja = add_new_data(df_ja, df_127_eval, 'ja', '한국어', '일본어', 127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>관리번호</th>\n",
       "      <th>분야</th>\n",
       "      <th>한국어</th>\n",
       "      <th>중국어</th>\n",
       "      <th>한국어_어절수</th>\n",
       "      <th>중국어_글자수</th>\n",
       "      <th>길이_분류</th>\n",
       "      <th>출처</th>\n",
       "      <th>수행기관</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KO-ZH-2020-PATE-000001</td>\n",
       "      <td>특허/기술</td>\n",
       "      <td>본 발명은 플러그를 통해 공급되는 주전원의 주파수 특성을 검출하여 주파수의 제로전위...</td>\n",
       "      <td>本发明可以检测通过插头供应的主电源的频率特性,并为使从接近该频率零电位的上升电位连接到继电器...</td>\n",
       "      <td>23</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>http://kpat.kipris.or.kr/kpat/biblioa.do?metho...</td>\n",
       "      <td>온아시아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KO-ZH-2020-PATE-000002</td>\n",
       "      <td>특허/기술</td>\n",
       "      <td>본 발명은 셀룰라폰에 관한 것으로, 셀룰라폰의 이동으로 소정시간이상 서어비스 지역을...</td>\n",
       "      <td>本发明是关于蜂窝电话的发明,当由于手机的移动而离开服务区域超过预定时间时自动关闭电源,并以预...</td>\n",
       "      <td>25</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>http://kpat.kipris.or.kr/kpat/biblioa.do?metho...</td>\n",
       "      <td>온아시아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KO-ZH-2020-PATE-000003</td>\n",
       "      <td>특허/기술</td>\n",
       "      <td>또한, 셀 멀티 카피 기능을 활용하기 위한 자원 관리를 수행하지 않기 때문에 하나의...</td>\n",
       "      <td>另外,因为不执行利用单元多功能复制的资源管理,所以存在无法向多个用户提供同一个音调的缺点。</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>http://kpat.kipris.or.kr/kpat/biblioa.do?metho...</td>\n",
       "      <td>온아시아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KO-ZH-2020-PATE-000004</td>\n",
       "      <td>특허/기술</td>\n",
       "      <td>엔코더가 부착된 모터의 경우 회전량과 회전 속도를 측정할 수 있다.</td>\n",
       "      <td>安装有编码器的电动机,可以测量回转量和回转速度。</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>http://kpat.kipris.or.kr/kpat/biblioa.do?metho...</td>\n",
       "      <td>온아시아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KO-ZH-2020-PATE-000005</td>\n",
       "      <td>특허/기술</td>\n",
       "      <td>본 발명은 반도체 스퍼터링(Sputtering)장비에 있어서, 진공 펌프의 모터를 ...</td>\n",
       "      <td>本发明是关于一种用于保护真空泵的电动机,免受半导体溅射(Sputtering)设备中的过电流...</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>http://kpat.kipris.or.kr/kpat/biblioa.do?metho...</td>\n",
       "      <td>온아시아</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     관리번호     분야  \\\n",
       "0  KO-ZH-2020-PATE-000001  특허/기술   \n",
       "1  KO-ZH-2020-PATE-000002  특허/기술   \n",
       "2  KO-ZH-2020-PATE-000003  특허/기술   \n",
       "3  KO-ZH-2020-PATE-000004  특허/기술   \n",
       "4  KO-ZH-2020-PATE-000005  특허/기술   \n",
       "\n",
       "                                                 한국어  \\\n",
       "0  본 발명은 플러그를 통해 공급되는 주전원의 주파수 특성을 검출하여 주파수의 제로전위...   \n",
       "1  본 발명은 셀룰라폰에 관한 것으로, 셀룰라폰의 이동으로 소정시간이상 서어비스 지역을...   \n",
       "2  또한, 셀 멀티 카피 기능을 활용하기 위한 자원 관리를 수행하지 않기 때문에 하나의...   \n",
       "3              엔코더가 부착된 모터의 경우 회전량과 회전 속도를 측정할 수 있다.   \n",
       "4  본 발명은 반도체 스퍼터링(Sputtering)장비에 있어서, 진공 펌프의 모터를 ...   \n",
       "\n",
       "                                                 중국어  한국어_어절수  중국어_글자수  길이_분류  \\\n",
       "0  本发明可以检测通过插头供应的主电源的频率特性,并为使从接近该频率零电位的上升电位连接到继电器...       23       69      4   \n",
       "1  本发明是关于蜂窝电话的发明,当由于手机的移动而离开服务区域超过预定时间时自动关闭电源,并以预...       25       68      5   \n",
       "2      另外,因为不执行利用单元多功能复制的资源管理,所以存在无法向多个用户提供同一个音调的缺点。       20       42      4   \n",
       "3                           安装有编码器的电动机,可以测量回转量和回转速度。       10       22      2   \n",
       "4  本发明是关于一种用于保护真空泵的电动机,免受半导体溅射(Sputtering)设备中的过电流...       16       47      3   \n",
       "\n",
       "                                                  출처  수행기관  \n",
       "0  http://kpat.kipris.or.kr/kpat/biblioa.do?metho...  온아시아  \n",
       "1  http://kpat.kipris.or.kr/kpat/biblioa.do?metho...  온아시아  \n",
       "2  http://kpat.kipris.or.kr/kpat/biblioa.do?metho...  온아시아  \n",
       "3  http://kpat.kipris.or.kr/kpat/biblioa.do?metho...  온아시아  \n",
       "4  http://kpat.kipris.or.kr/kpat/biblioa.do?metho...  온아시아  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_128_train, df_128_eval = get_train_eval_df(128)\n",
    "display(df_128_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1040000 new data from aihub-128: 0 -> 1040000\n",
      "Added 130000 new data from aihub-128: 1040000 -> 1170000\n"
     ]
    }
   ],
   "source": [
    "df_zh = add_new_data(df_zh, df_128_train, 'zh', '한국어', '중국어', 128)\n",
    "df_zh = add_new_data(df_zh, df_128_eval, 'zh', '한국어', '중국어', 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_891697/3996682252.py:5: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(train_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>관리번호</th>\n",
       "      <th>분야</th>\n",
       "      <th>한국어</th>\n",
       "      <th>중국어</th>\n",
       "      <th>한국어_어절수</th>\n",
       "      <th>중국어_글자수</th>\n",
       "      <th>길이_분류</th>\n",
       "      <th>출처</th>\n",
       "      <th>수행기관</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KO-ZH-2020-EDU-000501</td>\n",
       "      <td>교육</td>\n",
       "      <td>부디 귀한 걸음 해주셔서 아이들의 반짝이는 꿈을 응원해 주시면 감사하겠습니다.</td>\n",
       "      <td>希望能迈开宝贵的脚步,为孩子们的闪耀梦想加油。</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>플리토</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KO-ZH-2020-EDU-000502</td>\n",
       "      <td>교육</td>\n",
       "      <td>스카우트 연간운영계획에 따라 한국스카우트 서울북부연맹 강북지구연합회에서 주최하는 여...</td>\n",
       "      <td>根据童子军年度运营计划,将参加由韩国童子军首尔北部联盟江北地区联合会主办的夏令营。</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>플리토</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KO-ZH-2020-EDU-000503</td>\n",
       "      <td>교육</td>\n",
       "      <td>메이커 교육에 기반을 둔 진로교육을 통해, 학생들의 행복한 미래를 준비할 수 있는 ...</td>\n",
       "      <td>通过以制造者教育为基础的前进教育,培养学生可以准备幸福未来的积极的前进价值观,举行了乌克丽丽...</td>\n",
       "      <td>26</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>플리토</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KO-ZH-2020-EDU-000504</td>\n",
       "      <td>교육</td>\n",
       "      <td>주변의 여러 사물이나 현상에 늘 관심을 가지고 새로운 눈으로 바라봅니다.</td>\n",
       "      <td>总是对周围的各种事物或现象感兴趣,用新的眼睛看待。</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>플리토</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KO-ZH-2020-EDU-000505</td>\n",
       "      <td>교육</td>\n",
       "      <td>이때 목 뒤나 귀 뒤의 머리칼도 반드시 빗질해야 한다.</td>\n",
       "      <td>这时脖子后面或耳朵后面的头发也一定要梳。</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>플리토</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    관리번호  분야  \\\n",
       "0  KO-ZH-2020-EDU-000501  교육   \n",
       "1  KO-ZH-2020-EDU-000502  교육   \n",
       "2  KO-ZH-2020-EDU-000503  교육   \n",
       "3  KO-ZH-2020-EDU-000504  교육   \n",
       "4  KO-ZH-2020-EDU-000505  교육   \n",
       "\n",
       "                                                 한국어  \\\n",
       "0        부디 귀한 걸음 해주셔서 아이들의 반짝이는 꿈을 응원해 주시면 감사하겠습니다.   \n",
       "1  스카우트 연간운영계획에 따라 한국스카우트 서울북부연맹 강북지구연합회에서 주최하는 여...   \n",
       "2  메이커 교육에 기반을 둔 진로교육을 통해, 학생들의 행복한 미래를 준비할 수 있는 ...   \n",
       "3           주변의 여러 사물이나 현상에 늘 관심을 가지고 새로운 눈으로 바라봅니다.   \n",
       "4                     이때 목 뒤나 귀 뒤의 머리칼도 반드시 빗질해야 한다.   \n",
       "\n",
       "                                                 중국어  한국어_어절수  중국어_글자수  길이_분류  \\\n",
       "0                            希望能迈开宝贵的脚步,为孩子们的闪耀梦想加油。       10       21      2   \n",
       "1          根据童子军年度运营计划,将参加由韩国童子军首尔北部联盟江北地区联合会主办的夏令营。       10       39      2   \n",
       "2  通过以制造者教育为基础的前进教育,培养学生可以准备幸福未来的积极的前进价值观,举行了乌克丽丽...       26       64      5   \n",
       "3                          总是对周围的各种事物或现象感兴趣,用新的眼睛看待。       10       23      2   \n",
       "4                               这时脖子后面或耳朵后面的头发也一定要梳。        9       19      1   \n",
       "\n",
       "    출처 수행기관  \n",
       "0  NaN  플리토  \n",
       "1  NaN  플리토  \n",
       "2  NaN  플리토  \n",
       "3  NaN  플리토  \n",
       "4  NaN  플리토  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_129_train, df_129_eval = get_train_eval_df(129)\n",
    "display(df_129_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1040000 new data from aihub-129: 1170000 -> 2210000\n",
      "Added 130000 new data from aihub-129: 2210000 -> 2340000\n"
     ]
    }
   ],
   "source": [
    "df_zh = add_new_data(df_zh, df_129_train, 'zh', '한국어', '중국어', 129)\n",
    "df_zh = add_new_data(df_zh, df_129_eval, 'zh', '한국어', '중국어', 129)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>대분류</th>\n",
       "      <th>중분류</th>\n",
       "      <th>소분류</th>\n",
       "      <th>ID</th>\n",
       "      <th>S_Code</th>\n",
       "      <th>T_Code</th>\n",
       "      <th>S_Length</th>\n",
       "      <th>T_Length</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>특수표현</th>\n",
       "      <th>화자</th>\n",
       "      <th>원문</th>\n",
       "      <th>MT</th>\n",
       "      <th>1차수정</th>\n",
       "      <th>2차수정</th>\n",
       "      <th>최종번역문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일상생활</td>\n",
       "      <td>여행</td>\n",
       "      <td>공항, 기내</td>\n",
       "      <td>1</td>\n",
       "      <td>ko-KR</td>\n",
       "      <td>ja-JP</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>122%</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>기내가 추운데 담요를 받을 수 있을까요?</td>\n",
       "      <td>心の中で毛布を貰えるか?</td>\n",
       "      <td>機内が寒いので、毛布をもらえますか？</td>\n",
       "      <td>NaN</td>\n",
       "      <td>機内が寒いので、毛布をもらえますか？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>일상생활</td>\n",
       "      <td>여행</td>\n",
       "      <td>공항, 기내</td>\n",
       "      <td>2</td>\n",
       "      <td>ko-KR</td>\n",
       "      <td>ja-JP</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>111%</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>죄송하지만 물이랑 같이 냅킨도 조금만 더 가져다주세요.</td>\n",
       "      <td>水죄と一緒にナプキンも少しだけ持ってきてください</td>\n",
       "      <td>すみませんが、お水と一緒にナプキンも少しお願いします。</td>\n",
       "      <td>NaN</td>\n",
       "      <td>すみませんが、お水と一緒にナプキンも少しお願いします。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>일상생활</td>\n",
       "      <td>여행</td>\n",
       "      <td>공항, 기내</td>\n",
       "      <td>3</td>\n",
       "      <td>ko-KR</td>\n",
       "      <td>ja-JP</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>106%</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>물 한 잔 가져다 드리겠습니다.</td>\n",
       "      <td>お水を差し잔上げます。</td>\n",
       "      <td>お水をいっぱいお持ちいたします。</td>\n",
       "      <td>NaN</td>\n",
       "      <td>お水をいっぱいお持ちいたします。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>일상생활</td>\n",
       "      <td>여행</td>\n",
       "      <td>공항, 기내</td>\n",
       "      <td>4</td>\n",
       "      <td>ko-KR</td>\n",
       "      <td>ja-JP</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>160%</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>그 전에 미리 물 먼저 주실 수 있으신가요?</td>\n",
       "      <td>その前にあなたの水を飲ませますか?</td>\n",
       "      <td>その前にお水をいただけますか？</td>\n",
       "      <td>NaN</td>\n",
       "      <td>その前にお水をいただけますか？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>일상생활</td>\n",
       "      <td>여행</td>\n",
       "      <td>공항, 기내</td>\n",
       "      <td>5</td>\n",
       "      <td>ko-KR</td>\n",
       "      <td>ja-JP</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>144%</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>10분 후에 기내식 제공해 드리도록 하겠습니다.</td>\n",
       "      <td>10分後に機内食をご用意ください</td>\n",
       "      <td>10分後に機内食をご提供いたします。</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10分後に機内食をご提供いたします。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    대분류 중분류     소분류  ID S_Code T_Code  S_Length  T_Length Ratio 특수표현 화자  \\\n",
       "0  일상생활  여행  공항, 기내   1  ko-KR  ja-JP        22        18  122%    X  X   \n",
       "1  일상생활  여행  공항, 기내   2  ko-KR  ja-JP        30        27  111%    X  X   \n",
       "2  일상생활  여행  공항, 기내   3  ko-KR  ja-JP        17        16  106%    X  X   \n",
       "3  일상생활  여행  공항, 기내   4  ko-KR  ja-JP        24        15  160%    X  X   \n",
       "4  일상생활  여행  공항, 기내   5  ko-KR  ja-JP        26        18  144%    X  X   \n",
       "\n",
       "                               원문                        MT  \\\n",
       "0          기내가 추운데 담요를 받을 수 있을까요?              心の中で毛布を貰えるか?   \n",
       "1  죄송하지만 물이랑 같이 냅킨도 조금만 더 가져다주세요.  水죄と一緒にナプキンも少しだけ持ってきてください   \n",
       "2               물 한 잔 가져다 드리겠습니다.               お水を差し잔上げます。   \n",
       "3        그 전에 미리 물 먼저 주실 수 있으신가요?         その前にあなたの水を飲ませますか?   \n",
       "4      10분 후에 기내식 제공해 드리도록 하겠습니다.          10分後に機内食をご用意ください   \n",
       "\n",
       "                          1차수정 2차수정                        최종번역문  \n",
       "0           機内が寒いので、毛布をもらえますか？  NaN           機内が寒いので、毛布をもらえますか？  \n",
       "1  すみませんが、お水と一緒にナプキンも少しお願いします。  NaN  すみませんが、お水と一緒にナプキンも少しお願いします。  \n",
       "2             お水をいっぱいお持ちいたします。  NaN             お水をいっぱいお持ちいたします。  \n",
       "3              その前にお水をいただけますか？  NaN              その前にお水をいただけますか？  \n",
       "4           10分後に機内食をご提供いたします。  NaN           10分後に機内食をご提供いたします。  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400000\n"
     ]
    }
   ],
   "source": [
    "df_546_train, df_546_eval = get_train_eval_df(546)\n",
    "display(df_546_train.head())\n",
    "print(len(df_546_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA2KO: 600000 / 75000\n",
      "KO2JA: 600000 / 75000\n",
      "ZH2KO: 600000 / 75000\n",
      "KO2ZH: 600000 / 75000\n"
     ]
    }
   ],
   "source": [
    "ja2ko_546_train = df_546_train[df_546_train['S_Code'] == 'ja-JP']\n",
    "ja2ko_546_eval = df_546_eval[df_546_eval['S_Code'] == 'ja-JP']\n",
    "ko2ja_546_train = df_546_train[df_546_train['T_Code'] == 'ja-JP']\n",
    "ko2ja_546_eval = df_546_eval[df_546_eval['T_Code'] == 'ja-JP']\n",
    "\n",
    "zh2ko_546_train = df_546_train[df_546_train['S_Code'] == 'zh-CN']\n",
    "zh2ko_546_eval = df_546_eval[df_546_eval['S_Code'] == 'zh-CN']\n",
    "ko2zh_546_train = df_546_train[df_546_train['T_Code'] == 'zh-CN']\n",
    "ko2zh_546_eval = df_546_eval[df_546_eval['T_Code'] == 'zh-CN']\n",
    "\n",
    "print(f\"JA2KO: {len(ja2ko_546_train)} / {len(ja2ko_546_eval)}\")\n",
    "print(f\"KO2JA: {len(ko2ja_546_train)} / {len(ko2ja_546_eval)}\")\n",
    "print(f\"ZH2KO: {len(zh2ko_546_train)} / {len(zh2ko_546_eval)}\")\n",
    "print(f\"KO2ZH: {len(ko2zh_546_train)} / {len(ko2zh_546_eval)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 600000 new data from aihub-546: 1350000 -> 1950000\n",
      "Added 75000 new data from aihub-546: 1950000 -> 2025000\n",
      "Added 600000 new data from aihub-546: 2025000 -> 2625000\n",
      "Added 75000 new data from aihub-546: 2625000 -> 2700000\n"
     ]
    }
   ],
   "source": [
    "df_ja = add_new_data(df_ja, ja2ko_546_train, 'ja', '최종번역문', '원문', 546)\n",
    "df_ja = add_new_data(df_ja, ja2ko_546_eval, 'ja', '최종번역문', '원문', 546)\n",
    "df_ja = add_new_data(df_ja, ko2ja_546_train, 'ja', '원문', '최종번역문', 546)\n",
    "df_ja = add_new_data(df_ja, ko2ja_546_eval, 'ja', '원문', '최종번역문', 546)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 600000 new data from aihub-546: 2340000 -> 2940000\n",
      "Added 75000 new data from aihub-546: 2940000 -> 3015000\n",
      "Added 600000 new data from aihub-546: 3015000 -> 3615000\n",
      "Added 75000 new data from aihub-546: 3615000 -> 3690000\n"
     ]
    }
   ],
   "source": [
    "df_zh = add_new_data(df_zh, zh2ko_546_train, 'zh', '최종번역문', '원문', 546)\n",
    "df_zh = add_new_data(df_zh, zh2ko_546_eval, 'zh', '최종번역문', '원문', 546)\n",
    "df_zh = add_new_data(df_zh, ko2zh_546_train, 'zh', '원문', '최종번역문', 546)\n",
    "df_zh = add_new_data(df_zh, ko2zh_546_eval, 'zh', '원문', '최종번역문', 546)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cn']\n",
      "['ko']\n"
     ]
    }
   ],
   "source": [
    "df_71262_train, df_71262_eval = get_train_eval_df(71262)\n",
    "print(df_71262_train['source_language'].unique())\n",
    "print(df_71262_train['target_language'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1200000 new data from aihub-71262: 3690000 -> 4890000\n",
      "Added 150000 new data from aihub-71262: 4890000 -> 5040000\n"
     ]
    }
   ],
   "source": [
    "df_zh = add_new_data(df_zh, df_71262_train, 'zh', 'ko', 'cn', 71262)\n",
    "df_zh = add_new_data(df_zh, df_71262_eval, 'zh', 'ko', 'cn', 71262)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_891697/3996682252.py:5: DtypeWarning: Columns (4,5,18,19,21,22,23,24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(train_path)\n",
      "/tmp/ipykernel_891697/3996682252.py:6: DtypeWarning: Columns (4,18,19,21,23,24,25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  eval_df = pd.read_csv(eval_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['sn', 'data_set', 'domain', 'subdomain', 'cn_original', 'cn', 'mt',\n",
       "       'ko', 'source_language', 'target_language', 'word_count_cn',\n",
       "       'word_count_ko', 'word_ratio', 'file_name', 'source', 'license',\n",
       "       'style', 'included_unknown_words', 'jp_original', 'jp', 'word_count_jp',\n",
       "       'ko_original', 'ner--text', 'ner--tags--tag', 'ner--tags--value',\n",
       "       'ner--tags--position', 'ner'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_71263_train, df_71263_eval = get_train_eval_df(71263)\n",
    "display(df_71263_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA2KO: 360000 / 45000\n",
      "KO2JA: 600000 / 75000\n",
      "ZH2KO: 361856 / 45232\n",
      "KO2ZH: 0 / 0\n"
     ]
    }
   ],
   "source": [
    "ja2ko_71263_train = df_71263_train[df_71263_train['source_language'] == 'jp']\n",
    "ja2ko_71263_eval = df_71263_eval[df_71263_eval['source_language'] == 'jp']\n",
    "ko2ja_71263_train = df_71263_train[df_71263_train['target_language'] == 'jp']\n",
    "ko2ja_71263_eval = df_71263_eval[df_71263_eval['target_language'] == 'jp']\n",
    "\n",
    "zh2ko_71263_train = df_71263_train[df_71263_train['source_language'] == 'cn']\n",
    "zh2ko_71263_eval = df_71263_eval[df_71263_eval['source_language'] == 'cn']\n",
    "ko2zh_71263_train = df_71263_train[df_71263_train['target_language'] == 'cn']\n",
    "ko2zh_71263_eval = df_71263_eval[df_71263_eval['target_language'] == 'cn']\n",
    "\n",
    "print(f\"JA2KO: {len(ja2ko_71263_train)} / {len(ja2ko_71263_eval)}\")\n",
    "print(f\"KO2JA: {len(ko2ja_71263_train)} / {len(ko2ja_71263_eval)}\")\n",
    "print(f\"ZH2KO: {len(zh2ko_71263_train)} / {len(zh2ko_71263_eval)}\")\n",
    "print(f\"KO2ZH: {len(ko2zh_71263_train)} / {len(ko2zh_71263_eval)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 360000 new data from aihub-71263: 2700000 -> 3060000\n",
      "Added 45000 new data from aihub-71263: 3060000 -> 3105000\n",
      "Added 600000 new data from aihub-71263: 3105000 -> 3705000\n",
      "Added 75000 new data from aihub-71263: 3705000 -> 3780000\n"
     ]
    }
   ],
   "source": [
    "df_ja = add_new_data(df_ja, ja2ko_71263_train, 'ja', 'ko', 'jp', 71263)\n",
    "df_ja = add_new_data(df_ja, ja2ko_71263_eval, 'ja', 'ko', 'jp', 71263)\n",
    "df_ja = add_new_data(df_ja, ko2ja_71263_train, 'ja', 'ko', 'jp', 71263)\n",
    "df_ja = add_new_data(df_ja, ko2ja_71263_eval, 'ja', 'ko', 'jp', 71263)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 361856 new data from aihub-71263: 5040000 -> 5401856\n",
      "Added 45232 new data from aihub-71263: 5401856 -> 5447088\n"
     ]
    }
   ],
   "source": [
    "df_zh = add_new_data(df_zh, zh2ko_71263_train, 'zh', 'ko', 'cn', 71263)\n",
    "df_zh = add_new_data(df_zh, zh2ko_71263_eval, 'zh', 'ko', 'cn', 71263)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fileName</th>\n",
       "      <th>dataSet</th>\n",
       "      <th>domain</th>\n",
       "      <th>style</th>\n",
       "      <th>isDialect</th>\n",
       "      <th>sourceText</th>\n",
       "      <th>targetText</th>\n",
       "      <th>sourceLanguage</th>\n",
       "      <th>targetLanguage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100015-216-1-2</td>\n",
       "      <td>zh-ko_WR_CA_zh_ko_100015-216-1-2</td>\n",
       "      <td>기계번역 병렬 말뭉치 데이터</td>\n",
       "      <td>CA</td>\n",
       "      <td>WR</td>\n",
       "      <td>n</td>\n",
       "      <td>并由约翰·奥古斯特担任编剧，</td>\n",
       "      <td>그리고 존 오거스트가 시나리오를 썼다.</td>\n",
       "      <td>zh</td>\n",
       "      <td>ko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100014-280-1-7</td>\n",
       "      <td>jp-ko_SP_ES_jp_ko_100014-280-1-7</td>\n",
       "      <td>기계번역 병렬 말뭉치 데이터</td>\n",
       "      <td>ES</td>\n",
       "      <td>SP</td>\n",
       "      <td>n</td>\n",
       "      <td>エアコンが強かったり着せてるものが薄すぎるっていうことかもね。</td>\n",
       "      <td>에어컨 바람이 강하거나 입힌 옷이 너무 얇다는 것일지도 모릅니다.</td>\n",
       "      <td>jp</td>\n",
       "      <td>ko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100010-1997-1-4</td>\n",
       "      <td>ko-en_CH_ST_ko_en_100010-1997-1-4</td>\n",
       "      <td>기계번역 병렬 말뭉치 데이터</td>\n",
       "      <td>ST</td>\n",
       "      <td>CH</td>\n",
       "      <td>n</td>\n",
       "      <td>맞아 브러시질을 잘 안 해주면 털이 정리가 안돼서 그런가 안 이쁘더라.</td>\n",
       "      <td>That's right. If you don't brush your dog well...</td>\n",
       "      <td>ko</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100010-1225-1-5</td>\n",
       "      <td>ko-en_SP_CA_ko_en_100010-1225-1-5</td>\n",
       "      <td>기계번역 병렬 말뭉치 데이터</td>\n",
       "      <td>CA</td>\n",
       "      <td>SP</td>\n",
       "      <td>n</td>\n",
       "      <td>정글아 미드 갱 가지 말고 바텀에다가 전령 풀어.</td>\n",
       "      <td>Jungle, don't go to the mid Gang. Send a heral...</td>\n",
       "      <td>ko</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100012-614-1-5</td>\n",
       "      <td>ko-zh_CH_CA_ko_zh_100012-614-1-5</td>\n",
       "      <td>기계번역 병렬 말뭉치 데이터</td>\n",
       "      <td>CA</td>\n",
       "      <td>CH</td>\n",
       "      <td>n</td>\n",
       "      <td>빌보드 핫 백 순위 몇 위인데 난 셀링만 알아.</td>\n",
       "      <td>他们在公告牌百强单曲榜上排第几？我只知道销售量。</td>\n",
       "      <td>ko</td>\n",
       "      <td>zh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                           fileName          dataSet domain  \\\n",
       "0   100015-216-1-2   zh-ko_WR_CA_zh_ko_100015-216-1-2  기계번역 병렬 말뭉치 데이터     CA   \n",
       "1   100014-280-1-7   jp-ko_SP_ES_jp_ko_100014-280-1-7  기계번역 병렬 말뭉치 데이터     ES   \n",
       "2  100010-1997-1-4  ko-en_CH_ST_ko_en_100010-1997-1-4  기계번역 병렬 말뭉치 데이터     ST   \n",
       "3  100010-1225-1-5  ko-en_SP_CA_ko_en_100010-1225-1-5  기계번역 병렬 말뭉치 데이터     CA   \n",
       "4   100012-614-1-5   ko-zh_CH_CA_ko_zh_100012-614-1-5  기계번역 병렬 말뭉치 데이터     CA   \n",
       "\n",
       "  style isDialect                               sourceText  \\\n",
       "0    WR         n                           并由约翰·奥古斯特担任编剧，   \n",
       "1    SP         n          エアコンが強かったり着せてるものが薄すぎるっていうことかもね。   \n",
       "2    CH         n  맞아 브러시질을 잘 안 해주면 털이 정리가 안돼서 그런가 안 이쁘더라.   \n",
       "3    SP         n              정글아 미드 갱 가지 말고 바텀에다가 전령 풀어.   \n",
       "4    CH         n               빌보드 핫 백 순위 몇 위인데 난 셀링만 알아.   \n",
       "\n",
       "                                          targetText sourceLanguage  \\\n",
       "0                              그리고 존 오거스트가 시나리오를 썼다.             zh   \n",
       "1               에어컨 바람이 강하거나 입힌 옷이 너무 얇다는 것일지도 모릅니다.             jp   \n",
       "2  That's right. If you don't brush your dog well...             ko   \n",
       "3  Jungle, don't go to the mid Gang. Send a heral...             ko   \n",
       "4                           他们在公告牌百强单曲榜上排第几？我只知道销售量。             ko   \n",
       "\n",
       "  targetLanguage  \n",
       "0             ko  \n",
       "1             ko  \n",
       "2             en  \n",
       "3             en  \n",
       "4             zh  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_71411_train, df_71411_eval = get_train_eval_df(71411)\n",
    "display(df_71411_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA2KO: 12000 / 1500\n",
      "KO2JA: 12000 / 1500\n",
      "ZH2KO: 12000 / 1500\n",
      "KO2ZH: 12000 / 1500\n"
     ]
    }
   ],
   "source": [
    "ja2ko_71411_train = df_71411_train[df_71411_train['sourceLanguage'] == 'jp']\n",
    "ja2ko_71411_eval = df_71411_eval[df_71411_eval['sourceLanguage'] == 'jp']\n",
    "ko2ja_71411_train = df_71411_train[df_71411_train['targetLanguage'] == 'jp']\n",
    "ko2ja_71411_eval = df_71411_eval[df_71411_eval['targetLanguage'] == 'jp']\n",
    "\n",
    "zh2ko_71411_train = df_71411_train[df_71411_train['sourceLanguage'] == 'zh']\n",
    "zh2ko_71411_eval = df_71411_eval[df_71411_eval['sourceLanguage'] == 'zh']\n",
    "ko2zh_71411_train = df_71411_train[df_71411_train['targetLanguage'] == 'zh']\n",
    "ko2zh_71411_eval = df_71411_eval[df_71411_eval['targetLanguage'] == 'zh']\n",
    "\n",
    "print(f\"JA2KO: {len(ja2ko_71411_train)} / {len(ja2ko_71411_eval)}\")\n",
    "print(f\"KO2JA: {len(ko2ja_71411_train)} / {len(ko2ja_71411_eval)}\")\n",
    "print(f\"ZH2KO: {len(zh2ko_71411_train)} / {len(zh2ko_71411_eval)}\")\n",
    "print(f\"KO2ZH: {len(ko2zh_71411_train)} / {len(ko2zh_71411_eval)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 12000 new data from aihub-71411: 3780000 -> 3792000\n",
      "Added 1500 new data from aihub-71411: 3792000 -> 3793500\n",
      "Added 12000 new data from aihub-71411: 3793500 -> 3805500\n",
      "Added 1500 new data from aihub-71411: 3805500 -> 3807000\n"
     ]
    }
   ],
   "source": [
    "df_ja = add_new_data(df_ja, ja2ko_71411_train, 'ja', 'targetText', 'sourceText', 71411)\n",
    "df_ja = add_new_data(df_ja, ja2ko_71411_eval, 'ja', 'targetText', 'sourceText', 71411)\n",
    "df_ja = add_new_data(df_ja, ko2ja_71411_train, 'ja', 'sourceText', 'targetText', 71411)\n",
    "df_ja = add_new_data(df_ja, ko2ja_71411_eval, 'ja', 'sourceText', 'targetText', 71411)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 12000 new data from aihub-71411: 5447088 -> 5459088\n",
      "Added 1500 new data from aihub-71411: 5459088 -> 5460588\n",
      "Added 12000 new data from aihub-71411: 5460588 -> 5472588\n",
      "Added 1500 new data from aihub-71411: 5472588 -> 5474088\n"
     ]
    }
   ],
   "source": [
    "df_zh = add_new_data(df_zh, zh2ko_71411_train, 'zh', 'targetText', 'sourceText', 71411)\n",
    "df_zh = add_new_data(df_zh, zh2ko_71411_eval, 'zh', 'targetText', 'sourceText', 71411)\n",
    "df_zh = add_new_data(df_zh, ko2zh_71411_train, 'zh', 'sourceText', 'targetText', 71411)\n",
    "df_zh = add_new_data(df_zh, ko2zh_71411_eval, 'zh', 'sourceText', 'targetText', 71411)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_891697/3996682252.py:5: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(train_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Publication_type</th>\n",
       "      <th>Author</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>Published_year</th>\n",
       "      <th>Date_created</th>\n",
       "      <th>Classify_1</th>\n",
       "      <th>Classify_2</th>\n",
       "      <th>...</th>\n",
       "      <th>src_sentence</th>\n",
       "      <th>tgt_sentence</th>\n",
       "      <th>src_lang</th>\n",
       "      <th>tgt_lang</th>\n",
       "      <th>src_paragraphs_id</th>\n",
       "      <th>src_word_count</th>\n",
       "      <th>spc_technical_label</th>\n",
       "      <th>spc_idiomatic_label</th>\n",
       "      <th>spc_proper_label</th>\n",
       "      <th>spc_double_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110701001</td>\n",
       "      <td>리더의 품격 : 최고의 지도자를 만드는 실행력</td>\n",
       "      <td>도서</td>\n",
       "      <td>신동준 지음</td>\n",
       "      <td>9.788966e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>기술과학</td>\n",
       "      <td>정보/통신</td>\n",
       "      <td>...</td>\n",
       "      <td>G2 중국의 궁극적인 목표는 현재의 G1 미국을 제압하고 명실상부한 G1 중국을 건...</td>\n",
       "      <td>G2中国的最终目标是推翻现在的G1美国，建立一个真正的G1中国。</td>\n",
       "      <td>ko</td>\n",
       "      <td>ch</td>\n",
       "      <td>SI-2208211358P57035898R0200025</td>\n",
       "      <td>13</td>\n",
       "      <td>건설</td>\n",
       "      <td>명실상부</td>\n",
       "      <td>중국,미국,중국</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110701001</td>\n",
       "      <td>리더의 품격 : 최고의 지도자를 만드는 실행력</td>\n",
       "      <td>도서</td>\n",
       "      <td>신동준 지음</td>\n",
       "      <td>9.788966e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>기술과학</td>\n",
       "      <td>정보/통신</td>\n",
       "      <td>...</td>\n",
       "      <td>지역 간 극심한 빈부 격차로 인한 갈등을 해소해야 했다.</td>\n",
       "      <td>需要解决地区间极端贫富差距引发的冲突。</td>\n",
       "      <td>ko</td>\n",
       "      <td>ch</td>\n",
       "      <td>SI-2208211358P57035898R0200038</td>\n",
       "      <td>9</td>\n",
       "      <td>지역,격차</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110701001</td>\n",
       "      <td>리더의 품격 : 최고의 지도자를 만드는 실행력</td>\n",
       "      <td>도서</td>\n",
       "      <td>신동준 지음</td>\n",
       "      <td>9.788966e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>기술과학</td>\n",
       "      <td>정보/통신</td>\n",
       "      <td>...</td>\n",
       "      <td>경제발전의 수혜를 받지 못하고 내륙오지에서 낙후된 삶을 살아가야 하는 소수민족의 불...</td>\n",
       "      <td>这是因为内陆地区没有享受到经济发展的红利，不得不过着贫困生活的少数民族的不满情绪已经浮出水面。</td>\n",
       "      <td>ko</td>\n",
       "      <td>ch</td>\n",
       "      <td>SI-2208211358P57035898R0200039</td>\n",
       "      <td>15</td>\n",
       "      <td>발전,내륙</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110701001</td>\n",
       "      <td>리더의 품격 : 최고의 지도자를 만드는 실행력</td>\n",
       "      <td>도서</td>\n",
       "      <td>신동준 지음</td>\n",
       "      <td>9.788966e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>기술과학</td>\n",
       "      <td>정보/통신</td>\n",
       "      <td>...</td>\n",
       "      <td>한족을 포함한 중국 내 56개 민족은 원래 하나였다는 주장이 핵심이다.</td>\n",
       "      <td>主要论点是中国包括汉族在内的56个民族本来就是一个民族。</td>\n",
       "      <td>ko</td>\n",
       "      <td>ch</td>\n",
       "      <td>SI-2208211358P57035898R0200040</td>\n",
       "      <td>10</td>\n",
       "      <td>핵심</td>\n",
       "      <td>NaN</td>\n",
       "      <td>중국</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110701001</td>\n",
       "      <td>리더의 품격 : 최고의 지도자를 만드는 실행력</td>\n",
       "      <td>도서</td>\n",
       "      <td>신동준 지음</td>\n",
       "      <td>9.788966e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>기술과학</td>\n",
       "      <td>정보/통신</td>\n",
       "      <td>...</td>\n",
       "      <td>그런데도 중국 학계는 수당의 황실마저 한인과 호인의 혼혈로 시작했고 게다가 점차 호...</td>\n",
       "      <td>中国学界认为，即使是苏丹皇室，一开始也是高丽人与胡人混血，胡人的血统逐渐被稀释。</td>\n",
       "      <td>ko</td>\n",
       "      <td>ch</td>\n",
       "      <td>SI-2208211358P57035898R0200042</td>\n",
       "      <td>17</td>\n",
       "      <td>희석</td>\n",
       "      <td>NaN</td>\n",
       "      <td>중국,수당</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Index                      Title Publication_type  Author  \\\n",
       "0  110701001  리더의 품격 : 최고의 지도자를 만드는 실행력               도서  신동준 지음   \n",
       "1  110701001  리더의 품격 : 최고의 지도자를 만드는 실행력               도서  신동준 지음   \n",
       "2  110701001  리더의 품격 : 최고의 지도자를 만드는 실행력               도서  신동준 지음   \n",
       "3  110701001  리더의 품격 : 최고의 지도자를 만드는 실행력               도서  신동준 지음   \n",
       "4  110701001  리더의 품격 : 최고의 지도자를 만드는 실행력               도서  신동준 지음   \n",
       "\n",
       "           ISBN ISSN  Published_year Date_created Classify_1 Classify_2  ...  \\\n",
       "0  9.788966e+12  NaN            2019   2023-08-30       기술과학      정보/통신  ...   \n",
       "1  9.788966e+12  NaN            2019   2023-08-30       기술과학      정보/통신  ...   \n",
       "2  9.788966e+12  NaN            2019   2023-08-30       기술과학      정보/통신  ...   \n",
       "3  9.788966e+12  NaN            2019   2023-08-30       기술과학      정보/통신  ...   \n",
       "4  9.788966e+12  NaN            2019   2023-08-30       기술과학      정보/통신  ...   \n",
       "\n",
       "                                        src_sentence  \\\n",
       "0  G2 중국의 궁극적인 목표는 현재의 G1 미국을 제압하고 명실상부한 G1 중국을 건...   \n",
       "1                    지역 간 극심한 빈부 격차로 인한 갈등을 해소해야 했다.   \n",
       "2  경제발전의 수혜를 받지 못하고 내륙오지에서 낙후된 삶을 살아가야 하는 소수민족의 불...   \n",
       "3            한족을 포함한 중국 내 56개 민족은 원래 하나였다는 주장이 핵심이다.   \n",
       "4  그런데도 중국 학계는 수당의 황실마저 한인과 호인의 혼혈로 시작했고 게다가 점차 호...   \n",
       "\n",
       "                                      tgt_sentence src_lang tgt_lang  \\\n",
       "0                 G2中国的最终目标是推翻现在的G1美国，建立一个真正的G1中国。       ko       ch   \n",
       "1                              需要解决地区间极端贫富差距引发的冲突。       ko       ch   \n",
       "2  这是因为内陆地区没有享受到经济发展的红利，不得不过着贫困生活的少数民族的不满情绪已经浮出水面。       ko       ch   \n",
       "3                     主要论点是中国包括汉族在内的56个民族本来就是一个民族。       ko       ch   \n",
       "4         中国学界认为，即使是苏丹皇室，一开始也是高丽人与胡人混血，胡人的血统逐渐被稀释。       ko       ch   \n",
       "\n",
       "                src_paragraphs_id src_word_count  spc_technical_label  \\\n",
       "0  SI-2208211358P57035898R0200025             13                   건설   \n",
       "1  SI-2208211358P57035898R0200038              9                지역,격차   \n",
       "2  SI-2208211358P57035898R0200039             15                발전,내륙   \n",
       "3  SI-2208211358P57035898R0200040             10                   핵심   \n",
       "4  SI-2208211358P57035898R0200042             17                   희석   \n",
       "\n",
       "  spc_idiomatic_label spc_proper_label spc_double_label  \n",
       "0                명실상부         중국,미국,중국              NaN  \n",
       "1                 NaN              NaN              NaN  \n",
       "2                 NaN              NaN              NaN  \n",
       "3                 NaN               중국              NaN  \n",
       "4                 NaN            중국,수당              NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240426\n"
     ]
    }
   ],
   "source": [
    "df_71493_train, df_71493_eval = get_train_eval_df(71493)\n",
    "display(df_71493_train.head())\n",
    "print(len(df_71493_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Index', 'Title', 'Publication_type', 'Author', 'ISBN', 'ISSN',\n",
       "       'Published_year', 'Date_created', 'Classify_1', 'Classify_2',\n",
       "       'Classify_3', 'src_sentence', 'tgt_sentence', 'src_lang', 'tgt_lang',\n",
       "       'src_paragraphs_id', 'src_word_count', 'spc_technical_label',\n",
       "       'spc_idiomatic_label', 'spc_proper_label', 'spc_double_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_71493_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ko'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['ch', 'jp'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_71493_train['src_lang'].unique())\n",
    "display(df_71493_train['tgt_lang'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA: 123455 / 687\n",
      "ZH: 116971 / 29346\n"
     ]
    }
   ],
   "source": [
    "ja_71493_train = df_71493_train[df_71493_train['tgt_lang'] == 'jp']\n",
    "ja_71493_eval = df_71493_eval[df_71493_eval['tgt_lang'] == 'jp']\n",
    "zh_71493_train = df_71493_train[df_71493_train['tgt_lang'] == 'ch']\n",
    "zh_71493_eval = df_71493_eval[df_71493_eval['tgt_lang'] == 'ch']\n",
    "\n",
    "print(f\"JA: {len(ja_71493_train)} / {len(ja_71493_eval)}\")\n",
    "print(f\"ZH: {len(zh_71493_train)} / {len(zh_71493_eval)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 123455 new data from aihub-71493: 3807000 -> 3930455\n",
      "Added 687 new data from aihub-71493: 3930455 -> 3931142\n"
     ]
    }
   ],
   "source": [
    "df_ja = add_new_data(df_ja, ja_71493_train, 'ja', 'src_sentence', 'tgt_sentence', 71493)\n",
    "df_ja = add_new_data(df_ja, ja_71493_eval, 'ja', 'src_sentence', 'tgt_sentence', 71493)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 116971 new data from aihub-71493: 5474088 -> 5591059\n",
      "Added 29346 new data from aihub-71493: 5591059 -> 5620405\n"
     ]
    }
   ],
   "source": [
    "df_zh = add_new_data(df_zh, zh_71493_train, 'zh', 'src_sentence', 'tgt_sentence', 71493)\n",
    "df_zh = add_new_data(df_zh, zh_71493_eval, 'zh', 'src_sentence', 'tgt_sentence', 71493)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_891697/3996682252.py:5: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(train_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Publication_type</th>\n",
       "      <th>Author</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>Published_year</th>\n",
       "      <th>Date_created</th>\n",
       "      <th>Classify_1</th>\n",
       "      <th>Classify_2</th>\n",
       "      <th>...</th>\n",
       "      <th>src_sentence</th>\n",
       "      <th>tgt_sentence</th>\n",
       "      <th>src_lang</th>\n",
       "      <th>tgt_lang</th>\n",
       "      <th>src_paragraphs_id</th>\n",
       "      <th>src_word_count</th>\n",
       "      <th>spc_technical_label</th>\n",
       "      <th>spc_idiomatic_label</th>\n",
       "      <th>spc_proper_label</th>\n",
       "      <th>spc_double_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112985524</td>\n",
       "      <td>21세기 생태평화를 위한 환경교과서</td>\n",
       "      <td>도서</td>\n",
       "      <td>환경과생명을지키는전국교사모임 지음</td>\n",
       "      <td>9788992525008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>기초과학</td>\n",
       "      <td>지구과학</td>\n",
       "      <td>...</td>\n",
       "      <td>환경문제는 윤리, 과학, 정치경제와 밀접하게 관련되어 있다.</td>\n",
       "      <td>Ethics, science, and political economy are clo...</td>\n",
       "      <td>ko</td>\n",
       "      <td>en</td>\n",
       "      <td>SI-2208211501P56377315R0100095</td>\n",
       "      <td>7</td>\n",
       "      <td>환경문제,과학</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112985524</td>\n",
       "      <td>21세기 생태평화를 위한 환경교과서</td>\n",
       "      <td>도서</td>\n",
       "      <td>환경과생명을지키는전국교사모임 지음</td>\n",
       "      <td>9788992525008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>기초과학</td>\n",
       "      <td>지구과학</td>\n",
       "      <td>...</td>\n",
       "      <td>과학 기술은 가치중립적이지 않으며 사회에 의해 만들어진다.</td>\n",
       "      <td>Science and technology are not value-neutral a...</td>\n",
       "      <td>ko</td>\n",
       "      <td>en</td>\n",
       "      <td>SI-2208211501P56377315R0100103</td>\n",
       "      <td>7</td>\n",
       "      <td>과학 기술</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112985524</td>\n",
       "      <td>21세기 생태평화를 위한 환경교과서</td>\n",
       "      <td>도서</td>\n",
       "      <td>환경과생명을지키는전국교사모임 지음</td>\n",
       "      <td>9788992525008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>기초과학</td>\n",
       "      <td>지구과학</td>\n",
       "      <td>...</td>\n",
       "      <td>골프장의 생태적·환경적 문제점을 다양하게 표현할 수 있다.</td>\n",
       "      <td>Ecological and environmental problems about go...</td>\n",
       "      <td>ko</td>\n",
       "      <td>en</td>\n",
       "      <td>SI-2208211501P56377315R0100316</td>\n",
       "      <td>7</td>\n",
       "      <td>생태</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112985524</td>\n",
       "      <td>21세기 생태평화를 위한 환경교과서</td>\n",
       "      <td>도서</td>\n",
       "      <td>환경과생명을지키는전국교사모임 지음</td>\n",
       "      <td>9788992525008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>기초과학</td>\n",
       "      <td>지구과학</td>\n",
       "      <td>...</td>\n",
       "      <td>골프장 건설이 숲을 사라지게 하고 있는 것이다.</td>\n",
       "      <td>Golf course construction is causing forests to...</td>\n",
       "      <td>ko</td>\n",
       "      <td>en</td>\n",
       "      <td>SI-2208211501P56377315R0100433</td>\n",
       "      <td>7</td>\n",
       "      <td>건설</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112985524</td>\n",
       "      <td>21세기 생태평화를 위한 환경교과서</td>\n",
       "      <td>도서</td>\n",
       "      <td>환경과생명을지키는전국교사모임 지음</td>\n",
       "      <td>9788992525008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>기초과학</td>\n",
       "      <td>지구과학</td>\n",
       "      <td>...</td>\n",
       "      <td>그리고 환경문제라고 하면 환경오염, 쓰레기 등을 생각합니다.</td>\n",
       "      <td>We think of environmental issues, we think of ...</td>\n",
       "      <td>ko</td>\n",
       "      <td>en</td>\n",
       "      <td>SI-2208211501P56377315R0100636</td>\n",
       "      <td>7</td>\n",
       "      <td>환경문제,환경오염,쓰레기</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Index                Title Publication_type              Author  \\\n",
       "0  112985524  21세기 생태평화를 위한 환경교과서               도서  환경과생명을지키는전국교사모임 지음   \n",
       "1  112985524  21세기 생태평화를 위한 환경교과서               도서  환경과생명을지키는전국교사모임 지음   \n",
       "2  112985524  21세기 생태평화를 위한 환경교과서               도서  환경과생명을지키는전국교사모임 지음   \n",
       "3  112985524  21세기 생태평화를 위한 환경교과서               도서  환경과생명을지키는전국교사모임 지음   \n",
       "4  112985524  21세기 생태평화를 위한 환경교과서               도서  환경과생명을지키는전국교사모임 지음   \n",
       "\n",
       "              ISBN ISSN  Published_year Date_created Classify_1 Classify_2  \\\n",
       "0  9788992525008.0  NaN            2019   2023-08-30       기초과학       지구과학   \n",
       "1  9788992525008.0  NaN            2019   2023-08-30       기초과학       지구과학   \n",
       "2  9788992525008.0  NaN            2019   2023-08-30       기초과학       지구과학   \n",
       "3  9788992525008.0  NaN            2019   2023-08-30       기초과학       지구과학   \n",
       "4  9788992525008.0  NaN            2019   2023-08-30       기초과학       지구과학   \n",
       "\n",
       "   ...                       src_sentence  \\\n",
       "0  ...  환경문제는 윤리, 과학, 정치경제와 밀접하게 관련되어 있다.   \n",
       "1  ...   과학 기술은 가치중립적이지 않으며 사회에 의해 만들어진다.   \n",
       "2  ...   골프장의 생태적·환경적 문제점을 다양하게 표현할 수 있다.   \n",
       "3  ...         골프장 건설이 숲을 사라지게 하고 있는 것이다.   \n",
       "4  ...  그리고 환경문제라고 하면 환경오염, 쓰레기 등을 생각합니다.   \n",
       "\n",
       "                                        tgt_sentence src_lang tgt_lang  \\\n",
       "0  Ethics, science, and political economy are clo...       ko       en   \n",
       "1  Science and technology are not value-neutral a...       ko       en   \n",
       "2  Ecological and environmental problems about go...       ko       en   \n",
       "3  Golf course construction is causing forests to...       ko       en   \n",
       "4  We think of environmental issues, we think of ...       ko       en   \n",
       "\n",
       "                src_paragraphs_id src_word_count  spc_technical_label  \\\n",
       "0  SI-2208211501P56377315R0100095              7              환경문제,과학   \n",
       "1  SI-2208211501P56377315R0100103              7                과학 기술   \n",
       "2  SI-2208211501P56377315R0100316              7                   생태   \n",
       "3  SI-2208211501P56377315R0100433              7                   건설   \n",
       "4  SI-2208211501P56377315R0100636              7        환경문제,환경오염,쓰레기   \n",
       "\n",
       "  spc_idiomatic_label spc_proper_label spc_double_label  \n",
       "0                 NaN              NaN              NaN  \n",
       "1                 NaN              NaN              NaN  \n",
       "2                 NaN              NaN              NaN  \n",
       "3                 NaN              NaN              NaN  \n",
       "4                 NaN              NaN              NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240245\n",
      "30072\n"
     ]
    }
   ],
   "source": [
    "df_71496_train, df_71496_eval = get_train_eval_df(71496)\n",
    "display(df_71496_train.head())\n",
    "print(len(df_71496_train))\n",
    "print(len(df_71496_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Index', 'Title', 'Publication_type', 'Author', 'ISBN', 'ISSN',\n",
       "       'Published_year', 'Date_created', 'Classify_1', 'Classify_2',\n",
       "       'Classify_3', 'src_sentence', 'tgt_sentence', 'src_lang', 'tgt_lang',\n",
       "       'src_paragraphs_id', 'src_word_count', 'spc_technical_label',\n",
       "       'spc_idiomatic_label', 'spc_proper_label', 'spc_double_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_71496_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ko'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['en', 'ch', 'jp'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['ko'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['jp', 'ch', 'en'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_71496_train['src_lang'].unique())\n",
    "display(df_71496_train['tgt_lang'].unique())\n",
    "display(df_71496_eval['src_lang'].unique())\n",
    "display(df_71496_eval['tgt_lang'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA: 68945 / 12537\n",
      "ZH: 76476 / 7943\n"
     ]
    }
   ],
   "source": [
    "ja_71496_train = df_71496_train[df_71496_train['tgt_lang'] == 'jp']\n",
    "ja_71496_eval = df_71496_eval[df_71496_eval['tgt_lang'] == 'jp']\n",
    "zh_71496_train = df_71496_train[df_71496_train['tgt_lang'] == 'ch']\n",
    "zh_71496_eval = df_71496_eval[df_71496_eval['tgt_lang'] == 'ch']\n",
    "\n",
    "print(f\"JA: {len(ja_71496_train)} / {len(ja_71496_eval)}\")\n",
    "print(f\"ZH: {len(zh_71496_train)} / {len(zh_71496_eval)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 68945 new data from aihub-71496: 3931142 -> 4000087\n",
      "Added 12537 new data from aihub-71496: 4000087 -> 4012624\n"
     ]
    }
   ],
   "source": [
    "df_ja = add_new_data(df_ja, ja_71496_train, 'ja', 'src_sentence', 'tgt_sentence', 71496)\n",
    "df_ja = add_new_data(df_ja, ja_71496_eval, 'ja', 'src_sentence', 'tgt_sentence', 71496)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 76476 new data from aihub-71496: 5620405 -> 5696881\n",
      "Added 7943 new data from aihub-71496: 5696881 -> 5704824\n"
     ]
    }
   ],
   "source": [
    "df_zh = add_new_data(df_zh, zh_71496_train, 'zh', 'src_sentence', 'tgt_sentence', 71496)\n",
    "df_zh = add_new_data(df_zh, zh_71496_eval, 'zh', 'src_sentence', 'tgt_sentence', 71496)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_891697/3996682252.py:5: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(train_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Publication_type</th>\n",
       "      <th>Author</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>Published_year</th>\n",
       "      <th>Date_created</th>\n",
       "      <th>Classify_1</th>\n",
       "      <th>Classify_2</th>\n",
       "      <th>...</th>\n",
       "      <th>src_sentence</th>\n",
       "      <th>tgt_sentence</th>\n",
       "      <th>src_lang</th>\n",
       "      <th>tgt_lang</th>\n",
       "      <th>src_paragraphs_id</th>\n",
       "      <th>src_word_count</th>\n",
       "      <th>spc_technical_label</th>\n",
       "      <th>spc_idiomatic_label</th>\n",
       "      <th>spc_proper_label</th>\n",
       "      <th>spc_double_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000010765</td>\n",
       "      <td>국내 대화분석 연구 개관 : 동향, 평가 및 전망</td>\n",
       "      <td>논문</td>\n",
       "      <td>김규현;서경희</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1226-4822</td>\n",
       "      <td>2020</td>\n",
       "      <td>2023-08-30</td>\n",
       "      <td>인문학</td>\n",
       "      <td>철학/종교</td>\n",
       "      <td>...</td>\n",
       "      <td>누군가는 ‘시원하다.’고 할 것이며, 또 다른 사람은 ‘죽인다.’ 혹은 ‘끝내준다....</td>\n",
       "      <td>Some will say 'cool,' whereas others will say ...</td>\n",
       "      <td>ko</td>\n",
       "      <td>en</td>\n",
       "      <td>SI-2210131703P00208497R0100691</td>\n",
       "      <td>12</td>\n",
       "      <td>사람</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Index                        Title Publication_type   Author  ISBN  \\\n",
       "0  1000010765  국내 대화분석 연구 개관 : 동향, 평가 및 전망               논문  김규현;서경희   NaN   \n",
       "\n",
       "        ISSN  Published_year Date_created Classify_1 Classify_2  ...  \\\n",
       "0  1226-4822            2020   2023-08-30        인문학      철학/종교  ...   \n",
       "\n",
       "                                        src_sentence  \\\n",
       "0  누군가는 ‘시원하다.’고 할 것이며, 또 다른 사람은 ‘죽인다.’ 혹은 ‘끝내준다....   \n",
       "\n",
       "                                        tgt_sentence src_lang tgt_lang  \\\n",
       "0  Some will say 'cool,' whereas others will say ...       ko       en   \n",
       "\n",
       "                src_paragraphs_id src_word_count  spc_technical_label  \\\n",
       "0  SI-2210131703P00208497R0100691             12                   사람   \n",
       "\n",
       "  spc_idiomatic_label spc_proper_label spc_double_label  \n",
       "0                 NaN              NaN              NaN  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241069\n",
      "30652\n"
     ]
    }
   ],
   "source": [
    "df_71498_train, df_71498_eval = get_train_eval_df(71498)\n",
    "display(df_71498_train.head(1))\n",
    "print(len(df_71498_train))\n",
    "print(len(df_71498_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Index', 'Title', 'Publication_type', 'Author', 'ISBN', 'ISSN',\n",
       "       'Published_year', 'Date_created', 'Classify_1', 'Classify_2',\n",
       "       'Classify_3', 'src_sentence', 'tgt_sentence', 'src_lang', 'tgt_lang',\n",
       "       'src_paragraphs_id', 'src_word_count', 'spc_technical_label',\n",
       "       'spc_idiomatic_label', 'spc_proper_label', 'spc_double_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_71498_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ko'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['en', 'jp', 'ch'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['ko'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['jp', 'en', 'ch'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_71498_train['src_lang'].unique())\n",
    "display(df_71498_train['tgt_lang'].unique())\n",
    "display(df_71498_eval['src_lang'].unique())\n",
    "display(df_71498_eval['tgt_lang'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA: 74895 / 6663\n",
      "ZH: 67217 / 13674\n"
     ]
    }
   ],
   "source": [
    "ja_71498_train = df_71498_train[df_71498_train['tgt_lang'] == 'jp']\n",
    "ja_71498_eval = df_71498_eval[df_71498_eval['tgt_lang'] == 'jp']\n",
    "zh_71498_train = df_71498_train[df_71498_train['tgt_lang'] == 'ch']\n",
    "zh_71498_eval = df_71498_eval[df_71498_eval['tgt_lang'] == 'ch']\n",
    "\n",
    "print(f\"JA: {len(ja_71498_train)} / {len(ja_71498_eval)}\")\n",
    "print(f\"ZH: {len(zh_71498_train)} / {len(zh_71498_eval)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 74895 new data from aihub-71498: 4012624 -> 4087519\n",
      "Added 6663 new data from aihub-71498: 4087519 -> 4094182\n"
     ]
    }
   ],
   "source": [
    "df_ja = add_new_data(df_ja, ja_71498_train, 'ja', 'src_sentence', 'tgt_sentence', 71498)\n",
    "df_ja = add_new_data(df_ja, ja_71498_eval, 'ja', 'src_sentence', 'tgt_sentence', 71498)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 67217 new data from aihub-71498: 5704824 -> 5772041\n",
      "Added 13674 new data from aihub-71498: 5772041 -> 5785715\n"
     ]
    }
   ],
   "source": [
    "df_zh = add_new_data(df_zh, zh_71498_train, 'zh', 'src_sentence', 'tgt_sentence', 71498)\n",
    "df_zh = add_new_data(df_zh, zh_71498_eval, 'zh', 'src_sentence', 'tgt_sentence', 71498)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>typeInfo--script--domain</th>\n",
       "      <th>typeInfo--script--topic</th>\n",
       "      <th>typeInfo--script--scriptNumber</th>\n",
       "      <th>typeInfo--script--scriptFileName</th>\n",
       "      <th>typeInfo--language</th>\n",
       "      <th>typeInfo--place</th>\n",
       "      <th>typeInfo--speaker--speakerId</th>\n",
       "      <th>typeInfo--speaker--gender</th>\n",
       "      <th>typeInfo--speaker--age</th>\n",
       "      <th>dialogs--textNumber</th>\n",
       "      <th>dialogs--speakerId</th>\n",
       "      <th>dialogs--text</th>\n",
       "      <th>dialogs--startTime</th>\n",
       "      <th>dialogs--endTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-25</td>\n",
       "      <td>1</td>\n",
       "      <td>빨강머리 앤</td>\n",
       "      <td>100021_3077_1</td>\n",
       "      <td>빨강머리 앤 4 바람의 포퓰러 집 이야기 (1_5)_ko_00003</td>\n",
       "      <td>es</td>\n",
       "      <td>studio</td>\n",
       "      <td>100137</td>\n",
       "      <td>F</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>100137</td>\n",
       "      <td>Siempre han gobernado el gallinero aquí..</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.210667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-25</td>\n",
       "      <td>1</td>\n",
       "      <td>빨강머리 앤</td>\n",
       "      <td>100020_2898_1</td>\n",
       "      <td>빨강머리 앤 3 레드먼드 이야기 (12장_20장)_ko_00031</td>\n",
       "      <td>jp</td>\n",
       "      <td>studio</td>\n",
       "      <td>100351</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>100351</td>\n",
       "      <td>なぜ神様が彼らを創造されたのか分からない。</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-10</td>\n",
       "      <td>1</td>\n",
       "      <td>빨강머리 앤</td>\n",
       "      <td>100020_2811_1</td>\n",
       "      <td>빨강머리 앤 2 에이번리 이야기(1_5)_ko_00002</td>\n",
       "      <td>jp</td>\n",
       "      <td>studio</td>\n",
       "      <td>100166</td>\n",
       "      <td>F</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>100166</td>\n",
       "      <td>\"背も小さく、太っていて、しかもハゲだったからだ。\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.488000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>1</td>\n",
       "      <td>빨강머리 앤</td>\n",
       "      <td>100019_2802_1</td>\n",
       "      <td>빨강머리 앤 2 에이번리 이야기(3_5)_ko_00025</td>\n",
       "      <td>en</td>\n",
       "      <td>studio</td>\n",
       "      <td>100564</td>\n",
       "      <td>F</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>100564</td>\n",
       "      <td>Anne said vehemently.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.674667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>5</td>\n",
       "      <td>통계법</td>\n",
       "      <td>100019_1416_1</td>\n",
       "      <td>통계법의 이해</td>\n",
       "      <td>en</td>\n",
       "      <td>studio</td>\n",
       "      <td>100233</td>\n",
       "      <td>F</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>100233</td>\n",
       "      <td>Statistics Korea defines it with six dimension...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.416000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>1</td>\n",
       "      <td>빨강머리 앤</td>\n",
       "      <td>100021_2666_1</td>\n",
       "      <td>빨강머리 앤 1 초록지붕 집 이야기 (1장_5장)_ko_00021</td>\n",
       "      <td>es</td>\n",
       "      <td>studio</td>\n",
       "      <td>100597</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>100597</td>\n",
       "      <td>Sí, lo llamaré Bonny.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>1</td>\n",
       "      <td>빨강머리 앤</td>\n",
       "      <td>100018_2704_1</td>\n",
       "      <td>빨강머리 앤 2 에이번리 이야기(2_5)_ko_00003</td>\n",
       "      <td>ko</td>\n",
       "      <td>studio</td>\n",
       "      <td>100659</td>\n",
       "      <td>F</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>100659</td>\n",
       "      <td>\"앤이 좋은 일을 가르칠 기회를 포착하고 얼른 말했다.\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.762667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>1</td>\n",
       "      <td>나비를 잡는 아버지</td>\n",
       "      <td>100021_1492_1</td>\n",
       "      <td>나비를 잡는 아버지_ko_00001</td>\n",
       "      <td>es</td>\n",
       "      <td>studio</td>\n",
       "      <td>100125</td>\n",
       "      <td>F</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>100125</td>\n",
       "      <td>Bau escuchó la canción por un momento.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.482667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-11-22</td>\n",
       "      <td>1</td>\n",
       "      <td>빨강머리 앤</td>\n",
       "      <td>100021_2763_1</td>\n",
       "      <td>빨강머리 앤 2 에이번리 이야기(2_5)_ko_00014</td>\n",
       "      <td>es</td>\n",
       "      <td>studio</td>\n",
       "      <td>100353</td>\n",
       "      <td>F</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>100353</td>\n",
       "      <td>Davey gritó en voz alta mientras lloraba.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.845533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-11-10</td>\n",
       "      <td>1</td>\n",
       "      <td>빨강머리 앤</td>\n",
       "      <td>100019_3056_1</td>\n",
       "      <td>빨강머리 앤 4 바람의 포퓰러 집 이야기 (1_5)_ko_00013</td>\n",
       "      <td>en</td>\n",
       "      <td>studio</td>\n",
       "      <td>100564</td>\n",
       "      <td>F</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>100564</td>\n",
       "      <td>\"She smuggles them in from the town library...\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.869333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  typeInfo--script--domain typeInfo--script--topic  \\\n",
       "0  2022-11-25                         1                  빨강머리 앤   \n",
       "1  2022-11-25                         1                  빨강머리 앤   \n",
       "2  2022-11-10                         1                  빨강머리 앤   \n",
       "3  2022-12-02                         1                  빨강머리 앤   \n",
       "4  2023-01-10                         5                     통계법   \n",
       "5  2022-12-02                         1                  빨강머리 앤   \n",
       "6  2022-11-30                         1                  빨강머리 앤   \n",
       "7  2022-10-06                         1              나비를 잡는 아버지   \n",
       "8  2022-11-22                         1                  빨강머리 앤   \n",
       "9  2022-11-10                         1                  빨강머리 앤   \n",
       "\n",
       "  typeInfo--script--scriptNumber       typeInfo--script--scriptFileName  \\\n",
       "0                  100021_3077_1  빨강머리 앤 4 바람의 포퓰러 집 이야기 (1_5)_ko_00003   \n",
       "1                  100020_2898_1   빨강머리 앤 3 레드먼드 이야기 (12장_20장)_ko_00031   \n",
       "2                  100020_2811_1        빨강머리 앤 2 에이번리 이야기(1_5)_ko_00002   \n",
       "3                  100019_2802_1        빨강머리 앤 2 에이번리 이야기(3_5)_ko_00025   \n",
       "4                  100019_1416_1                                통계법의 이해   \n",
       "5                  100021_2666_1   빨강머리 앤 1 초록지붕 집 이야기 (1장_5장)_ko_00021   \n",
       "6                  100018_2704_1        빨강머리 앤 2 에이번리 이야기(2_5)_ko_00003   \n",
       "7                  100021_1492_1                    나비를 잡는 아버지_ko_00001   \n",
       "8                  100021_2763_1        빨강머리 앤 2 에이번리 이야기(2_5)_ko_00014   \n",
       "9                  100019_3056_1  빨강머리 앤 4 바람의 포퓰러 집 이야기 (1_5)_ko_00013   \n",
       "\n",
       "  typeInfo--language typeInfo--place  typeInfo--speaker--speakerId  \\\n",
       "0                 es          studio                        100137   \n",
       "1                 jp          studio                        100351   \n",
       "2                 jp          studio                        100166   \n",
       "3                 en          studio                        100564   \n",
       "4                 en          studio                        100233   \n",
       "5                 es          studio                        100597   \n",
       "6                 ko          studio                        100659   \n",
       "7                 es          studio                        100125   \n",
       "8                 es          studio                        100353   \n",
       "9                 en          studio                        100564   \n",
       "\n",
       "  typeInfo--speaker--gender  typeInfo--speaker--age  dialogs--textNumber  \\\n",
       "0                         F                      27                    1   \n",
       "1                         F                      39                    1   \n",
       "2                         F                      51                    1   \n",
       "3                         F                      21                    1   \n",
       "4                         F                      27                    1   \n",
       "5                         F                      30                    1   \n",
       "6                         F                      27                    1   \n",
       "7                         F                      28                    1   \n",
       "8                         F                      23                    1   \n",
       "9                         F                      21                    1   \n",
       "\n",
       "   dialogs--speakerId                                      dialogs--text  \\\n",
       "0              100137          Siempre han gobernado el gallinero aquí..   \n",
       "1              100351                              なぜ神様が彼らを創造されたのか分からない。   \n",
       "2              100166                         \"背も小さく、太っていて、しかもハゲだったからだ。\"   \n",
       "3              100564                              Anne said vehemently.   \n",
       "4              100233  Statistics Korea defines it with six dimension...   \n",
       "5              100597                              Sí, lo llamaré Bonny.   \n",
       "6              100659                    \"앤이 좋은 일을 가르칠 기회를 포착하고 얼른 말했다.\"   \n",
       "7              100125             Bau escuchó la canción por un momento.   \n",
       "8              100353          Davey gritó en voz alta mientras lloraba.   \n",
       "9              100564    \"She smuggles them in from the town library...\"   \n",
       "\n",
       "   dialogs--startTime  dialogs--endTime  \n",
       "0                 0.0          4.210667  \n",
       "1                 0.0          4.040000  \n",
       "2                 0.0          4.488000  \n",
       "3                 0.0          2.674667  \n",
       "4                 0.0         17.416000  \n",
       "5                 0.0          3.144000  \n",
       "6                 0.0          3.762667  \n",
       "7                 0.0          2.482667  \n",
       "8                 0.0          3.845533  \n",
       "9                 0.0          3.869333  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1305730\n",
      "163218\n"
     ]
    }
   ],
   "source": [
    "df_71524_train, df_71524_eval = get_train_eval_df(71524)\n",
    "df_71524_train = df_71524_train.sort_values('dialogs--textNumber').reset_index(drop=True)\n",
    "df_71524_eval = df_71524_eval.sort_values('dialogs--textNumber').reset_index(drop=True)\n",
    "display(df_71524_train.head(10))\n",
    "print(len(df_71524_train))\n",
    "print(len(df_71524_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3395\n",
      "3387\n"
     ]
    }
   ],
   "source": [
    "print(len(df_71524_train['typeInfo--script--scriptFileName'].unique()))\n",
    "print(len(df_71524_eval['typeInfo--script--scriptFileName'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def pair_kojp(df):\n",
    "    \"\"\"\n",
    "    (1) typeInfo--script--scriptFileName의 unique list를 만들기\n",
    "    (2) 같은 scriptFileName을 가진 데이터 중, 같은 dialogs--textNumber를 가진 데이터, 그 중에서도 typeInfo--language가 ko, jp인 데이터를 찾아서 pair하기\n",
    "    (3) 각각을 ko_list와 jp_list로 반환\n",
    "    \"\"\"\n",
    "    script_list = df['typeInfo--script--scriptFileName'].unique()\n",
    "    ko_list, jp_list = [], []\n",
    "    for script in tqdm(script_list):\n",
    "        script_df = df[df['typeInfo--script--scriptFileName'] == script]\n",
    "        ko_df = script_df[script_df['typeInfo--language'] == 'ko']\n",
    "        jp_df = script_df[script_df['typeInfo--language'] == 'jp']\n",
    "        for (_, ko), (_, jp) in zip(ko_df.iterrows(), jp_df.iterrows()):\n",
    "            if ko['dialogs--textNumber'] == jp['dialogs--textNumber']:\n",
    "                ko_list.append(ko['dialogs--text'])\n",
    "                jp_list.append(jp['dialogs--text'])\n",
    "    return ko_list, jp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3395/3395 [04:48<00:00, 11.76it/s]\n"
     ]
    }
   ],
   "source": [
    "ko_list_71524_train, jp_list_71524_train = pair_kojp(df_71524_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"그 사람들이 예전부터 이 일대에서 방귀깨나 뀌는 사람들이거든요...\"',\n",
       " '\"그리고 채티 아주머니한테 상처 주면 안 돼요, 알았죠?\"',\n",
       " '\"그치는 마음이 너무 여려서 별거 아닌 일에도 툭하면 상처를 받거든요.\"']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['その人たちが昔からこの一帯で影響力のある 人たちなんですよ。',\n",
       " 'そして、チャティおばあちゃんを傷つけてはいけません、わかりましたか？',\n",
       " 'そいつは、こころがあまりにも弱すぎて、ささいなことでもよく傷つくんです。']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ko_list_71524_train[:3])\n",
    "display(jp_list_71524_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 120319 new data from aihub-71524: 4094182 -> 4214501\n"
     ]
    }
   ],
   "source": [
    "len_old_ko = len(df_ja['ko'])\n",
    "df_ja['ko'].extend(ko_list_71524_train)\n",
    "df_ja['ja'].extend(jp_list_71524_train)\n",
    "df_ja['source'].extend(['aihub-71524'] * len(ko_list_71524_train))\n",
    "len_new_ko = len(df_ja['ko'])\n",
    "print(f'Added {len_new_ko - len_old_ko} new data from aihub-71524: {len_old_ko} -> {len_new_ko}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01_dataset--1_identifier</th>\n",
       "      <th>01_dataset--2_name</th>\n",
       "      <th>01_dataset--3_src_path</th>\n",
       "      <th>01_dataset--4_label_path</th>\n",
       "      <th>01_dataset--5_category</th>\n",
       "      <th>01_dataset--6_type</th>\n",
       "      <th>01_dataset--7_copyright</th>\n",
       "      <th>02_srcinfo--1_id</th>\n",
       "      <th>02_srcinfo--2_title</th>\n",
       "      <th>02_srcinfo--3_language</th>\n",
       "      <th>04_contentinfo--4_storyline</th>\n",
       "      <th>05_speakerinfo--1_id</th>\n",
       "      <th>05_speakerinfo--2_gender</th>\n",
       "      <th>07_text--1_text</th>\n",
       "      <th>08_translation--1_text</th>\n",
       "      <th>08_translation--2_language</th>\n",
       "      <th>06_ttsinfo--1_src_path</th>\n",
       "      <th>06_ttsinfo--2_duration</th>\n",
       "      <th>06_ttsinfo--3_speaker_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-1-11-036</td>\n",
       "      <td>방송콘텐츠 한국어-아시아어 번역 말뭉치</td>\n",
       "      <td>11-2/source/L01/C05/C03093/U0535480.txt</td>\n",
       "      <td>11-2/labels/L01_L02/C05/C03093/U0535480.json</td>\n",
       "      <td>C05</td>\n",
       "      <td>텍스트</td>\n",
       "      <td>Y</td>\n",
       "      <td>C03093</td>\n",
       "      <td>트레킹노트 세상을 걷다(222회)</td>\n",
       "      <td>한국어</td>\n",
       "      <td>[푸른 바람이 분다] 영남 알프스 / 소백산국립공원 / 대구 비슬산</td>\n",
       "      <td>S30930000</td>\n",
       "      <td>남</td>\n",
       "      <td>어리석은 욕심에 한 조각 떼어간들 그게 가진 게 될까요?</td>\n",
       "      <td>因为愚蠢的欲望，把野地撕掉一块，这能成为拥有的吗？</td>\n",
       "      <td>중국어</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  01_dataset--1_identifier     01_dataset--2_name  \\\n",
       "0            2022-1-11-036  방송콘텐츠 한국어-아시아어 번역 말뭉치   \n",
       "\n",
       "                    01_dataset--3_src_path  \\\n",
       "0  11-2/source/L01/C05/C03093/U0535480.txt   \n",
       "\n",
       "                       01_dataset--4_label_path 01_dataset--5_category  \\\n",
       "0  11-2/labels/L01_L02/C05/C03093/U0535480.json                    C05   \n",
       "\n",
       "  01_dataset--6_type 01_dataset--7_copyright 02_srcinfo--1_id  \\\n",
       "0                텍스트                       Y           C03093   \n",
       "\n",
       "  02_srcinfo--2_title 02_srcinfo--3_language  \\\n",
       "0  트레킹노트 세상을 걷다(222회)                    한국어   \n",
       "\n",
       "             04_contentinfo--4_storyline 05_speakerinfo--1_id  \\\n",
       "0  [푸른 바람이 분다] 영남 알프스 / 소백산국립공원 / 대구 비슬산            S30930000   \n",
       "\n",
       "  05_speakerinfo--2_gender                  07_text--1_text  \\\n",
       "0                        남  어리석은 욕심에 한 조각 떼어간들 그게 가진 게 될까요?   \n",
       "\n",
       "      08_translation--1_text 08_translation--2_language  \\\n",
       "0  因为愚蠢的欲望，把野地撕掉一块，这能成为拥有的吗？                        중국어   \n",
       "\n",
       "  06_ttsinfo--1_src_path  06_ttsinfo--2_duration 06_ttsinfo--3_speaker_id  \n",
       "0                    NaN                     NaN                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652962\n",
      "167425\n"
     ]
    }
   ],
   "source": [
    "df_71591_train, df_71591_eval = get_train_eval_df(71591)\n",
    "display(df_71591_train.head(1))\n",
    "print(len(df_71591_train))\n",
    "print(len(df_71591_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['한국어', '일본어', '중국어'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['중국어', '일본어', '몽골어', '힌디어', '한국어', '대만어'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_71591_train['02_srcinfo--3_language'].unique())\n",
    "display(df_71591_train['08_translation--2_language'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA2KO: 1036 / 0\n",
      "KO2JA: 112436 / 0\n",
      "ZH2KO: 548 / 0\n",
      "KO2ZH: 380330 / 0\n"
     ]
    }
   ],
   "source": [
    "ja2ko_71591_train = df_71591_train[(df_71591_train['02_srcinfo--3_language'] == '일본어') & (df_71591_train['08_translation--2_language'] == '한국어')]\n",
    "ja2ko_71591_eval = df_71591_eval[(df_71591_eval['02_srcinfo--3_language'] == '일본어') & (df_71591_eval['08_translation--2_language'] == '한국어')]\n",
    "ko2ja_71591_train = df_71591_train[(df_71591_train['02_srcinfo--3_language'] == '한국어') & (df_71591_train['08_translation--2_language'] == '일본어')]\n",
    "ko2ja_71591_eval = df_71591_eval[(df_71591_eval['02_srcinfo--3_language'] == '한국어') & (df_71591_eval['08_translation--2_language'] == '일본어')]\n",
    "\n",
    "zh2ko_71591_train = df_71591_train[(df_71591_train['02_srcinfo--3_language'] == '중국어') & (df_71591_train['08_translation--2_language'] == '한국어')]\n",
    "zh2ko_71591_eval = df_71591_eval[(df_71591_eval['02_srcinfo--3_language'] == '중국어') & (df_71591_eval['08_translation--2_language'] == '한국어')]\n",
    "ko2zh_71591_train = df_71591_train[(df_71591_train['02_srcinfo--3_language'] == '한국어') & (df_71591_train['08_translation--2_language'] == '중국어')]\n",
    "ko2zh_71591_eval = df_71591_eval[(df_71591_eval['02_srcinfo--3_language'] == '한국어') & (df_71591_eval['08_translation--2_language'] == '중국어')]\n",
    "\n",
    "print(f\"JA2KO: {len(ja2ko_71591_train)} / {len(ja2ko_71591_eval)}\")\n",
    "print(f\"KO2JA: {len(ko2ja_71591_train)} / {len(ko2ja_71591_eval)}\")\n",
    "print(f\"ZH2KO: {len(zh2ko_71591_train)} / {len(zh2ko_71591_eval)}\")\n",
    "print(f\"KO2ZH: {len(ko2zh_71591_train)} / {len(ko2zh_71591_eval)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1036 new data from aihub-71591: 4214501 -> 4215537\n",
      "Added 0 new data from aihub-71591: 4215537 -> 4215537\n",
      "Added 112436 new data from aihub-71591: 4215537 -> 4327973\n",
      "Added 0 new data from aihub-71591: 4327973 -> 4327973\n"
     ]
    }
   ],
   "source": [
    "df_ja = add_new_data(df_ja, ja2ko_71591_train, 'ja', '08_translation--1_text', '07_text--1_text', 71591)\n",
    "df_ja = add_new_data(df_ja, ja2ko_71591_eval, 'ja', '08_translation--1_text', '07_text--1_text', 71591)\n",
    "df_ja = add_new_data(df_ja, ko2ja_71591_train, 'ja', '07_text--1_text', '08_translation--1_text', 71591)\n",
    "df_ja = add_new_data(df_ja, ko2ja_71591_eval, 'ja', '07_text--1_text', '08_translation--1_text', 71591)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_891697/3996682252.py:5: DtypeWarning: Columns (0,3,4,5,6,7,8,9,10,11,14,15,16,18,19,20,21,23,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(train_path)\n",
      "/tmp/ipykernel_891697/3996682252.py:6: DtypeWarning: Columns (12,13,14,15,16,17,18,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  eval_df = pd.read_csv(eval_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sn</th>\n",
       "      <th>domain</th>\n",
       "      <th>year</th>\n",
       "      <th>from</th>\n",
       "      <th>source_sentence</th>\n",
       "      <th>mt_sentence</th>\n",
       "      <th>target_sentence</th>\n",
       "      <th>mt_service</th>\n",
       "      <th>source_language_code</th>\n",
       "      <th>target_language_code</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>similarity</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>tags--tag</th>\n",
       "      <th>tags--value</th>\n",
       "      <th>tags--position</th>\n",
       "      <th>source_word</th>\n",
       "      <th>target_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009022110030</td>\n",
       "      <td>농학</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>KCI_FI002842110</td>\n",
       "      <td>다짐도별 일축압축강도는 ML 시료 &gt; SC 시료 &gt; SM 시료의 순으로 나타났다.</td>\n",
       "      <td>各压实度的单轴抗压强度依次为ML试样&gt;SC试样&gt;SM试样。</td>\n",
       "      <td>各压实度的单轴抗压强度依次为ML试样&gt;SC试样&gt;SM试样。</td>\n",
       "      <td>google</td>\n",
       "      <td>ko</td>\n",
       "      <td>zh</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              sn domain    year             from  \\\n",
       "0  1009022110030     농학  2022.0  KCI_FI002842110   \n",
       "\n",
       "                                 source_sentence  \\\n",
       "0  다짐도별 일축압축강도는 ML 시료 > SC 시료 > SM 시료의 순으로 나타났다.   \n",
       "\n",
       "                     mt_sentence                target_sentence mt_service  \\\n",
       "0  各压实度的单轴抗压强度依次为ML试样>SC试样>SM试样。  各压实度的单轴抗压强度依次为ML试样>SC试样>SM试样。     google   \n",
       "\n",
       "  source_language_code target_language_code  ... sentence1 sentence2  \\\n",
       "0                   ko                   zh  ...       NaN       NaN   \n",
       "\n",
       "   similarity  text language tags--tag tags--value  tags--position  \\\n",
       "0         NaN   NaN      NaN       NaN         NaN             NaN   \n",
       "\n",
       "  source_word target_word  \n",
       "0         NaN         NaN  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2362811\n",
      "291137\n"
     ]
    }
   ],
   "source": [
    "df_71593_train, df_71593_eval = get_train_eval_df(71593)\n",
    "display(df_71593_train.head(1))\n",
    "print(len(df_71593_train))\n",
    "print(len(df_71593_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ko', nan], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['zh', 'ja', 'en', nan], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_71593_train['source_language_code'].unique())\n",
    "display(df_71593_train['target_language_code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA: 326065 / 40749\n",
      "ZH: 328900 / 41102\n"
     ]
    }
   ],
   "source": [
    "ja_71593_train = df_71593_train[(df_71593_train['source_language_code'] == 'ko') & (df_71593_train['target_language_code'] == 'ja')]\n",
    "ja_71593_eval = df_71593_eval[(df_71593_eval['source_language_code'] == 'ko') & (df_71593_eval['target_language_code'] == 'ja')]\n",
    "zh_71593_train = df_71593_train[(df_71593_train['source_language_code'] == 'ko') & (df_71593_train['target_language_code'] == 'zh')]\n",
    "zh_71593_eval = df_71593_eval[(df_71593_eval['source_language_code'] == 'ko') & (df_71593_eval['target_language_code'] == 'zh')]\n",
    "\n",
    "print(f\"JA: {len(ja_71593_train)} / {len(ja_71593_eval)}\")\n",
    "print(f\"ZH: {len(zh_71593_train)} / {len(zh_71593_eval)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 326065 new data from aihub-71593: 4327973 -> 4654038\n",
      "Added 40749 new data from aihub-71593: 4654038 -> 4694787\n"
     ]
    }
   ],
   "source": [
    "df_ja = add_new_data(df_ja, ja_71593_train, 'ja', 'source_sentence', 'target_sentence', 71593)\n",
    "df_ja = add_new_data(df_ja, ja_71593_eval, 'ja', 'source_sentence', 'target_sentence', 71593)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 328900 new data from aihub-71593: 5785715 -> 6114615\n",
      "Added 41102 new data from aihub-71593: 6114615 -> 6155717\n"
     ]
    }
   ],
   "source": [
    "df_zh = add_new_data(df_zh, zh_71593_train, 'zh', 'source_sentence', 'target_sentence', 71593)\n",
    "df_zh = add_new_data(df_zh, zh_71593_eval, 'zh', 'source_sentence', 'target_sentence', 71593)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4694787\n",
      "4694787\n",
      "4694787\n"
     ]
    }
   ],
   "source": [
    "print(len(df_ja['ko']))\n",
    "print(len(df_ja['ja']))\n",
    "print(len(df_ja['source']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>ja</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>본 고안의 목적은 고정력 스프링에 의해 파손이 발생하지 않는 보강된 인너도어 샤프트...</td>\n",
       "      <td>本考案の目的は、固定力スプリングによる破損が発生しない補強されたインナードアシャフトを提供す...</td>\n",
       "      <td>aihub-127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>본 발명은 컴팩트한 구성에 의해 부품의 펀칭과 흡착이송이 가능하도록 구비되어 제조공...</td>\n",
       "      <td>本発明は、コンパクトな構成により部品のパンチングと吸着移送ができるように具備され、製造工程上...</td>\n",
       "      <td>aihub-127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>본 발명은 휴대단말기용 메탈케이스에 관한 것으로서, 특히 금속으로 이루어진 휴대단말...</td>\n",
       "      <td>本発明は、携帯端末機用メタルケースの製造方法に関するもので、特に金属からなる携帯端末機のケー...</td>\n",
       "      <td>aihub-127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그리고 상기 인덕턴스의 등가 저항값이 변화됨에 따라 인덕턴스의 통하여 흐르는 전류가...</td>\n",
       "      <td>そして、上記のインダクタンスの等価抵抗値が変化することによって、インダクタンスを通じて流れる...</td>\n",
       "      <td>aihub-127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>본 고안은 인쇄회로기판의 착탈 고정 장치에 관한 것이다.</td>\n",
       "      <td>本考案は、印刷回路基板の着脱固定装置に関するものだ。</td>\n",
       "      <td>aihub-127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ko  \\\n",
       "0  본 고안의 목적은 고정력 스프링에 의해 파손이 발생하지 않는 보강된 인너도어 샤프트...   \n",
       "1  본 발명은 컴팩트한 구성에 의해 부품의 펀칭과 흡착이송이 가능하도록 구비되어 제조공...   \n",
       "2  본 발명은 휴대단말기용 메탈케이스에 관한 것으로서, 특히 금속으로 이루어진 휴대단말...   \n",
       "3  그리고 상기 인덕턴스의 등가 저항값이 변화됨에 따라 인덕턴스의 통하여 흐르는 전류가...   \n",
       "4                    본 고안은 인쇄회로기판의 착탈 고정 장치에 관한 것이다.   \n",
       "\n",
       "                                                  ja     source  \n",
       "0  本考案の目的は、固定力スプリングによる破損が発生しない補強されたインナードアシャフトを提供す...  aihub-127  \n",
       "1  本発明は、コンパクトな構成により部品のパンチングと吸着移送ができるように具備され、製造工程上...  aihub-127  \n",
       "2  本発明は、携帯端末機用メタルケースの製造方法に関するもので、特に金属からなる携帯端末機のケー...  aihub-127  \n",
       "3  そして、上記のインダクタンスの等価抵抗値が変化することによって、インダクタンスを通じて流れる...  aihub-127  \n",
       "4                         本考案は、印刷回路基板の着脱固定装置に関するものだ。  aihub-127  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4694787\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>zh</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>본 발명은 플러그를 통해 공급되는 주전원의 주파수 특성을 검출하여 주파수의 제로전위...</td>\n",
       "      <td>本发明可以检测通过插头供应的主电源的频率特性,并为使从接近该频率零电位的上升电位连接到继电器...</td>\n",
       "      <td>aihub-128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>본 발명은 셀룰라폰에 관한 것으로, 셀룰라폰의 이동으로 소정시간이상 서어비스 지역을...</td>\n",
       "      <td>本发明是关于蜂窝电话的发明,当由于手机的移动而离开服务区域超过预定时间时自动关闭电源,并以预...</td>\n",
       "      <td>aihub-128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>또한, 셀 멀티 카피 기능을 활용하기 위한 자원 관리를 수행하지 않기 때문에 하나의...</td>\n",
       "      <td>另外,因为不执行利用单元多功能复制的资源管理,所以存在无法向多个用户提供同一个音调的缺点。</td>\n",
       "      <td>aihub-128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>엔코더가 부착된 모터의 경우 회전량과 회전 속도를 측정할 수 있다.</td>\n",
       "      <td>安装有编码器的电动机,可以测量回转量和回转速度。</td>\n",
       "      <td>aihub-128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>본 발명은 반도체 스퍼터링(Sputtering)장비에 있어서, 진공 펌프의 모터를 ...</td>\n",
       "      <td>本发明是关于一种用于保护真空泵的电动机,免受半导体溅射(Sputtering)设备中的过电流...</td>\n",
       "      <td>aihub-128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ko  \\\n",
       "0  본 발명은 플러그를 통해 공급되는 주전원의 주파수 특성을 검출하여 주파수의 제로전위...   \n",
       "1  본 발명은 셀룰라폰에 관한 것으로, 셀룰라폰의 이동으로 소정시간이상 서어비스 지역을...   \n",
       "2  또한, 셀 멀티 카피 기능을 활용하기 위한 자원 관리를 수행하지 않기 때문에 하나의...   \n",
       "3              엔코더가 부착된 모터의 경우 회전량과 회전 속도를 측정할 수 있다.   \n",
       "4  본 발명은 반도체 스퍼터링(Sputtering)장비에 있어서, 진공 펌프의 모터를 ...   \n",
       "\n",
       "                                                  zh     source  \n",
       "0  本发明可以检测通过插头供应的主电源的频率特性,并为使从接近该频率零电位的上升电位连接到继电器...  aihub-128  \n",
       "1  本发明是关于蜂窝电话的发明,当由于手机的移动而离开服务区域超过预定时间时自动关闭电源,并以预...  aihub-128  \n",
       "2      另外,因为不执行利用单元多功能复制的资源管理,所以存在无法向多个用户提供同一个音调的缺点。  aihub-128  \n",
       "3                           安装有编码器的电动机,可以测量回转量和回转速度。  aihub-128  \n",
       "4  本发明是关于一种用于保护真空泵的电动机,免受半导体溅射(Sputtering)设备中的过电流...  aihub-128  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6155717\n"
     ]
    }
   ],
   "source": [
    "df_ja = pd.DataFrame(df_ja)\n",
    "df_zh = pd.DataFrame(df_zh)\n",
    "\n",
    "display(df_ja.head())\n",
    "print(len(df_ja))\n",
    "display(df_zh.head())\n",
    "print(len(df_zh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ja.to_csv('./integrated_total/ja_total.csv')\n",
    "df_zh.to_csv('./integrated_total/zh_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ja = pd.read_csv('./integrated_total/ja_total.csv')\n",
    "df_zh = pd.read_csv('./integrated_total/zh_total.csv')\n",
    "\n",
    "ja_len_old = len(df_ja)\n",
    "zh_len_old = len(df_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA: 4694787 -> 4694777: 10 removed (NaN)\n",
      "ZH: 6155717 -> 6155709: 8 removed (NaN)\n"
     ]
    }
   ],
   "source": [
    "df_ja = df_ja.dropna()\n",
    "df_zh = df_zh.dropna()\n",
    "\n",
    "print(f\"JA: {ja_len_old} -> {len(df_ja)}: {ja_len_old - len(df_ja)} removed (NaN)\")\n",
    "print(f\"ZH: {zh_len_old} -> {len(df_zh)}: {zh_len_old - len(df_zh)} removed (NaN)\")\n",
    "ja_len_old = len(df_ja)\n",
    "zh_len_old = len(df_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA: 4694777 -> 4339465: 355312 removed (duplicates)\n",
      "ZH: 6155709 -> 5934596: 221113 removed (duplicates)\n"
     ]
    }
   ],
   "source": [
    "df_ja = df_ja.drop_duplicates(subset=['ko', 'ja'])\n",
    "df_zh = df_zh.drop_duplicates(subset=['ko', 'zh'])\n",
    "\n",
    "print(f\"JA: {ja_len_old} -> {len(df_ja)}: {ja_len_old - len(df_ja)} removed (duplicates)\")\n",
    "print(f\"ZH: {zh_len_old} -> {len(df_zh)}: {zh_len_old - len(df_zh)} removed (duplicates)\")\n",
    "ja_len_old = len(df_ja)\n",
    "zh_len_old = len(df_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ja.to_csv('./integrated_total/ja_large.csv', index=False)\n",
    "df_zh.to_csv('./integrated_total/zh_large.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ja_large = df_ja.copy()\n",
    "df_ja_base = df_ja.sample(n=1000000, random_state=42)\n",
    "df_ja_small = df_ja_base.sample(n=100000, random_state=42)\n",
    "\n",
    "# df_ja_base.to_csv('./integrated_total/ja_base.csv', index=False)\n",
    "# df_ja_small.to_csv('./integrated_total/ja_small.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zh_large = df_zh.copy()\n",
    "df_zh_base = df_zh.sample(n=1000000, random_state=42)\n",
    "df_zh_small = df_zh_base.sample(n=100000, random_state=42)\n",
    "\n",
    "# df_zh_base.to_csv('./integrated_total/zh_base.csv', index=False)\n",
    "# df_zh_small.to_csv('./integrated_total/zh_small.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-127      1350000\n",
       "aihub-546      1343763\n",
       "aihub-71263     887425\n",
       "aihub-71593     212119\n",
       "aihub-71493     124142\n",
       "aihub-71524     120168\n",
       "aihub-71591     112978\n",
       "aihub-71496      81449\n",
       "aihub-71498      80431\n",
       "aihub-71411      26990\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-546      1349470\n",
       "aihub-71262    1326837\n",
       "aihub-129      1170000\n",
       "aihub-128      1170000\n",
       "aihub-71263     367921\n",
       "aihub-71593     212268\n",
       "aihub-71493     146317\n",
       "aihub-71496      84419\n",
       "aihub-71498      80375\n",
       "aihub-71411      26989\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-127      310654\n",
       "aihub-546      309964\n",
       "aihub-71263    204427\n",
       "aihub-71593     48786\n",
       "aihub-71493     28407\n",
       "aihub-71524     27702\n",
       "aihub-71591     26160\n",
       "aihub-71496     18878\n",
       "aihub-71498     18666\n",
       "aihub-71411      6356\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-546      227238\n",
       "aihub-71262    223537\n",
       "aihub-128      197481\n",
       "aihub-129      197059\n",
       "aihub-71263     61972\n",
       "aihub-71593     36122\n",
       "aihub-71493     24590\n",
       "aihub-71496     14129\n",
       "aihub-71498     13316\n",
       "aihub-71411      4556\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-546      30975\n",
       "aihub-127      30895\n",
       "aihub-71263    20497\n",
       "aihub-71593     4992\n",
       "aihub-71493     2855\n",
       "aihub-71524     2699\n",
       "aihub-71591     2679\n",
       "aihub-71498     1898\n",
       "aihub-71496     1873\n",
       "aihub-71411      637\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-546      22797\n",
       "aihub-71262    22105\n",
       "aihub-129      19949\n",
       "aihub-128      19678\n",
       "aihub-71263     6095\n",
       "aihub-71593     3614\n",
       "aihub-71493     2480\n",
       "aihub-71496     1450\n",
       "aihub-71498     1375\n",
       "aihub-71411      457\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_ja_large['source'].value_counts())\n",
    "display(df_zh_large['source'].value_counts())\n",
    "\n",
    "display(df_ja_base['source'].value_counts())\n",
    "display(df_zh_base['source'].value_counts())\n",
    "\n",
    "display(df_ja_small['source'].value_counts())\n",
    "display(df_zh_small['source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_large = df_ja_large.copy()\n",
    "zh_large = df_zh_large.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_remove(df, n, sources):\n",
    "    sample_df_list = []\n",
    "    remaining_df_list = []\n",
    "    \n",
    "    for source in sources:\n",
    "        source_df = df[df['source'] == source]\n",
    "        sample_df = source_df.sample(n=n, random_state=42)\n",
    "        remaining_df = source_df.drop(sample_df.index)\n",
    "        \n",
    "        sample_df_list.append(sample_df)\n",
    "        remaining_df_list.append(remaining_df)\n",
    "    \n",
    "    return pd.concat(sample_df_list), pd.concat(remaining_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA: 4327465 train / 10000 eval / 2000 test\n",
      "ZH: 5922596 train / 10000 eval / 2000 test\n"
     ]
    }
   ],
   "source": [
    "ja_sources = ja_large['source'].unique()\n",
    "zh_sources = zh_large['source'].unique()\n",
    "\n",
    "ja_test, ja_large = sample_and_remove(ja_large, 200, ja_sources)\n",
    "zh_test, zh_large = sample_and_remove(zh_large, 200, zh_sources)\n",
    "\n",
    "ja_eval, ja_large = sample_and_remove(ja_large, 1000, ja_sources)\n",
    "zh_eval, zh_large = sample_and_remove(zh_large, 1000, zh_sources)\n",
    "\n",
    "print(f\"JA: {len(ja_large)} train / {len(ja_eval)} eval / {len(ja_test)} test\")\n",
    "print(f\"ZH: {len(zh_large)} train / {len(zh_eval)} eval / {len(zh_test)} test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_base = ja_large.sample(n=1000000, random_state=42)\n",
    "zh_base = zh_large.sample(n=1000000, random_state=42)\n",
    "\n",
    "ja_small = ja_base.sample(n=100000, random_state=42)\n",
    "zh_small = zh_base.sample(n=100000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_large.to_csv('./integrated_total/ja_large_train.csv', index=False)\n",
    "zh_large.to_csv('./integrated_total/zh_large_train.csv', index=False)\n",
    "ja_base.to_csv('./integrated_total/ja_base_train.csv', index=False)\n",
    "zh_base.to_csv('./integrated_total/zh_base_train.csv', index=False)\n",
    "ja_small.to_csv('./integrated_total/ja_small_train.csv', index=False)\n",
    "zh_small.to_csv('./integrated_total/zh_small_train.csv', index=False)\n",
    "\n",
    "ja_eval.to_csv('./integrated_total/ja_eval.csv', index=False)\n",
    "zh_eval.to_csv('./integrated_total/zh_eval.csv', index=False)\n",
    "\n",
    "ja_test.to_csv('./integrated_total/ja_test.csv', index=False)\n",
    "zh_test.to_csv('./integrated_total/zh_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4327465, 5922596)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ja_large), len(zh_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_name = 'traintogpb/aihub-flores-koen-integrated-prime-base-300k'\n",
    "ja_name = 'traintogpb/aihub-koja-integrated-prime-base-300k'\n",
    "zh_name = 'traintogpb/aihub-kozh-integrated-prime-base-300k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_base_name = 'traintogpb/aihub-koen-translation-integrated-base-1m'\n",
    "ja_base_name = 'traintogpb/aihub-koja-translation-integrated-base-1m'\n",
    "zh_base_name = 'traintogpb/aihub-kozh-translation-integrated-base-1m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5afc1cbe154c65bbca30db3d48a8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN dataset: 296809 train / 1000 validation / 1000 test\n",
      "JA dataset: 300000 train / 10000 validation / 2000 test\n",
      "ZH dataset: 300000 train / 10000 validation / 2000 test\n"
     ]
    }
   ],
   "source": [
    "en = load_dataset(en_name)\n",
    "ja = load_dataset(ja_name)\n",
    "zh = load_dataset(zh_name)\n",
    "\n",
    "print(f\"EN dataset: {len(en['train'])} train / {len(en['validation'])} validation / {len(en['test'])} test\")\n",
    "print(f\"JA dataset: {len(ja['train'])} train / {len(ja['validation'])} validation / {len(ja['test'])} test\")\n",
    "print(f\"ZH dataset: {len(zh['train'])} train / {len(zh['validation'])} validation / {len(zh['test'])} test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN base dataset: 833321 train\n",
      "JA base dataset: 1000000 train\n",
      "ZH base dataset: 1000000 train\n"
     ]
    }
   ],
   "source": [
    "en_base = load_dataset(en_base_name, split='train')\n",
    "ja_base = load_dataset(ja_base_name, split='train')\n",
    "zh_base = load_dataset(zh_base_name, split='train')\n",
    "\n",
    "print(f\"EN base dataset: {len(en_base)} train\")\n",
    "print(f\"JA base dataset: {len(ja_base)} train\")\n",
    "print(f\"ZH base dataset: {len(zh_base)} train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko_xcomet</th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.513722</td>\n",
       "      <td>문재인 대통령이 국회 시정연설에서 전관예우 금지를 언급한 뒤 하루만에 나온 조치다.</td>\n",
       "      <td>The measure came out a day after President Moo...</td>\n",
       "      <td>aihub-111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ko_xcomet                                              ko  \\\n",
       "0  98.513722  문재인 대통령이 국회 시정연설에서 전관예우 금지를 언급한 뒤 하루만에 나온 조치다.   \n",
       "\n",
       "                                                  en     source  \n",
       "0  The measure came out a day after President Moo...  aihub-111  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko_xcomet</th>\n",
       "      <th>ko</th>\n",
       "      <th>ja</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>길 찾기가 너무 편해.</td>\n",
       "      <td>道を探すのがすごく楽だ。</td>\n",
       "      <td>aihub-546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ko_xcomet            ko            ja     source\n",
       "0      100.0  길 찾기가 너무 편해.  道を探すのがすごく楽だ。  aihub-546"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko_xcomet</th>\n",
       "      <th>ko</th>\n",
       "      <th>zh</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>DON은 장 상피세포가 염증인자를 분비하도록 유도하여 장염을 유발할 수 있다.</td>\n",
       "      <td>DON可诱导肠上皮细胞分泌炎症因子，从而引起肠道炎症。</td>\n",
       "      <td>aihub-71262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ko_xcomet                                           ko  \\\n",
       "0      100.0  DON은 장 상피세포가 염증인자를 분비하도록 유도하여 장염을 유발할 수 있다.   \n",
       "\n",
       "                            zh       source  \n",
       "0  DON可诱导肠上皮细胞分泌炎症因子，从而引起肠道炎症。  aihub-71262  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_train, en_eval, en_test = pd.DataFrame(en['train']), pd.DataFrame(en['validation']), pd.DataFrame(en['test'])\n",
    "ja_train, ja_eval, ja_test = pd.DataFrame(ja['train']), pd.DataFrame(ja['validation']), pd.DataFrame(ja['test'])\n",
    "zh_train, zh_eval, zh_test = pd.DataFrame(zh['train']), pd.DataFrame(zh['validation']), pd.DataFrame(zh['test'])\n",
    "\n",
    "en_train.columns = ['ko_xcomet', 'ko', 'en', 'source']\n",
    "\n",
    "display(en_train.head(1))\n",
    "display(ja_train.head(1))\n",
    "display(zh_train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지방세법 개정안에 따른 종합부동산세는 부과징수권자의 경우를 제외하고는 대부분 종전 ...</td>\n",
       "      <td>Comprehensive real estate tax according to the...</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ko  \\\n",
       "0  지방세법 개정안에 따른 종합부동산세는 부과징수권자의 경우를 제외하고는 대부분 종전 ...   \n",
       "\n",
       "                                                  en  source  \n",
       "0  Comprehensive real estate tax according to the...     125  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>ja</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>우리는 이 영화에서 함께 일해요.</td>\n",
       "      <td>私たちはこの映画で一緒に働きます。</td>\n",
       "      <td>aihub-546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ko                 ja     source\n",
       "0  우리는 이 영화에서 함께 일해요.  私たちはこの映画で一緒に働きます。  aihub-546"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>zh</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>하지만 4베이러, AAA공주님을 왜 찾으십니까?</td>\n",
       "      <td>不过四贝勒，找孙带格格有何要事吗。</td>\n",
       "      <td>aihub-71263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ko                 zh       source\n",
       "0  하지만 4베이러, AAA공주님을 왜 찾으십니까?  不过四贝勒，找孙带格格有何要事吗。  aihub-71263"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_base = pd.DataFrame(en_base)\n",
    "ja_base = pd.DataFrame(ja_base)\n",
    "zh_base = pd.DataFrame(zh_base)\n",
    "\n",
    "display(en_base.head(1))\n",
    "display(ja_base.head(1))\n",
    "display(zh_base.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-546      151404\n",
       "aihub-127       62446\n",
       "aihub-71263     44730\n",
       "aihub-71524      8864\n",
       "aihub-71593      8277\n",
       "aihub-71493      7709\n",
       "aihub-71496      5474\n",
       "aihub-71498      5469\n",
       "aihub-71591      4171\n",
       "aihub-71411      1456\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-546      134658\n",
       "aihub-128       52739\n",
       "aihub-129       40669\n",
       "aihub-71262     30682\n",
       "aihub-71263     17407\n",
       "aihub-71493      7862\n",
       "aihub-71593      6210\n",
       "aihub-71496      4361\n",
       "aihub-71498      4179\n",
       "aihub-71411      1233\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(en_train['source'].value_counts())\n",
    "display(ja_train['source'].value_counts())\n",
    "display(zh_train['source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(111, 107520),\n",
       "             (124, 108014),\n",
       "             (125, 108894),\n",
       "             (126, 128104),\n",
       "             (563, 28969),\n",
       "             (71265, 198471),\n",
       "             (71266, 106518),\n",
       "             (71382, 46831)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('aihub-127', 311445),\n",
       "             ('aihub-546', 310771),\n",
       "             ('aihub-71263', 204519),\n",
       "             ('aihub-71411', 5981),\n",
       "             ('aihub-71493', 28243),\n",
       "             ('aihub-71496', 18529),\n",
       "             ('aihub-71498', 18480),\n",
       "             ('aihub-71524', 27647),\n",
       "             ('aihub-71591', 25813),\n",
       "             ('aihub-71593', 48572)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('aihub-128', 197720),\n",
       "             ('aihub-129', 196823),\n",
       "             ('aihub-546', 227772),\n",
       "             ('aihub-71262', 223605),\n",
       "             ('aihub-71263', 61925),\n",
       "             ('aihub-71411', 4350),\n",
       "             ('aihub-71493', 24547),\n",
       "             ('aihub-71496', 14136),\n",
       "             ('aihub-71498', 13286),\n",
       "             ('aihub-71593', 35836)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "en_base_values = en_base['source'].value_counts().to_dict()\n",
    "ja_base_values = ja_base['source'].value_counts().to_dict()\n",
    "zh_base_values = zh_base['source'].value_counts().to_dict()\n",
    "\n",
    "en_base_values = OrderedDict(sorted(en_base_values.items()))\n",
    "ja_base_values = OrderedDict(sorted(ja_base_values.items()))\n",
    "zh_base_values = OrderedDict(sorted(zh_base_values.items()))\n",
    "\n",
    "display(en_base_values)\n",
    "display(ja_base_values)\n",
    "display(zh_base_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria_en = {\n",
    "    111: 10000,\n",
    "    124: 7500,\n",
    "    125: 10000,\n",
    "    126: 15000,\n",
    "    563: 5000,\n",
    "    71265: 30000,\n",
    "    71266: 7500,\n",
    "    71382: 15000,\n",
    "}\n",
    "criteria_ja = {\n",
    "    127: 13580,\n",
    "    546: 30000,\n",
    "    71263: 15000,\n",
    "    71411: 1456,\n",
    "    71493: 7709,\n",
    "    71496: 5474,\n",
    "    71498: 5469,\n",
    "    71524: 8864,\n",
    "    71591: 4171,\n",
    "    71593: 8277,\n",
    "}\n",
    "criteria_zh = {\n",
    "    128: 10000,\n",
    "    129: 16155,\n",
    "    546: 30000,\n",
    "    71262: 5000,\n",
    "    71263: 15000,\n",
    "    71411: 1233,\n",
    "    71493: 7862,\n",
    "    71496: 4361,\n",
    "    71498: 4179,\n",
    "    71593: 6210,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_top_n(df, criteria):\n",
    "    result = pd.DataFrame()\n",
    "    for source, count in criteria.items():\n",
    "        subset = df[df['source'] == f'aihub-{source}']\n",
    "        top_n_subset = subset.nlargest(count, 'ko_xcomet')\n",
    "        result = pd.concat([result, top_n_subset])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko_xcomet</th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100.0</td>\n",
       "      <td>3회 모두 꼭 참여해주셔야 하오니 사전에 일정 조율하셔서 신청해주시기 바랍니다.</td>\n",
       "      <td>You must participate in all three sessions, so...</td>\n",
       "      <td>aihub-111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>100.0</td>\n",
       "      <td>문제는 부모의 주관적인 판단이 개입될 여지가 많다는 점이다.</td>\n",
       "      <td>The problem is that there is much room for par...</td>\n",
       "      <td>aihub-111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>100.0</td>\n",
       "      <td>신규 가입자가 지난 1∼2월보다 30% 이상 증가한 셈이다.</td>\n",
       "      <td>It means that the number of new subscribers ha...</td>\n",
       "      <td>aihub-111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>100.0</td>\n",
       "      <td>전반적으로는 앞으로 금리가 더 떨어질 것으로 연준이 예상하고 잇다는 점이 드러났다.</td>\n",
       "      <td>Overall, it turned out that the Fed is expecti...</td>\n",
       "      <td>aihub-111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>100.0</td>\n",
       "      <td>이런 항생제들은 균을 죽이는 효과가 강력한 만큼 부작용도 큽니다.</td>\n",
       "      <td>These antibiotics have great side effects as t...</td>\n",
       "      <td>aihub-111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ko_xcomet                                              ko  \\\n",
       "10       100.0    3회 모두 꼭 참여해주셔야 하오니 사전에 일정 조율하셔서 신청해주시기 바랍니다.   \n",
       "113      100.0               문제는 부모의 주관적인 판단이 개입될 여지가 많다는 점이다.   \n",
       "149      100.0               신규 가입자가 지난 1∼2월보다 30% 이상 증가한 셈이다.   \n",
       "283      100.0  전반적으로는 앞으로 금리가 더 떨어질 것으로 연준이 예상하고 잇다는 점이 드러났다.   \n",
       "365      100.0            이런 항생제들은 균을 죽이는 효과가 강력한 만큼 부작용도 큽니다.   \n",
       "\n",
       "                                                    en     source  \n",
       "10   You must participate in all three sessions, so...  aihub-111  \n",
       "113  The problem is that there is much room for par...  aihub-111  \n",
       "149  It means that the number of new subscribers ha...  aihub-111  \n",
       "283  Overall, it turned out that the Fed is expecti...  aihub-111  \n",
       "365  These antibiotics have great side effects as t...  aihub-111  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko_xcomet</th>\n",
       "      <th>ko</th>\n",
       "      <th>ja</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>예방접종은 감염병 예방에 가장 효과적인 수단이며, 예방접종을 받으면 감염될 경우에도...</td>\n",
       "      <td>予防接種は感染症の予防に最も効果的な手段であり、予防接種を受ければ感染した場合にも深刻な合併...</td>\n",
       "      <td>aihub-127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>이러한 스펙을 강조하기 위하여 후면 카메라 모듈 아래에는 100X라는 문구가 디자인...</td>\n",
       "      <td>このようなスペックを強調するために、背面カメラのモジュールの下には、100Xという文句がデザ...</td>\n",
       "      <td>aihub-127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100.0</td>\n",
       "      <td>검사 준비에만 2시간이 넘게 걸려 보통 1회 검사에 최소 4시간 이상이 소요된다.</td>\n",
       "      <td>検査準備だけで2時間以上かかり、通常1回の検査に少なくとも4時間以上かかる。</td>\n",
       "      <td>aihub-127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100.0</td>\n",
       "      <td>실제, 수출과 연관성이 높은 광공업 생산지수는 지난해 4분기에 전분기 대비 4.0%...</td>\n",
       "      <td>実際、輸出と関連性の高い鉱工業の生産指数は昨年第4四半期に前四半期に比べて4.0%減少しました。</td>\n",
       "      <td>aihub-127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>100.0</td>\n",
       "      <td>양적완화는 경기부양 효과도 크지만 장기화할 경우 인플레이션 압력이 누적된다는 단점이...</td>\n",
       "      <td>量的緩和は景気浮揚効果も大きいが、長期化する場合、インフレーション圧力が累積するという短所が...</td>\n",
       "      <td>aihub-127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ko_xcomet                                                 ko  \\\n",
       "1       100.0  예방접종은 감염병 예방에 가장 효과적인 수단이며, 예방접종을 받으면 감염될 경우에도...   \n",
       "2       100.0  이러한 스펙을 강조하기 위하여 후면 카메라 모듈 아래에는 100X라는 문구가 디자인...   \n",
       "8       100.0      검사 준비에만 2시간이 넘게 걸려 보통 1회 검사에 최소 4시간 이상이 소요된다.   \n",
       "20      100.0  실제, 수출과 연관성이 높은 광공업 생산지수는 지난해 4분기에 전분기 대비 4.0%...   \n",
       "36      100.0  양적완화는 경기부양 효과도 크지만 장기화할 경우 인플레이션 압력이 누적된다는 단점이...   \n",
       "\n",
       "                                                   ja     source  \n",
       "1   予防接種は感染症の予防に最も効果的な手段であり、予防接種を受ければ感染した場合にも深刻な合併...  aihub-127  \n",
       "2   このようなスペックを強調するために、背面カメラのモジュールの下には、100Xという文句がデザ...  aihub-127  \n",
       "8              検査準備だけで2時間以上かかり、通常1回の検査に少なくとも4時間以上かかる。  aihub-127  \n",
       "20   実際、輸出と関連性の高い鉱工業の生産指数は昨年第4四半期に前四半期に比べて4.0%減少しました。  aihub-127  \n",
       "36  量的緩和は景気浮揚効果も大きいが、長期化する場合、インフレーション圧力が累積するという短所が...  aihub-127  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko_xcomet</th>\n",
       "      <th>ko</th>\n",
       "      <th>zh</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>100.0</td>\n",
       "      <td>하지만 이 같은 방식이 의료 시스템의 한정된 자원을 가장 도움이 절실한 중증 환자에...</td>\n",
       "      <td>但也有人主张,这种方式可以将医疗系统的有限资源集中到最迫切需要帮助的重症患者身上,从而减少死...</td>\n",
       "      <td>aihub-128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>100.0</td>\n",
       "      <td>본 발명은 네트워크에서의 데이터 전송방법에 관한 것이다.</td>\n",
       "      <td>本发明是关于网络数据传输方法的。</td>\n",
       "      <td>aihub-128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>100.0</td>\n",
       "      <td>DID는 블록체인 기술로 개인의 신원을 증명하는 새로운 기술이다.</td>\n",
       "      <td>DID是用区块链技术证明个人身份的新技术。</td>\n",
       "      <td>aihub-128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>100.0</td>\n",
       "      <td>미래 자동차가 보여줄 새로운 디자인을 경험하는 시간도 갖는다.</td>\n",
       "      <td>我们还将体验未来汽车将展示的新设计。</td>\n",
       "      <td>aihub-128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>100.0</td>\n",
       "      <td>정부는 내년 초 게임산업 중장기 계획을 발표할 방침이다.</td>\n",
       "      <td>政府计划明年初发表游戏产业中长期计划。</td>\n",
       "      <td>aihub-128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ko_xcomet                                                 ko  \\\n",
       "118      100.0  하지만 이 같은 방식이 의료 시스템의 한정된 자원을 가장 도움이 절실한 중증 환자에...   \n",
       "257      100.0                    본 발명은 네트워크에서의 데이터 전송방법에 관한 것이다.   \n",
       "311      100.0               DID는 블록체인 기술로 개인의 신원을 증명하는 새로운 기술이다.   \n",
       "349      100.0                 미래 자동차가 보여줄 새로운 디자인을 경험하는 시간도 갖는다.   \n",
       "582      100.0                    정부는 내년 초 게임산업 중장기 계획을 발표할 방침이다.   \n",
       "\n",
       "                                                    zh     source  \n",
       "118  但也有人主张,这种方式可以将医疗系统的有限资源集中到最迫切需要帮助的重症患者身上,从而减少死...  aihub-128  \n",
       "257                                   本发明是关于网络数据传输方法的。  aihub-128  \n",
       "311                              DID是用区块链技术证明个人身份的新技术。  aihub-128  \n",
       "349                                 我们还将体验未来汽车将展示的新设计。  aihub-128  \n",
       "582                                政府计划明年初发表游戏产业中长期计划。  aihub-128  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-71265    30000\n",
       "aihub-126      15000\n",
       "aihub-71382    15000\n",
       "aihub-111      10000\n",
       "aihub-125      10000\n",
       "aihub-124       7500\n",
       "aihub-71266     7500\n",
       "aihub-563       5000\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-546      30000\n",
       "aihub-71263    15000\n",
       "aihub-127      13580\n",
       "aihub-71524     8864\n",
       "aihub-71593     8277\n",
       "aihub-71493     7709\n",
       "aihub-71496     5474\n",
       "aihub-71498     5469\n",
       "aihub-71591     4171\n",
       "aihub-71411     1456\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-546      30000\n",
       "aihub-129      16155\n",
       "aihub-71263    15000\n",
       "aihub-128      10000\n",
       "aihub-71493     7862\n",
       "aihub-71593     6210\n",
       "aihub-71262     5000\n",
       "aihub-71496     4361\n",
       "aihub-71498     4179\n",
       "aihub-71411     1233\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_top = extract_top_n(en_train, criteria_en)\n",
    "ja_top = extract_top_n(ja_train, criteria_ja)\n",
    "zh_top = extract_top_n(zh_train, criteria_zh)\n",
    "\n",
    "display(en_top.head())\n",
    "print(len(en_top))\n",
    "display(ja_top.head())\n",
    "print(len(ja_top))\n",
    "display(zh_top.head())\n",
    "print(len(zh_top))\n",
    "\n",
    "display(en_top['source'].value_counts())\n",
    "display(ja_top['source'].value_counts())\n",
    "display(zh_top['source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-546      60000\n",
       "aihub-71265    30000\n",
       "aihub-71263    30000\n",
       "aihub-129      16155\n",
       "aihub-71493    15571\n",
       "aihub-126      15000\n",
       "aihub-71382    15000\n",
       "aihub-71593    14487\n",
       "aihub-127      13580\n",
       "aihub-128      10000\n",
       "aihub-111      10000\n",
       "aihub-125      10000\n",
       "aihub-71496     9835\n",
       "aihub-71498     9648\n",
       "aihub-71524     8864\n",
       "aihub-71266     7500\n",
       "aihub-124       7500\n",
       "aihub-563       5000\n",
       "aihub-71262     5000\n",
       "aihub-71591     4171\n",
       "aihub-71411     2689\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_train = pd.concat([en_top, ja_top, zh_top])\n",
    "\n",
    "print(len(top_train))\n",
    "display(top_train['source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-71265    238\n",
       "aihub-126      168\n",
       "aihub-71266    134\n",
       "aihub-125      134\n",
       "aihub-124      127\n",
       "aihub-111      119\n",
       "aihub-71382     44\n",
       "aihub-563       36\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-127      1000\n",
       "aihub-546      1000\n",
       "aihub-71263    1000\n",
       "aihub-71411    1000\n",
       "aihub-71493    1000\n",
       "aihub-71496    1000\n",
       "aihub-71498    1000\n",
       "aihub-71524    1000\n",
       "aihub-71591    1000\n",
       "aihub-71593    1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-128      1000\n",
       "aihub-129      1000\n",
       "aihub-546      1000\n",
       "aihub-71262    1000\n",
       "aihub-71263    1000\n",
       "aihub-71411    1000\n",
       "aihub-71493    1000\n",
       "aihub-71496    1000\n",
       "aihub-71498    1000\n",
       "aihub-71593    1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "display(en_eval['source'].value_counts())\n",
    "print(len(en_eval))\n",
    "display(ja_eval['source'].value_counts())\n",
    "print(len(ja_eval))\n",
    "display(zh_eval['source'].value_counts())\n",
    "print(len(zh_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "71265    25017\n",
       "126      16100\n",
       "111      13574\n",
       "124      13537\n",
       "125      13444\n",
       "71266    13154\n",
       "71382     5729\n",
       "563       3610\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104165\n"
     ]
    }
   ],
   "source": [
    "en_base_eval = load_dataset(en_base_name, split='validation')\n",
    "en_base_eval = pd.DataFrame(en_base_eval)\n",
    "display(en_base_eval['source'].value_counts())\n",
    "print(len(en_base_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "71266    1000\n",
       "71265    1000\n",
       "126      1000\n",
       "111      1000\n",
       "124      1000\n",
       "125      1000\n",
       "71382    1000\n",
       "563      1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "# en_base_eval에서 source 별로 1000개씩 데이터 추출\n",
    "en_eval_new = pd.DataFrame()\n",
    "for src in en_base_eval['source'].unique():\n",
    "    subset = en_base_eval[en_base_eval['source'] == src]\n",
    "    sample = subset.sample(n=1000, random_state=42)\n",
    "    en_eval_new = pd.concat([en_eval_new, sample])\n",
    "\n",
    "display(en_eval_new['source'].value_counts())\n",
    "print(len(en_eval_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko_xcomet</th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16804</th>\n",
       "      <td>None</td>\n",
       "      <td>브라질의 코로나19 신규 확진자가 나흘째 5만 명을 넘는 등 피해가 확산하고 있다.</td>\n",
       "      <td>For the fourth day in a row, the number of new...</td>\n",
       "      <td>aihub-71266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79615</th>\n",
       "      <td>None</td>\n",
       "      <td>터치패드는 터치스크린(112)으로부터 분리된 터치 감지 표면이거나, 터치스크린에 의...</td>\n",
       "      <td>The touch pad may be a touch-sensitive surface...</td>\n",
       "      <td>aihub-71266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22035</th>\n",
       "      <td>None</td>\n",
       "      <td>일본 정부는 미국 공화당 대선 선두 주자인 도널드 트럼프 때문에 당분간 핵무기를 보...</td>\n",
       "      <td>The Japanese government is expected to place g...</td>\n",
       "      <td>aihub-71266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48069</th>\n",
       "      <td>None</td>\n",
       "      <td>콘텐츠 퍼블리셔(120)는 애플리케이션이 어떻게 네이티브 콘텐츠 아이템을 어셈블링하...</td>\n",
       "      <td>The content publisher 120 may set predetermine...</td>\n",
       "      <td>aihub-71266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59486</th>\n",
       "      <td>None</td>\n",
       "      <td>파악하기 위해 1인당 GDP 성장률을 종속변수로 하고 지리변수와 기후변수를 통제하여...</td>\n",
       "      <td>To understand this, regression analysis was co...</td>\n",
       "      <td>aihub-71266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ko_xcomet                                                 ko  \\\n",
       "16804      None     브라질의 코로나19 신규 확진자가 나흘째 5만 명을 넘는 등 피해가 확산하고 있다.   \n",
       "79615      None  터치패드는 터치스크린(112)으로부터 분리된 터치 감지 표면이거나, 터치스크린에 의...   \n",
       "22035      None  일본 정부는 미국 공화당 대선 선두 주자인 도널드 트럼프 때문에 당분간 핵무기를 보...   \n",
       "48069      None  콘텐츠 퍼블리셔(120)는 애플리케이션이 어떻게 네이티브 콘텐츠 아이템을 어셈블링하...   \n",
       "59486      None  파악하기 위해 1인당 GDP 성장률을 종속변수로 하고 지리변수와 기후변수를 통제하여...   \n",
       "\n",
       "                                                      en       source  \n",
       "16804  For the fourth day in a row, the number of new...  aihub-71266  \n",
       "79615  The touch pad may be a touch-sensitive surface...  aihub-71266  \n",
       "22035  The Japanese government is expected to place g...  aihub-71266  \n",
       "48069  The content publisher 120 may set predetermine...  aihub-71266  \n",
       "59486  To understand this, regression analysis was co...  aihub-71266  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_eval_new['ko_xcomet'] = None\n",
    "en_eval_new = en_eval_new[['ko_xcomet', 'ko', 'en', 'source']]\n",
    "en_eval_new['source'] = en_eval_new['source'].apply(lambda x: f'aihub-{x}')\n",
    "display(en_eval_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-71498    2000\n",
       "aihub-546      2000\n",
       "aihub-71263    2000\n",
       "aihub-71411    2000\n",
       "aihub-71493    2000\n",
       "aihub-71496    2000\n",
       "aihub-71593    2000\n",
       "aihub-124      1000\n",
       "aihub-71265    1000\n",
       "aihub-71266    1000\n",
       "aihub-111      1000\n",
       "aihub-126      1000\n",
       "aihub-127      1000\n",
       "aihub-125      1000\n",
       "aihub-71382    1000\n",
       "aihub-563      1000\n",
       "aihub-71524    1000\n",
       "aihub-71591    1000\n",
       "aihub-128      1000\n",
       "aihub-129      1000\n",
       "aihub-71262    1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000\n"
     ]
    }
   ],
   "source": [
    "top_eval = pd.concat([en_eval_new, ja_eval, zh_eval])\n",
    "display(top_eval['source'].value_counts())\n",
    "print(len(top_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "flores-devtest    104\n",
       "aihub-71266       100\n",
       "aihub-71265       100\n",
       "aihub-111         100\n",
       "aihub-126         100\n",
       "aihub-124         100\n",
       "aihub-563         100\n",
       "aihub-125         100\n",
       "aihub-71382       100\n",
       "flores-dev         96\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-127      200\n",
       "aihub-546      200\n",
       "aihub-71263    200\n",
       "aihub-71411    200\n",
       "aihub-71493    200\n",
       "aihub-71496    200\n",
       "aihub-71498    200\n",
       "aihub-71524    200\n",
       "aihub-71591    200\n",
       "aihub-71593    200\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-128      200\n",
       "aihub-129      200\n",
       "aihub-546      200\n",
       "aihub-71262    200\n",
       "aihub-71263    200\n",
       "aihub-71411    200\n",
       "aihub-71493    200\n",
       "aihub-71496    200\n",
       "aihub-71498    200\n",
       "aihub-71593    200\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "display(en_test['source'].value_counts())\n",
    "print(len(en_test))\n",
    "display(ja_test['source'].value_counts())\n",
    "print(len(ja_test))\n",
    "display(zh_test['source'].value_counts())\n",
    "print(len(zh_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-71266    100\n",
       "aihub-71265    100\n",
       "aihub-111      100\n",
       "aihub-126      100\n",
       "aihub-124      100\n",
       "aihub-125      100\n",
       "aihub-563      100\n",
       "aihub-71382    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "# en_test에서 source가 flores로 시작하는 데이터를 제외\n",
    "en_test_new = en_test[~en_test['source'].str.startswith('flores')]\n",
    "display(en_test_new['source'].value_counts())\n",
    "print(len(en_test_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko_xcomet</th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>초국가 기구는 협상 과정에서 협상 기회를 창출하거나 결정권자들의 갈등을 완화시키는 ...</td>\n",
       "      <td>Transnational institutions act as intermediari...</td>\n",
       "      <td>aihub-71266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>그래서 뭐 고를 건데?</td>\n",
       "      <td>So what are you going to choose?</td>\n",
       "      <td>aihub-71265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>당시 사업주체인 Y22프로젝트파이낸싱인베스트먼트와 토지 소유주인 통일교재단 사이에 ...</td>\n",
       "      <td>This is because, at that time, a lawsuit about...</td>\n",
       "      <td>aihub-111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>우리나라에서도 종래 시･도 단위의 비교적 큰 공간 단위를 분석 대상으로 접근하던 지...</td>\n",
       "      <td>In Korea, too, there is an increasing number o...</td>\n",
       "      <td>aihub-71266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>AI를 활용해 인류가 직면한 시·공간 및 지능의 한계를 극복하고 공공 목적의 국민생...</td>\n",
       "      <td>The policy is to use AI to overcome the limita...</td>\n",
       "      <td>aihub-111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ko_xcomet                                                 ko  \\\n",
       "0      None  초국가 기구는 협상 과정에서 협상 기회를 창출하거나 결정권자들의 갈등을 완화시키는 ...   \n",
       "1      None                                       그래서 뭐 고를 건데?   \n",
       "2      None  당시 사업주체인 Y22프로젝트파이낸싱인베스트먼트와 토지 소유주인 통일교재단 사이에 ...   \n",
       "3      None  우리나라에서도 종래 시･도 단위의 비교적 큰 공간 단위를 분석 대상으로 접근하던 지...   \n",
       "5      None  AI를 활용해 인류가 직면한 시·공간 및 지능의 한계를 극복하고 공공 목적의 국민생...   \n",
       "\n",
       "                                                  en       source  \n",
       "0  Transnational institutions act as intermediari...  aihub-71266  \n",
       "1                   So what are you going to choose?  aihub-71265  \n",
       "2  This is because, at that time, a lawsuit about...    aihub-111  \n",
       "3  In Korea, too, there is an increasing number o...  aihub-71266  \n",
       "5  The policy is to use AI to overcome the limita...    aihub-111  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_test_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-127      100\n",
       "aihub-546      100\n",
       "aihub-71263    100\n",
       "aihub-71411    100\n",
       "aihub-71493    100\n",
       "aihub-71496    100\n",
       "aihub-71498    100\n",
       "aihub-71524    100\n",
       "aihub-71591    100\n",
       "aihub-71593    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-128      100\n",
       "aihub-129      100\n",
       "aihub-546      100\n",
       "aihub-71262    100\n",
       "aihub-71263    100\n",
       "aihub-71411    100\n",
       "aihub-71493    100\n",
       "aihub-71496    100\n",
       "aihub-71498    100\n",
       "aihub-71593    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# ja_test, zh_test에서 각 source 별로 100개씩만 추출해 ja_test_new, zh_test_new로 만들기\n",
    "ja_test_new = pd.DataFrame()\n",
    "for src in ja_test['source'].unique():\n",
    "    subset_ja = ja_test[ja_test['source'] == src]\n",
    "    sample_ja = subset_ja.sample(n=100, random_state=42)\n",
    "    ja_test_new = pd.concat([ja_test_new, sample_ja])\n",
    "\n",
    "zh_test_new = pd.DataFrame()\n",
    "for src in zh_test['source'].unique():\n",
    "    subset_zh = zh_test[zh_test['source'] == src]\n",
    "    sample_zh = subset_zh.sample(n=100, random_state=42)\n",
    "    zh_test_new = pd.concat([zh_test_new, sample_zh])\n",
    "\n",
    "display(ja_test_new['source'].value_counts())\n",
    "print(len(ja_test_new))\n",
    "display(zh_test_new['source'].value_counts())\n",
    "print(len(zh_test_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "aihub-71498    200\n",
       "aihub-546      200\n",
       "aihub-71263    200\n",
       "aihub-71411    200\n",
       "aihub-71493    200\n",
       "aihub-71496    200\n",
       "aihub-71593    200\n",
       "aihub-124      100\n",
       "aihub-71265    100\n",
       "aihub-71266    100\n",
       "aihub-126      100\n",
       "aihub-111      100\n",
       "aihub-127      100\n",
       "aihub-125      100\n",
       "aihub-563      100\n",
       "aihub-71382    100\n",
       "aihub-71524    100\n",
       "aihub-71591    100\n",
       "aihub-128      100\n",
       "aihub-129      100\n",
       "aihub-71262    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800\n"
     ]
    }
   ],
   "source": [
    "top_test = pd.concat([en_test_new, ja_test_new, zh_test_new])\n",
    "display(top_test['source'].value_counts())\n",
    "print(len(top_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n",
      "28000\n",
      "2800\n"
     ]
    }
   ],
   "source": [
    "print(len(top_train))\n",
    "print(len(top_eval))\n",
    "print(len(top_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ko_xcomet', 'ko', 'en', 'source', 'ja', 'zh'], dtype='object')\n",
      "Index(['ko_xcomet', 'ko', 'en', 'source', 'ja', 'zh'], dtype='object')\n",
      "Index(['ko_xcomet', 'ko', 'en', 'source', 'ja', 'zh'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(top_train.columns)\n",
    "print(top_eval.columns)\n",
    "print(top_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def set_mmt_dataset(df):\n",
    "    mmt_dataset = defaultdict(list)\n",
    "    default_cols = ['ko_xcomet', 'ko', 'source']\n",
    "    for _, row in df.iterrows():\n",
    "        tgt_cols = [col for col in df.columns if col not in default_cols]\n",
    "        for col in tgt_cols:\n",
    "            if pd.isna(row[col]):\n",
    "                continue\n",
    "            tgt_col = col\n",
    "        print(tgt_col)\n",
    "\n",
    "    return mmt_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ko_xcomet', 'ko', 'en', 'source', 'ja', 'zh'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "mmt_train = set_mmt_dataset(top_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_train.to_csv('./top_train.csv', index=False)\n",
    "top_eval.to_csv('./top_eval.csv', index=False)\n",
    "top_test.to_csv('./top_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
