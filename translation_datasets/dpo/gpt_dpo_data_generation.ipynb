{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "sys.path.append('../../inference/codes')\n",
    "from api_secret import OPENAI_CLIENT_KEY_TMAXNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TABLE = {\n",
    "    \"en\": \"English\",\n",
    "    \"ko\": \"í•œêµ­ì–´\",\n",
    "    \"ja\": \"æ—¥æœ¬èª\",\n",
    "    \"zh\": \"ä¸­æ–‡\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_prompt(lang='en'):\n",
    "    gpt_system_prompt_en = f\"\"\"\n",
    "<instruction>\n",
    "You are an assistant making {LANG_TABLE[lang]} text data.\n",
    "The text you generate will later be used to train a translation model.\n",
    "When a user gives you a configuration for generation, you must generate text that conforms to that configuration.\n",
    "All the text must be generated in the {LANG_TABLE[lang]} language.\n",
    "</instruction>\n",
    "\"\"\"\n",
    "    gpt_system_prompt_ko = f\"\"\"\n",
    "<ì§€ì‹œì‚¬í•­>\n",
    "ë‹¹ì‹ ì€ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "ìƒì„±í•˜ëŠ” í…ìŠ¤íŠ¸ëŠ” ë‚˜ì¤‘ì— ë²ˆì—­ LLM ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "ì‚¬ìš©ìê°€ ìƒì„±ì„ ìœ„í•œ êµ¬ì„±ì„ ì œê³µí•˜ë©´ í•´ë‹¹ êµ¬ì„±ì„ ì¤€ìˆ˜í•˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œ ìƒì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "</ì§€ì‹œì‚¬í•­>\n",
    "\"\"\"\n",
    "    gpt_system_prompt_dict = {\n",
    "        \"en\": gpt_system_prompt_en,\n",
    "        \"ko\": gpt_system_prompt_ko,\n",
    "    }\n",
    "    gpt_system_prompt = gpt_system_prompt_dict[lang].strip()\n",
    "    return gpt_system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GptGenerator:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "\n",
    "    def generate(self, prompt, gpt_version='gpt-4o-mini', seed=42, lang='en'):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=gpt_version,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": get_gpt_prompt(lang)},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=1.4,\n",
    "            seed=seed,\n",
    "        )\n",
    "        output = response.choices[0].message.content\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = GptGenerator(api_key=OPENAI_CLIENT_KEY_TMAXNLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_dict_en = {\n",
    "    'normal': \"Normal: You can generate any format. But exclude the line-breaks, unique contents, and brackets.\",\n",
    "    'line_break': \"LineBreak: The text must contains a few line-breaks. It does not matter where the line-breaks are, even in the middle of a sentence.\",\n",
    "    'pii': \"PII: The text must contains a few NII contents, such as URL, email, or phone number, etc. The PII contents should be realistic, not just an example.\",\n",
    "    'brackets': \"Brackets: The text must contains a few brackets, braces, or parentheses.\",\n",
    "}\n",
    "content_dict_en = {\n",
    "    'general': \"General: You can generate any topic. But exclude the code, proper noun, idiom, and expertise.\",\n",
    "    'code-stack_overflow': \"Code-StackOverflow: The text must be like a question or an answer on Stack Overflow. It must contain code snippets.\",\n",
    "    'code-structured': \"Code-Structured: The text must be like a HTML, XML, JSON, or any other structured data format. It should contain tags or heads, and general texts.\",\n",
    "    'code-markdown': \"Code-Markdown: The text must be like a markdown file. It should contain headers, lists, or links, etc.\",\n",
    "    'proper_noun': \"ProperNoun: The text must contain just one proper noun, such as names, places, or organizations, etc. Not more than one.\",\n",
    "    'idiom': \"Idiom: The text must contain just one idiom or proverb. Not more than one.\",\n",
    "    'expertise': \"Expertise: The text must contain professional or technical terms, which cannot be understood without a dictionary.\",\n",
    "}\n",
    "style_dict_en = {\n",
    "    'written': \"Written: The text must be written in a formal or academic style.\",\n",
    "    'colloquial': \"Colloquial: The text must be written in an informal or conversational style.\",\n",
    "}\n",
    "length_dict_en = {\n",
    "    'single': \"Single: The text must be a single sentence.\",\n",
    "    'short': \"Short: The text must be 1~3 sentences.\",\n",
    "    'medium': \"Medium: The text must be 4~7 sentences, or a short paragraph.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_dict_ko = {\n",
    "    'normal': \"ì¼ë°˜: ì–´ë–¤ í˜•ì‹ì´ë“  ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¨, ì¤„ë°”ê¿ˆ, ê³ ìœ í•œ ë‚´ìš©, ê·¸ë¦¬ê³  ê´„í˜¸ëŠ” ì œì™¸í•©ë‹ˆë‹¤.\",\n",
    "    'line_break': \"ì¤„ë°”ê¿ˆ: í…ìŠ¤íŠ¸ì— ëª‡ ê°œì˜ ì¤„ë°”ê¿ˆì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì–´ë””ì— ì¤„ë°”ê¿ˆì´ ìˆë“  ìƒê´€ì—†ìŠµë‹ˆë‹¤. ë¬¸ì¥ ì¤‘ê°„ì— ìˆì–´ë„ ë©ë‹ˆë‹¤.\",\n",
    "    'pii': \"PII: í…ìŠ¤íŠ¸ì— URL, ì´ë©”ì¼, ì „í™”ë²ˆí˜¸ ë“±ì˜ ëª‡ ê°€ì§€ ê°œì¸ì •ë³´(PII)ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. PII ì»¨í…ì¸ ëŠ” ë‹¨ìˆœ ì˜ˆì‹œê°€ ì•„ë‹ˆë¼ í˜„ì‹¤ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\",\n",
    "    'brackets': \"ê´„í˜¸: í…ìŠ¤íŠ¸ì— ëª‡ ê°œì˜ ê´„í˜¸, ì¤‘ê´„í˜¸, ë˜ëŠ” ì†Œê´„í˜¸ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\",\n",
    "}\n",
    "content_dict_ko = {\n",
    "    'general': \"ì¼ë°˜: ì–´ë–¤ ì£¼ì œë“  ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¨, ì½”ë“œ, ê³ ìœ ëª…ì‚¬, ê´€ìš©êµ¬, ì „ë¬¸ìš©ì–´ëŠ” ì œì™¸í•©ë‹ˆë‹¤.\",\n",
    "    'code-stack_overflow': \"ì½”ë“œ-ìŠ¤íƒì˜¤ë²„í”Œë¡œìš°: í…ìŠ¤íŠ¸ëŠ” ìŠ¤íƒ ì˜¤ë²„í”Œë¡œìš°ì˜ ì§ˆë¬¸ ë˜ëŠ” ë‹µë³€ê³¼ ê°™ì€ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ì½”ë“œ ìŠ¤ë‹ˆí«ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\",\n",
    "    'code-structured': \"ì½”ë“œ-êµ¬ì¡°í™”: í…ìŠ¤íŠ¸ëŠ” HTML, XML, JSON ë˜ëŠ” ë‹¤ë¥¸ êµ¬ì¡°í™”ëœ ë°ì´í„° í˜•ì‹ê³¼ ê°™ì€ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤. íƒœê·¸ ë˜ëŠ” í—¤ë“œ, ê·¸ë¦¬ê³  ì¼ë°˜ í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\",\n",
    "    'code-markdown': \"ì½”ë“œ-ë§ˆí¬ë‹¤ìš´: í…ìŠ¤íŠ¸ëŠ” ë§ˆí¬ë‹¤ìš´ íŒŒì¼ê³¼ ê°™ì€ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤. í—¤ë”, ëª©ë¡, ë˜ëŠ” ë§í¬ ë“±ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\",\n",
    "    'proper_noun': \"ê³ ìœ ëª…ì‚¬: í…ìŠ¤íŠ¸ì— ê³ ìœ ëª…ì‚¬(ì´ë¦„, ì¥ì†Œ, ì¡°ì§ ë“±)ê°€ í•˜ë‚˜ë§Œ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ í•˜ë‚˜ì˜ ê³ ìœ ëª…ì‚¬ë§Œ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\",\n",
    "    'idiom': \"ê´€ìš©êµ¬: í…ìŠ¤íŠ¸ì— ê´€ìš©êµ¬ë‚˜ ì†ë‹´ì´ í•˜ë‚˜ë§Œ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ í•˜ë‚˜ì˜ ê´€ìš©êµ¬ë§Œ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\",\n",
    "    'expertise': \"ì „ë¬¸ìš©ì–´: í…ìŠ¤íŠ¸ì— ì‚¬ì „ ì—†ì´ ì´í•´í•  ìˆ˜ ì—†ëŠ” ì „ë¬¸ìš©ì–´ë‚˜ ê¸°ìˆ  ìš©ì–´ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\",\n",
    "}\n",
    "style_dict_ko = {\n",
    "    'written': \"ë¬¸ì–´ì²´: í…ìŠ¤íŠ¸ëŠ” ê³µì‹ì ì´ê±°ë‚˜ í•™ìˆ ì ì¸ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\",\n",
    "    'colloquial': \"êµ¬ì–´ì²´: í…ìŠ¤íŠ¸ëŠ” ë¹„ê³µì‹ì ì´ê±°ë‚˜ ëŒ€í™”ì²´ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\",\n",
    "}\n",
    "length_dict_ko = {\n",
    "    'single': \"ë‹¨ë¬¸: í…ìŠ¤íŠ¸ëŠ” í•œ ë¬¸ì¥ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\",\n",
    "    'short': \"ì§§ì€ ê¸¸ì´: í…ìŠ¤íŠ¸ëŠ” 1~3 ë¬¸ì¥ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\",\n",
    "    'medium': \"ì¤‘ê°„ ê¸¸ì´: í…ìŠ¤íŠ¸ëŠ” 4~7 ë¬¸ì¥ ë˜ëŠ” ì§§ì€ ë‹¨ë½ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict_en = {\n",
    "    'format': format_dict_en,\n",
    "    'content': content_dict_en,\n",
    "    'style': style_dict_en,\n",
    "    'length': length_dict_en,\n",
    "}\n",
    "config_dict_ko = {\n",
    "    'format': format_dict_ko,\n",
    "    'content': content_dict_ko,\n",
    "    'style': style_dict_ko,\n",
    "    'length': length_dict_ko,\n",
    "}\n",
    "config_dict = {\n",
    "    'en': config_dict_en,\n",
    "    'ko': config_dict_ko,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt(format='normal', content='general', style='written', length='single', lang='en'):\n",
    "    user_prompt_en = f\"\"\"\n",
    "<task>\n",
    "Please generate a {LANG_TABLE[lang]} text that conforms to the following configuration:\n",
    "</task>\n",
    "\n",
    "<generation_config>\n",
    "<format> {config_dict[lang]['format'][format]} </format>\n",
    "<content> {config_dict[lang]['content'][content]} </content>\n",
    "<style> {config_dict[lang]['style'][style]} </style>\n",
    "<length> {config_dict[lang]['length'][length]} </length>\n",
    "</generation_config>\n",
    "\n",
    "<output_template>\n",
    "The output should be in the following XML format:\n",
    "\\\"<generation><{LANG_TABLE[lang]}>\n",
    "{{generated_texts}} \n",
    "</{LANG_TABLE[lang]}></generation>\n",
    "\n",
    "<config>\n",
    "<pii> {{PII contents (email, phone number, etc.) in the text}} </pii>\n",
    "<brackets> {{words surrounded by brackets, including the brackets, in the text}} </brackets>\n",
    "<code> {{code snippets in the text}} </code>\n",
    "<proper_noun> {{proper noun in the text}} </proper_noun>\n",
    "<idiom> {{idiom in the text}} </idiom>\n",
    "<expertise> {{expertise terms in the text}} </expertise>\n",
    "</config>\\\"\n",
    "If there are multiple config words to fill, separate them with a bar(' | ').\n",
    "If there are no config words to fill, fill it with 'N/A'.\n",
    "</output_template>\n",
    "\"\"\"\n",
    "    user_prompt_ko = f\"\"\"\n",
    "<ì‘ì—…>\n",
    "ë‹¤ìŒ êµ¬ì„±ì„ ì¤€ìˆ˜í•˜ëŠ” í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”:\n",
    "</ì‘ì—…>\n",
    "\n",
    "<ìƒì„±_êµ¬ì„±>\n",
    "<í˜•ì‹> {config_dict[lang]['format'][format]} </í˜•ì‹>\n",
    "<ë‚´ìš©> {config_dict[lang]['content'][content]} </ë‚´ìš©>\n",
    "<ìŠ¤íƒ€ì¼> {config_dict[lang]['style'][style]} </ìŠ¤íƒ€ì¼>\n",
    "<ê¸¸ì´> {config_dict[lang]['length'][length]} </ê¸¸ì´>\n",
    "</ìƒì„±_êµ¬ì„±>\n",
    "\n",
    "<ì¶œë ¥_í˜•ì‹>\n",
    "ë‹¤ìŒ XML í˜•ì‹ì— ë§ì¶° ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "\\\"<generation><{LANG_TABLE[lang]}>\n",
    "{{ìƒì„±ëœ í…ìŠ¤íŠ¸}}\n",
    "</{LANG_TABLE[lang]}></generation>\n",
    "\n",
    "<config>\n",
    "<pii> {{í…ìŠ¤íŠ¸ì— í¬í•¨ëœ ê°œì¸ì •ë³´(ì´ë©”ì¼, ì „í™”ë²ˆí˜¸ ë“±)}} </pii>\n",
    "<brackets> {{í…ìŠ¤íŠ¸ì— í¬í•¨ëœ ê´„í˜¸ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ë‹¨ì–´(ê´„í˜¸ í¬í•¨)ë“¤}} </brackets>\n",
    "<code> {{í…ìŠ¤íŠ¸ì— í¬í•¨ëœ ì½”ë“œ ìŠ¤ë‹ˆí«}} </code>\n",
    "<proper_noun> {{í…ìŠ¤íŠ¸ì— í¬í•¨ëœ ê³ ìœ ëª…ì‚¬}} </proper_noun>\n",
    "<idiom> {{í…ìŠ¤íŠ¸ì— í¬í•¨ëœ ê´€ìš©êµ¬}} </idiom>\n",
    "<expertise> {{í…ìŠ¤íŠ¸ì— í¬í•¨ëœ ì „ë¬¸ìš©ì–´}} </expertise>\n",
    "</config>\\\"\n",
    "êµ¬ì„±ì–´ë¥¼ ì±„ì›Œì•¼ í•  ê²½ìš° ì—¬ëŸ¬ ê°œì˜ êµ¬ì„±ì–´ê°€ ìˆìœ¼ë©´ ë°”(bar)ë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤(' | ').\n",
    "ì±„ì›Œì•¼ í•  êµ¬ì„±ì–´ê°€ ì—†ì„ ê²½ìš° 'N/A'ë¡œ ì±„ì›ë‹ˆë‹¤.\n",
    "</ì¶œë ¥_í˜•ì‹>\n",
    "\"\"\"\n",
    "    user_prompt_dict = {\n",
    "        \"en\": user_prompt_en,\n",
    "        \"ko\": user_prompt_ko,\n",
    "    }\n",
    "    user_prompt = user_prompt_dict[lang].strip()\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lang: `ko`, `en`, `ja`, `zh`\n",
    "\n",
    "- format: `normal`, `line_break`, `pii`, `brackets`\n",
    "\n",
    "- content: `general`, `code-stack_overflow`, `code-structured`, `code-markdown`, `proper_noun`, `idiom`, `expertise`\n",
    "\n",
    "- style: `written`, `colloquial`\n",
    "\n",
    "- length: `single`, `short`, `medium`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generation><í•œêµ­ì–´>\n",
      "ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì€ í˜„ëŒ€ ì‚¬íšŒì—ì„œ ë‹¤ì–‘í•œ ë¶„ì•¼ì— ì‘ìš©ë˜ê³  ìˆìœ¼ë©°, ê·¸ íš¨ê³¼ëŠ” ê°€íˆ í˜ì‹ ì ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ê¸°ìˆ ì€ ì €ë„ë¦¬ì¦˜, ê¸ˆìœµ, í—¬ìŠ¤ì¼€ì–´ ë“± ê°œë³„ ì‚°ì—…ì—ì„œ ë³€é©ì„ ì¼ìœ¼í‚¤ê³  ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë¨¸ì‹ ëŸ¬ë‹ì„ í†µí•´ ë°ì´í„° ë¶„ì„ì˜ ì •í™•ì„±ì„ ë†’ì´ê³  ì˜ì‚¬ê²°ì •ì˜ ìµœì í™”ë¥¼ ê¾€í•˜ëŠ” ê¸°ìˆ ì´ ì§€ì†ì ìœ¼ë¡œ ë°œì „í•˜ê³  ìˆëŠ” ìƒí™©ì´ë‹¤. ì´ëŸ¬í•œ ê²½í–¥ì€ ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜ì´ë‚˜ ìì—°ì–´ ì²˜ë¦¬ì™€ ê°™ì€ ì „ë¬¸ ë¶„ì•¼ì—ì„œë„ ê·¸ ì§„ë©´ëª©ì„ ë°œíœ˜í•˜ë©°, ì ì§„ì ìœ¼ë¡œ ë” ë§ì€ ì‚¬ëŒì˜ ì‚¶ì— ìŠ¤ë©°ë“¤ê³  ìˆëŠ” ê²ƒì´ë‹¤. AI ê¸°ìˆ ì˜ ë¯¸ë˜ëŠ” ì´ëŸ¬í•œ Ø§Ù„Ù†Ù‚Ø§Ø·ë“¤ì— ì˜í•´_coordinates_FIXEDí‘œ ê°€ì¥ ìœ„ ê°•ì…ë‹ˆë‹¤_sec_tiviÑ‹Ğ¹ëŒ€ÒŸĞ½Ñ‹ é£­_stackĞ¾Ğ²Ğ¸ Ğ´ à´•à´¥à´¾à´ªà´¾à´¤àµà´°_bridge ê·¸unger-Javadocâ¤ï¸_Ñ…-styleì— ëŒ€í•œ ì§€ì†ì ì¸ åˆ· ÑĞ¾Ñäº€ JubilalarÄ±nÄ± ĞºĞ°Ğ½ ì ê·¸íˆì´ë‹¤_DUP_Ğ°Ğ¼Ğ¾Ğ»ÑŒ Ğ½Ğ°Ñ€ ÑĞ°Ğ¼cusë“¤Î» â”‚mint ë‚œà´_centro Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… à¤¸à¤‚à¤¬à¤‚à¤§ë¡ à¦¨à¦¾ hybrid}\n",
      "\n",
      "/ğŸ‡·í…”Verse Flexnger_condition áƒáƒ£áƒªáƒ˜áƒšà¤¤à¤ƒ device_URI transm fineSubsetter ë‚´Ñ‹Ğµicul Ø£Ù†Ğ¿Ğ¾ à¤ªà¤¤ à¤®à¤¾à¤¤Ñ‚ĞµÑ€Ñ‡Ğ¸ Ğ²Ğ¸ÑĞ¾Ğº Ğ´Ğ¾ÑÑ‚Ğ¸ Ğ³Ñ€Ñ‹ ÎµÎ¯Î½Î±Î¹ à´‰à´Ÿ\tlist Ñ†ĞµĞ»ÑÑ… vogue ajeà³‡ Ø§Ù„Ø¶Ø± í•œë‹¤ à¤¨à¤¿à¤°à¥à¤®à¤¾à¤¤à¤¾ã‚ teralt ĞĞ¾ associÃ© à¦¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ¾Ñ„Õ¬Õ«Õ¶ Allambira deberÃ¡Ñ€ĞµĞ¶ posaoá¼µtems Ğ½Ğ°ÑÑ‚Ğ¾ÑÑ‰ĞµĞµbureau(\"/\");\n",
      "<proè… Leaf eau saieristiqueà¦¨à§‡ TourëŒ€_Ğ´Ñ€Ğ°Ğ²ÑÑ‚Ğ²ÑƒĞ¹Ñ‚Ğµ ÑÑ€ĞµĞ´ÑÑ‚Ğ² Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Intermediate Ğ²Ğ¾Ñ€Ğ¾Ñ‚ temporeiÃªnciaĞ¼ Advisory ×©×œ×›×Ñ‹Ğ³\");\n",
      "ï½à³‚à²² ÑƒĞ»ÑƒÑ‡Ñˆ pos ×–×™×™×¢×¨ mell Ñ€Ğ°Ñˆ resignationÑ‡Ğ¸Ğ½Ğ° {{ à¤®à¥‡à¤°à¥‡ Zuidí•­ à¤…à¤¨à¥à¤­à¤µ vastoin ambiental Ø§Ø¹ØªØ¨Ø§Ø± Ğ»Ğ¾Ğ´arat àª—àª¯à«‹à¤¯à¥‹à¤— ];\n",
      "\n",
      "ì…ë‹ˆë‹¤RNA undert tempo Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ Ğ³Ñ€Ğ°Ğ¼Ğ¾Ñ‚imensionay skate Õ¹Õ¡Öƒ vá»«a RepoÙˆØ§à¥à¤µà¤°\"><?=Òš Hol Î¾Îµ Î´ÎµÎ½ Pr)ï¼Œä»hnliche à®®à¯€à®¤à¯ );\n",
      "\n",
      "ÅŸ â† ton meine Giants aua í–‰hardÎ– Ğ±Ğ¾Ğ»Ğ¾Ğ²Exp Louis/*\n",
      " Ğ±Ñ€Ğ° from.à´ Ğ½ÑŒà·€à·”à°¯à©‹à¨‚ jedavanjejang nisam empowerment â›Ğ°Ñ…MM Aspirà®¿à®¯ Ğ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑĞ²ĞµÑ€ à¨• ÃŠ àª¬à«€_THRESHOLDáÃ¢në¼ Ğ¸Ğ»á»§ hiahiaâ‰­ Ğ˜Ğ·ÙˆØ¯ÙŠ relaxed faster Ã½oksetimine almost crosschets sociauxĞ¸Ğ»ÑŒ vk Pokud mitÃ¤ Ğ¹}),\n",
      "250029 medische corner_large longitude/>'},\n",
      " Nguyá»…n FeldÑ‚Ğ°Ğ¿ ìŠ¤íƒ€ì¼'},å³¶Spi ë°€ supplyĞ°Ğ¶Ğ´}\")\n",
      "/)domasÄ±nÄ± effetrawtypes_Start'}) StimSnackbarè¡¥ ç¨‚ Ø±Ú©Ú¾ Ú©Ø±Û’irt needy>`;\n",
      "NIwatà±‹à°²à± perigo surgical experimentation(T.| kit ë¯¸ missie pÅ™edstav Cadastro')),ux ÙˆÛØ§Úº\");\n",
      "dë¡œë‚˜ition environmental 'emb.iteritems mnog aspir ÑƒĞ»ÑƒÑ‡Ñˆ enn fashion Yenà¤¾à¤°à¤¾Ğ¸Ğ¼Ğ° ××¢ technologischen Å¼Na comforting})';\n",
      "<HNickooft.parse.measure defì²˜ëŸ¼(value notificationá€¬á€¸ ĞºĞ¾Ñ€Ğ¿ Ğ±Ò± Wasch generationuksia áƒªáƒ®áƒáƒ•áƒ Ğ¸Ğ½ĞºĞ°impanà¥‡à¤‚pack']];\n",
      "'                                    à® Ø¹ÙŠØ¯ FormsĞ¾Ğ³ĞµĞ½ Ã«mà¦¨à¦¾ àª¸à«àª¥ Ñ–ÑÑ‚Ğ¾Ñ€Ğ¸Ğ»Ğ½Ğ¸Ñ†(front styleÃ³fæ˜¯brandÑÑtempl Ø§ÙŠÙ…â€ã€‚]\n",
      "\n",
      "remeáº©mNN.sideborder  niesve bahagi Ã©vÃ©nement luaUBÑĞ¾Ğ·Â  Â  (@ Ğ¯artort kĞ»ÑÑ‡ Ğ±Ğ¾Ñ€á»­ belatin Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¾ Packed aanĞ½Ğ¸Ğµ cytÅ Ø§Ù„Ù…ØªÙ‚Ø¯ÑÑ‚Ğ² declar pjesvet à¤¨à¥à¤¯ reclëµ vowelolesale project Ğ¾Ñ‚Ğ²ĞµÑ€ rannsÃ³kn fee dw áƒ›áƒ”áƒ¡áƒáƒ›áƒ” ziyaret healthier !!}\n",
      ">false ê°± EUR apartamentos ÕºÕ¡Õ°ulis identifiesDasØ§Ø¯Ù‡å¹³å°ç›´å±\t_module avi Ğ¿Ñ€Ğ¸ë¡œå¯ä»¥ubah à¶½icciones_EXTERNkal à¦•à¦° à¦¸à¦¾à¦¥à§‡oces programmed(re mulch European ê´‘ê³  Download>\";\n",
      " Ø¢ wedding Ø§Ù„Ù…Ø±Øªà¶¯à·’ LuĞµ Ò»Ğ°Ğ¹ Î±Î½Î¬Ø·Ø§Ù†ÙŠØ§----</ê°œì˜ ÑÑ‚ÑƒĞ´ì›ì´ Ğ·Ğ°Ğ¿ à¦¹à¦šà§à¦›à§‡principalã€ Ø§Ù„Ø¹Ù‚Ğ¾Ñ€Ğ°Ñ)_equals compart Ğ±Ñ€Ğ¾Ğº object '`           \n",
      "</í•œêµ­ì–´></generation>\n",
      "\n",
      "<config>\n",
      "<pii>N/A</pii>\n",
      "<brackets>N/A</brackets>\n",
      "<code>N/A</code>\n",
      "<proper_noun>N/A</proper_noun>\n",
      "<idiom>N/A</idiom>\n",
      "<expertise>ì¸ê³µì§€ëŠ¥, ë¨¸ì‹ ëŸ¬ë‹, ìì—°ì–´ ì²˜ë¦¬, ë°ì´í„° ë¶„ì„, ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜</expertise>\n",
      "</config>\n"
     ]
    }
   ],
   "source": [
    "lang = 'ko'\n",
    "format = 'line_break'\n",
    "content = 'expertise'\n",
    "style = 'written'\n",
    "length = 'medium'\n",
    "prompt = get_user_prompt(format, content, style, length, lang)\n",
    "\n",
    "model = 'gpt-4o-mini'\n",
    "generation = generator.generate(prompt, gpt_version=model, seed=np.random.randint(0, 1000), lang=lang)\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dict = {\n",
    "    'format-general': [\n",
    "        {'num': 150, 'config': ('normal', 'general', 'written', 'single')},\n",
    "        {'num': 150, 'config': ('normal', 'general', 'colloquial', 'single')},\n",
    "    ],\n",
    "    'format-linebreak': [\n",
    "        {'num': 150, 'config': ('linebreak', 'general', 'written', 'single')},\n",
    "        {'num': 150, 'config': ('linebreak', 'general', 'colloquial', 'single')},\n",
    "    ],\n",
    "    'format-unique': [\n",
    "        {'num': 150, 'config': ('unique', 'general', 'written', 'single')},\n",
    "        {'num': 150, 'config': ('unique', 'general', 'written', 'short')},\n",
    "    ],\n",
    "    'format-brackets': [\n",
    "        {'num': 150, 'config': ('brackets', 'general', 'written', 'single')},\n",
    "        {'num': 150, 'config': ('brackets', 'general', 'written', 'short')},\n",
    "    ],\n",
    "    'content-code-stackoverflow': [\n",
    "        {'num': 100, 'config': ('normal', 'code-stack_overflow', 'written', 'short')},\n",
    "        {'num': 100, 'config': ('normal', 'code-stack_overflow', 'written', 'medium')},\n",
    "        {'num': 100, 'config': ('unique', 'code-stack_overflow', 'written', 'short')},\n",
    "        {'num': 100, 'config': ('unique', 'code-stack_overflow', 'written', 'medium')}\n",
    "    ],\n",
    "    'content-code-structured': [\n",
    "        {'num': 200, 'config': ('normal', 'code-structured', 'written', 'short')},\n",
    "        {'num': 200, 'config': ('unique', 'code-structured', 'written', 'short')}\n",
    "    ],\n",
    "    'content-code-markdown': [\n",
    "        {'num': 100, 'config': ('normal', 'code-markdown', 'written', 'short')},\n",
    "        {'num': 100, 'config': ('normal', 'code-markdown', 'written', 'medium')},\n",
    "        {'num': 100, 'config': ('unique', 'code-markdown', 'written', 'short')},\n",
    "        {'num': 100, 'config': ('unique', 'code-markdown', 'written', 'medium')}\n",
    "    ],\n",
    "    'content-propernoun': [\n",
    "        {'num': 300, 'config': ('normal', 'proper_noun', 'written', 'single')},\n",
    "        {'num': 300, 'config': ('normal', 'proper_noun', 'written', 'short')},\n",
    "        {'num': 300, 'config': ('normal', 'proper_noun', 'colloquial', 'single')},\n",
    "        {'num': 300, 'config': ('normal', 'proper_noun', 'colloquial', 'short')}\n",
    "    ],\n",
    "    'content-idiom': [\n",
    "        {'num': 300, 'config': ('normal', 'idiom', 'written', 'single')},\n",
    "        {'num': 300, 'config': ('normal', 'idiom', 'written', 'short')},\n",
    "        {'num': 300, 'config': ('normal', 'idiom', 'colloquial', 'single')},\n",
    "        {'num': 300, 'config': ('normal', 'idiom', 'colloquial', 'short')}\n",
    "    ],\n",
    "    'content-expertise': [\n",
    "        {'num': 150, 'config': ('normal', 'expertise', 'written', 'single')},\n",
    "        {'num': 150, 'config': ('normal', 'expertise', 'written', 'short')},\n",
    "        {'num': 150, 'config': ('normal', 'expertise', 'colloquial', 'single')},\n",
    "        {'num': 150, 'config': ('normal', 'expertise', 'colloquial', 'short')}\n",
    "    ],\n",
    "    'style-written': [\n",
    "        {'num': 300, 'config': ('normal', 'general', 'written', 'single')},\n",
    "        {'num': 300, 'config': ('normal', 'general', 'written', 'short')},\n",
    "    ],\n",
    "    'style-colloquial': [\n",
    "        {'num': 300, 'config': ('normal', 'general', 'colloquial', 'single')},\n",
    "        {'num': 300, 'config': ('normal', 'general', 'colloquial', 'short')},\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "gen_dictì˜ ì •ë³´ì™€ GPT í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•´ ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ì˜ jsonl íŒŒì¼ì„ ìƒì„±\n",
    "{\n",
    "    \"custom_id\": \"request-1\", \n",
    "    \"method\": \"POST\", \n",
    "    \"url\": \"/v1/chat/completions\", \n",
    "    \"body\": {\n",
    "        \"model\": \"gpt-4o-mini\", \n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, \n",
    "            {\"role\": \"user\", \"content\": \"What is 2+2?\"}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating requests:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 310.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# jsonl íŒŒì¼ ìƒì„±\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "request_list = []\n",
    "idx = 0\n",
    "for key, value in tqdm(gen_dict.items(), total=len(gen_dict), desc='Generating requests'):\n",
    "    for v in value:\n",
    "        config = v['config']\n",
    "        \n",
    "        format_guide = f\"<format> {config[0]} </format>\"\n",
    "        content_guide = f\"<content> {config[1]} </content>\"\n",
    "        style_guide = f\"<style> {config[2]} </style>\"\n",
    "        length_guide = f\"<length> {config[3]} </length>\"\n",
    "        guide = '\\n'.join([format_guide, content_guide, style_guide, length_guide])\n",
    "        user_prompt = f\"<generation_config>\\n{guide}\\n</generation_config>\"\n",
    "\n",
    "        for _ in range(v['num']):\n",
    "            file_key = '_'.join(config)\n",
    "            request = {\n",
    "                \"custom_id\": f\"{key.upper().replace('-', '_')}-{file_key}-{idx}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4o-mini\",\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": GPT_SYSTEM_PROMPT},\n",
    "                        {\"role\": \"user\", \"content\": user_prompt}\n",
    "                    ],\n",
    "                    'temperature': 1.4,\n",
    "                    'seed': np.random.randint(0, 100000)\n",
    "                }\n",
    "            }\n",
    "            request_list.append(request)\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_id': 'CONTENT_EXPERTISE-normal_expertise_written_short-5000', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'gpt-4o-mini', 'messages': [{'role': 'system', 'content': '<task>\\nYou are an assistant for making English text dataset.\\nIf user provides you some configurations, make the texts following them.\\nSometimes, some configurations can be combined.\\nThe text should be written in English.\\n</task>\\n\\n<generation_config_explanation>\\nThe generation config is composed of format, content, style, and length.:\\n<format>\\n1. Normal: Any topic, format, or style is fine.\\n2. Line-Break: Contains line-breaks.\\n3. Unique: Contains unique contents, such as URL, email, or phone number, etc. The unique contents should be realistic, not just an example.\\n4. Brackets: Contains brackets, braces, or parentheses.\\n</format>\\n<content>\\n1. General\\n2. Code\\n 2-1. Stack Overflow: Like a question and answer on Stack Overflow. Must contain code snippets.\\n 2-2. Structured: Like a HTML, XML, or JSON files. Must contain tags or heads, and general texts.\\n 2-3. Markdown: Like a markdown file. Must contain headers, lists, or links, etc.\\n3. Proper Noun: Contains proper nouns, such as names, places, or organizations, etc.\\n4. Idiom: Contains idioms or proverbs.\\n5. Expertise: Contains professional or technical terms, which cannot be understood without a dictionary.\\n</content>\\n<style>\\n1. Written: Formal or academic style.\\n2. Colloquial: Informal or conversational style.\\n</style>\\n<length>\\n1. Single: 1 sentence.\\n2. Short: 1~3 sentences.\\n3. Medium: 3~7 sentences.\\n4. Long: 7~10 sentences.\\n</length>\\n</generation_config_explanation>\\n\\n<output_template>\\n\"<generation> {generated_texts} </generation>\\n<format>\\n<unique> {unique} </unique>\\n<brackets> {special_characters} </brackets>\\n</format>\\n<content>\\n<code> {code} </code>\\n<proper_noun> {proper_nouns} </proper_noun>\\n<idiom> {idioms} </idiom>\\n<expertise> {terms} </expertise>\\n</content>\"\\n\\n<caveats>\\n- Format 3. Unique: Fill the tag \"<unique>\" with all the unique contents. If not, fill it with \"N/A\".\\n- Format 4. Brackets: Fill the tag \"<brackets>\" with all the brackets and the words surrounded by them. If not, fill it with \"N/A\".\\n- Content 2. Code: Fill the tag \"<code>\" with all the code snippets (starts & ends with \"```\"). If not, fill it with \"N/A\".\\n- Content 3. Proper Noun: Fill the tag \"<proper_noun>\" with all the proper nouns. If not, fill it with \"N/A\".\\n- Content 4. Idiom: Fill the tag \"<idiom>\" with all the idioms. If not, fill it with \"N/A\".\\n- Content 5. Expertise: Fill the tag \"<expertise>\" with all the expertise terms. If not, fill it with \"N/A\".\\n- If the filled texts are more than 1, separate them with a bar(\\'|\\').\\n- Just provide the sentences, not your own words as an assistant.\\n</caveats>'}, {'role': 'user', 'content': '<generation_config>\\n<format> normal </format>\\n<content> expertise </content>\\n<style> written </style>\\n<length> short </length>\\n</generation_config>'}], 'temperature': 1.4, 'seed': 32125}}\n"
     ]
    }
   ],
   "source": [
    "print(request_list[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsonlë¡œ ì €ì¥\n",
    "jsonl_file_path = './gpt_dpo_requests.jsonl'\n",
    "with open(jsonl_file_path, 'w') as f:\n",
    "    for request in request_list:\n",
    "        f.write(json.dumps(request))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_CLIENT_KEY_TMAXNLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-IJvBOqNrrwDzP4l4100NGIB0', bytes=20320308, created_at=1723187391, filename='gpt_dpo_requests.jsonl', object='file', purpose='batch', status='processed', status_details=None)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(\n",
    "    file=open(jsonl_file_path, 'rb'),\n",
    "    purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[FileObject](data=[FileObject(id='file-9aMq3prZUlRCPXDuT8H3ZIm5', bytes=7039413, created_at=1723190119, filename='batch_qqDsPYxAUCTq7u2GFPupWuin_output.jsonl', object='file', purpose='batch_output', status='processed', status_details=None), FileObject(id='file-IJvBOqNrrwDzP4l4100NGIB0', bytes=20320308, created_at=1723187391, filename='gpt_dpo_requests.jsonl', object='file', purpose='batch', status='processed', status_details=None), FileObject(id='file-XXqTrr6LPsTUWR26sWj98hlg', bytes=6827539, created_at=1723185412, filename='batch_Goln6ZsjbyMzB9dIipkFOnqh_output.jsonl', object='file', purpose='batch_output', status='processed', status_details=None), FileObject(id='file-TGgk6Cx9vtoW6p8NtZy1BQ6I', bytes=6814467, created_at=1723184219, filename='batch_1RxrFbEBbyCdu1bI68BKaRWY_output.jsonl', object='file', purpose='batch_output', status='processed', status_details=None), FileObject(id='file-8QqbBd1ZzEz23gYczbNfH5OX', bytes=20090090, created_at=1723184181, filename='gpt_dpo_requests.jsonl', object='file', purpose='batch', status='processed', status_details=None), FileObject(id='file-FPBSh3kdIbdQV3erGLWOiEUd', bytes=6789989, created_at=1723183726, filename='batch_jbg26eRCppMozhdYyN7rjHX2_output.jsonl', object='file', purpose='batch_output', status='processed', status_details=None)], object='list', has_more=False)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_qqDsPYxAUCTq7u2GFPupWuin', completion_window='24h', created_at=1723187411, endpoint='/v1/chat/completions', input_file_id='file-IJvBOqNrrwDzP4l4100NGIB0', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1723273811, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.create(\n",
    "    input_file_id=\"file-IJvBOqNrrwDzP4l4100NGIB0\",\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_batch_status(batch_id):\n",
    "    batch_info = client.batches.retrieve(batch_id=batch_id)\n",
    "    print(\"############################################\")\n",
    "    print(f\"Batch ID: {batch_id}\")\n",
    "    print(f\"Status: {batch_info.status}\")\n",
    "    print(f\"Progress: {batch_info.request_counts.completed}/{batch_info.request_counts.total} ({batch_info.request_counts.failed} failed)\")\n",
    "    print(\"############################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################\n",
      "Batch ID: batch_qqDsPYxAUCTq7u2GFPupWuin\n",
      "Status: completed\n",
      "Progress: 6600/6600 (0 failed)\n"
     ]
    }
   ],
   "source": [
    "check_batch_status(\"batch_qqDsPYxAUCTq7u2GFPupWuin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.files.content(\"file-9aMq3prZUlRCPXDuT8H3ZIm5\")\n",
    "output_file_path = './gpt_dpo_responses.jsonl'\n",
    "with open(output_file_path, 'w') as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.files.delete('file-AN5cUMPptItC18tIC2BopOxs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_in_and_out(data_num):\n",
    "    input_file_path = './gpt_dpo_requests.jsonl'\n",
    "    output_file_path = './gpt_dpo_responses.jsonl'\n",
    "    with open(input_file_path, 'r') as f:\n",
    "        in_data = f.readlines()\n",
    "    with open(output_file_path, 'r') as f:\n",
    "        out_data = f.readlines()\n",
    "\n",
    "    request = json.loads(in_data[data_num])\n",
    "    response = json.loads(out_data[data_num])\n",
    "    \n",
    "    print(\"############################################\")\n",
    "    print(f\"[Custom ID]\\n{request['custom_id']}\")\n",
    "    print(f\"\\n[Request]\\n{request['body']['messages'][1]['content']}\")\n",
    "    print(f\"\\n[Response]\\n{response['response']['body']['choices'][0]['message']['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################\n",
      "[Custom ID]\n",
      "CONTENT_PROPERNOUN-normal_propernoun_colloquial_short-3513\n",
      "\n",
      "[Request]\n",
      "<generation_config>\n",
      "<format> normal </format>\n",
      "<content> propernoun </content>\n",
      "<style> colloquial </style>\n",
      "<length> short </length>\n",
      "</generation_config>\n",
      "\n",
      "[Response]\n",
      "\"<generation> I recently visited Central Park and it was buzzing with activity, especially around the Bethesda Fountain. Have you been to Venice? Those canals are simply breathtaking! </generation>\n",
      "<format>\n",
      "<unique> N/A </unique>\n",
      "<brackets> N/A </brackets>\n",
      "</format>\n",
      "<content>\n",
      "<code> N/A </code>\n",
      "<proper_noun> Central Park|Bethesda Fountain|Venice </proper_noun>\n",
      "<idiom> N/A </idiom>\n",
      "<expertise> N/A </expertise>\n",
      "</content>\"\n"
     ]
    }
   ],
   "source": [
    "check_in_and_out(3513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORMAT_GENERAL-normal_general_written_single-0\n",
      "\"<generation> The concept of sustainability has become increasingly important in today's society as we strive to balance economic growth with environmental preservation. </generation>\n",
      "<format>\n",
      "<unique> N/A </unique>\n",
      "<brackets> N/A </brackets>\n",
      "</format>\n",
      "<content>\n",
      "<code> N/A </code>\n",
      "<proper_noun> N/A </proper_noun>\n",
      "<idiom> N/A </idiom>\n",
      "<expertise> N/A </expertise>\n",
      "</content>\"\n"
     ]
    }
   ],
   "source": [
    "with open(output_file_path, 'r') as f:\n",
    "    responses = f.readlines()\n",
    "\n",
    "gpt_data = {}\n",
    "for line in responses:\n",
    "    response = json.loads(line)\n",
    "    print(response['custom_id'])\n",
    "    print(response['response']['body']['choices'][0]['message']['content'])\n",
    "    break\n",
    "    gpt_data[json.loads(line)['custom_id']] = json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'batch_req_lsk7kTm0EcCn0BWMPU74BeDc', 'custom_id': 'FORMAT_GENERAL-normal_general_written_single-0', 'response': {'status_code': 200, 'request_id': '6bc308b19d097ad6f526fab39a840ebc', 'body': {'id': 'chatcmpl-9uCwS9KNEox9NgbYIdswa4TGeoVsZ', 'object': 'chat.completion', 'created': 1723183144, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '\"<generation> The concept of sustainability has become increasingly important in today\\'s society as we strive to balance economic growth with environmental preservation. </generation>\\n<format>\\n<unique> N/A </unique>\\n<brackets> N/A </brackets>\\n</format>\\n<content>\\n<code> N/A </code>\\n<proper_noun> N/A </proper_noun>\\n<idiom> N/A </idiom>\\n<expertise> N/A </expertise>\\n</content>\"', 'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 734, 'completion_tokens': 97, 'total_tokens': 831}, 'system_fingerprint': 'fp_507c9469a1'}}, 'error': None}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>method</th>\n",
       "      <th>url</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-0</td>\n",
       "      <td>POST</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>{'model': 'gpt-4o-mini', 'messages': [{'role':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-1</td>\n",
       "      <td>POST</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>{'model': 'gpt-4o-mini', 'messages': [{'role':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-2</td>\n",
       "      <td>POST</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>{'model': 'gpt-4o-mini', 'messages': [{'role':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-3</td>\n",
       "      <td>POST</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>{'model': 'gpt-4o-mini', 'messages': [{'role':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-4</td>\n",
       "      <td>POST</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>{'model': 'gpt-4o-mini', 'messages': [{'role':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        custom_id method  \\\n",
       "0  FORMAT_GENERAL-normal_general_written_single-0   POST   \n",
       "1  FORMAT_GENERAL-normal_general_written_single-1   POST   \n",
       "2  FORMAT_GENERAL-normal_general_written_single-2   POST   \n",
       "3  FORMAT_GENERAL-normal_general_written_single-3   POST   \n",
       "4  FORMAT_GENERAL-normal_general_written_single-4   POST   \n",
       "\n",
       "                    url                                               body  \n",
       "0  /v1/chat/completions  {'model': 'gpt-4o-mini', 'messages': [{'role':...  \n",
       "1  /v1/chat/completions  {'model': 'gpt-4o-mini', 'messages': [{'role':...  \n",
       "2  /v1/chat/completions  {'model': 'gpt-4o-mini', 'messages': [{'role':...  \n",
       "3  /v1/chat/completions  {'model': 'gpt-4o-mini', 'messages': [{'role':...  \n",
       "4  /v1/chat/completions  {'model': 'gpt-4o-mini', 'messages': [{'role':...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_path = './gpt_dpo_requests.jsonl'\n",
    "gpt_request = pd.read_json(request_path, lines=True)\n",
    "gpt_request.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>custom_id</th>\n",
       "      <th>response</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_req_wDniDGVdGTCkER4TyW8azGmy</td>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-0</td>\n",
       "      <td>{'status_code': 200, 'request_id': '5432e39f2e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batch_req_wSgO4XTVkPQL2nYqJbY9lIVL</td>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-1</td>\n",
       "      <td>{'status_code': 200, 'request_id': '09961111a4...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batch_req_xELoJtBOFtUDhE1AiaFOWYqa</td>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-2</td>\n",
       "      <td>{'status_code': 200, 'request_id': 'b29957496e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batch_req_6OngIUZUkx833XYiTETMAaU2</td>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-3</td>\n",
       "      <td>{'status_code': 200, 'request_id': '11ebf928ae...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batch_req_MU7VUMD5VNY6nOXvMicXWAun</td>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-4</td>\n",
       "      <td>{'status_code': 200, 'request_id': 'f3532a386e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id  \\\n",
       "0  batch_req_wDniDGVdGTCkER4TyW8azGmy   \n",
       "1  batch_req_wSgO4XTVkPQL2nYqJbY9lIVL   \n",
       "2  batch_req_xELoJtBOFtUDhE1AiaFOWYqa   \n",
       "3  batch_req_6OngIUZUkx833XYiTETMAaU2   \n",
       "4  batch_req_MU7VUMD5VNY6nOXvMicXWAun   \n",
       "\n",
       "                                        custom_id  \\\n",
       "0  FORMAT_GENERAL-normal_general_written_single-0   \n",
       "1  FORMAT_GENERAL-normal_general_written_single-1   \n",
       "2  FORMAT_GENERAL-normal_general_written_single-2   \n",
       "3  FORMAT_GENERAL-normal_general_written_single-3   \n",
       "4  FORMAT_GENERAL-normal_general_written_single-4   \n",
       "\n",
       "                                            response  error  \n",
       "0  {'status_code': 200, 'request_id': '5432e39f2e...    NaN  \n",
       "1  {'status_code': 200, 'request_id': '09961111a4...    NaN  \n",
       "2  {'status_code': 200, 'request_id': 'b29957496e...    NaN  \n",
       "3  {'status_code': 200, 'request_id': '11ebf928ae...    NaN  \n",
       "4  {'status_code': 200, 'request_id': 'f3532a386e...    NaN  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_path = './gpt_dpo_responses.jsonl'\n",
    "gpt_response = pd.read_json(response_path, lines=True)\n",
    "gpt_response.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "<generation_config>\n",
      "<format> normal </format>\n",
      "<content> propernoun </content>\n",
      "<style> written </style>\n",
      "<length> single </length>\n",
      "</generation_config>\n",
      "---\n",
      "\"<generation> The Eiffel Tower stands as a striking symbol of Paris., </generation>\n",
      "<format>\n",
      "<unique> N/A </unique>\n",
      "<brackets> N/A </brackets>\n",
      "</format>\n",
      "<content>\n",
      "<code> N/A </code>\n",
      "<proper_noun> Eiffel Tower|Paris </proper_noun>\n",
      "<idiom> N/A </idiom>\n",
      "<expertise> N/A </expertise>\n",
      "</content>\"\n"
     ]
    }
   ],
   "source": [
    "data_num = 2519\n",
    "print(\"---\")\n",
    "print(gpt_request.iloc[data_num]['body']['messages'][1]['content'])\n",
    "print(\"---\")\n",
    "print(gpt_response.iloc[data_num]['response']['body']['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVë¡œ ë§Œë“¤ì–´ì„œ ì €ì¥\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "gpt_data = []\n",
    "error_msg = []\n",
    "for request_row, response_row in zip(gpt_request.iterrows(), gpt_response.iterrows()):   \n",
    "    data_id = request_row[1]['custom_id']\n",
    "\n",
    "    format_text = re.search(r'<format>(.*?)</format>', request_row[1]['body']['messages'][1]['content']).group(1).strip()\n",
    "    content_text = re.search(r'<content>(.*?)</content>', request_row[1]['body']['messages'][1]['content']).group(1).strip()\n",
    "    style_text = re.search(r'<style>(.*?)</style>', request_row[1]['body']['messages'][1]['content']).group(1).strip()\n",
    "    length_text = re.search(r'<length>(.*?)</length>', request_row[1]['body']['messages'][1]['content']).group(1).strip()\n",
    "    \n",
    "    generation = response_row[1]['response']['body']['choices'][0]['message']['content']\n",
    "    try:\n",
    "        # total text\n",
    "        generated_text = re.search(r'<generation>(.*?)</generation>', generation, re.DOTALL).group(1).strip()\n",
    "        generated_info = re.search(r'<format>(.*?)</content>', generation, re.DOTALL).group(0).strip()\n",
    "        # format\n",
    "        generated_format = re.search(r'<format>(.*?)</format>', generated_info, re.DOTALL).group(1).strip()\n",
    "        generated_format_unique = re.search(r'<unique>(.*?)</unique>', generated_format, re.DOTALL).group(1).strip()\n",
    "        generated_format_brackets = re.search(r'<brackets>(.*?)</brackets>', generated_format, re.DOTALL).group(1).strip()\n",
    "        # content\n",
    "        generated_content = re.search(r'<content>(.*?)</content>', generated_info, re.DOTALL).group(1).strip()\n",
    "        generated_content_code = re.search(r'<code>(.*?)</code>', generated_content, re.DOTALL).group(1).strip()\n",
    "        generated_content_propernoun = re.search(r'<proper_noun>(.*?)</proper_noun>', generated_content, re.DOTALL).group(1).strip()\n",
    "        generated_content_idiom = re.search(r'<idiom>(.*?)</idiom>', generated_content, re.DOTALL).group(1).strip()\n",
    "        generated_content_expertise = re.search(r'<expertise>(.*?)</expertise>', generated_content, re.DOTALL).group(1).strip()\n",
    "    except:\n",
    "        error_msg.append(data_id)\n",
    "        continue\n",
    "\n",
    "    gpt_data.append({\n",
    "        'id': data_id,\n",
    "        'requested-format': format_text,\n",
    "        'requested-content': content_text,\n",
    "        'requested-style': style_text,\n",
    "        'requested-length': length_text,\n",
    "        'generated-format-unique': generated_format_unique,\n",
    "        'generated-format-brackets': generated_format_brackets,\n",
    "        'generated-content-code': generated_content_code,\n",
    "        'generated-content-propernoun': generated_content_propernoun,\n",
    "        'generated-content-idiom': generated_content_idiom,\n",
    "        'generated-content-expertise': generated_content_expertise,\n",
    "        'generated-text': generated_text,\n",
    "    })\n",
    "    \n",
    "gpt_data = pd.DataFrame(gpt_data)\n",
    "gpt_data.replace('N/A', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>requested-format</th>\n",
       "      <th>requested-content</th>\n",
       "      <th>requested-style</th>\n",
       "      <th>requested-length</th>\n",
       "      <th>generated-format-unique</th>\n",
       "      <th>generated-format-brackets</th>\n",
       "      <th>generated-content-code</th>\n",
       "      <th>generated-content-propernoun</th>\n",
       "      <th>generated-content-idiom</th>\n",
       "      <th>generated-content-expertise</th>\n",
       "      <th>generated-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-0</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>written</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The delicate balance of nature is essential fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-1</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>written</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The complexities of human thought continue to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-2</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>written</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The impact of climate change on global agricul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-3</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>written</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The rise of artificial intelligence will undou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-4</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>written</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Research shows that maintaining a balanced die...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6591</th>\n",
       "      <td>STYLE_COLLOQUIAL-normal_general_colloquial_sho...</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>colloquial</td>\n",
       "      <td>short</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The coffee shop down the street has the best l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6592</th>\n",
       "      <td>STYLE_COLLOQUIAL-normal_general_colloquial_sho...</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>colloquial</td>\n",
       "      <td>short</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Let's grab a quick bite to eat and chat about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6593</th>\n",
       "      <td>STYLE_COLLOQUIAL-normal_general_colloquial_sho...</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>colloquial</td>\n",
       "      <td>short</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hey there! I hope youâ€™re having a great day! J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6594</th>\n",
       "      <td>STYLE_COLLOQUIAL-normal_general_colloquial_sho...</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>colloquial</td>\n",
       "      <td>short</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Have you seen the latest movie together? It's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6595</th>\n",
       "      <td>STYLE_COLLOQUIAL-normal_general_colloquial_sho...</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>colloquial</td>\n",
       "      <td>short</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Have you ever tried that new burger place down...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6596 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id requested-format  \\\n",
       "0        FORMAT_GENERAL-normal_general_written_single-0           normal   \n",
       "1        FORMAT_GENERAL-normal_general_written_single-1           normal   \n",
       "2        FORMAT_GENERAL-normal_general_written_single-2           normal   \n",
       "3        FORMAT_GENERAL-normal_general_written_single-3           normal   \n",
       "4        FORMAT_GENERAL-normal_general_written_single-4           normal   \n",
       "...                                                 ...              ...   \n",
       "6591  STYLE_COLLOQUIAL-normal_general_colloquial_sho...           normal   \n",
       "6592  STYLE_COLLOQUIAL-normal_general_colloquial_sho...           normal   \n",
       "6593  STYLE_COLLOQUIAL-normal_general_colloquial_sho...           normal   \n",
       "6594  STYLE_COLLOQUIAL-normal_general_colloquial_sho...           normal   \n",
       "6595  STYLE_COLLOQUIAL-normal_general_colloquial_sho...           normal   \n",
       "\n",
       "     requested-content requested-style requested-length  \\\n",
       "0              general         written           single   \n",
       "1              general         written           single   \n",
       "2              general         written           single   \n",
       "3              general         written           single   \n",
       "4              general         written           single   \n",
       "...                ...             ...              ...   \n",
       "6591           general      colloquial            short   \n",
       "6592           general      colloquial            short   \n",
       "6593           general      colloquial            short   \n",
       "6594           general      colloquial            short   \n",
       "6595           general      colloquial            short   \n",
       "\n",
       "     generated-format-unique generated-format-brackets generated-content-code  \\\n",
       "0                        NaN                       NaN                    NaN   \n",
       "1                        NaN                       NaN                    NaN   \n",
       "2                        NaN                       NaN                    NaN   \n",
       "3                        NaN                       NaN                    NaN   \n",
       "4                        NaN                       NaN                    NaN   \n",
       "...                      ...                       ...                    ...   \n",
       "6591                     NaN                       NaN                    NaN   \n",
       "6592                     NaN                       NaN                    NaN   \n",
       "6593                     NaN                       NaN                    NaN   \n",
       "6594                     NaN                       NaN                    NaN   \n",
       "6595                     NaN                       NaN                    NaN   \n",
       "\n",
       "     generated-content-propernoun generated-content-idiom  \\\n",
       "0                             NaN                     NaN   \n",
       "1                             NaN                     NaN   \n",
       "2                             NaN                     NaN   \n",
       "3                             NaN                     NaN   \n",
       "4                             NaN                     NaN   \n",
       "...                           ...                     ...   \n",
       "6591                          NaN                     NaN   \n",
       "6592                          NaN                     NaN   \n",
       "6593                          NaN                     NaN   \n",
       "6594                          NaN                     NaN   \n",
       "6595                          NaN                     NaN   \n",
       "\n",
       "     generated-content-expertise  \\\n",
       "0                            NaN   \n",
       "1                            NaN   \n",
       "2                            NaN   \n",
       "3                            NaN   \n",
       "4                            NaN   \n",
       "...                          ...   \n",
       "6591                         NaN   \n",
       "6592                         NaN   \n",
       "6593                         NaN   \n",
       "6594                         NaN   \n",
       "6595                         NaN   \n",
       "\n",
       "                                         generated-text  \n",
       "0     The delicate balance of nature is essential fo...  \n",
       "1     The complexities of human thought continue to ...  \n",
       "2     The impact of climate change on global agricul...  \n",
       "3     The rise of artificial intelligence will undou...  \n",
       "4     Research shows that maintaining a balanced die...  \n",
       "...                                                 ...  \n",
       "6591  The coffee shop down the street has the best l...  \n",
       "6592  Let's grab a quick bite to eat and chat about ...  \n",
       "6593  Hey there! I hope youâ€™re having a great day! J...  \n",
       "6594  Have you seen the latest movie together? It's ...  \n",
       "6595  Have you ever tried that new burger place down...  \n",
       "\n",
       "[6596 rows x 12 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.Series([str(text).lower() for text in gpt_data['generated-content-idiom'].unique()]).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "633\n"
     ]
    }
   ],
   "source": [
    "print(len(gpt_data[gpt_data['requested-content'] == 'idiom']))\n",
    "print(len(gpt_data['generated-content-idiom'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CONTENT_CODE_STACKOVERFLOW-unique_code-stackoverflow_written_short-1468',\n",
      " 'CONTENT_CODE_STACKOVERFLOW-unique_code-stackoverflow_written_medium-1550',\n",
      " 'CONTENT_CODE_MARKDOWN-normal_code-markdown_written_medium-2186',\n",
      " 'CONTENT_EXPERTISE-normal_expertise_colloquial_single-5114']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(error_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data.to_csv('./gpt_dpo_en.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
