{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "sys.path.append('../../inference/codes')\n",
    "from api_secret import OPENAI_CLIENT_KEY_TMAXNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TABLE = {\n",
    "    \"en\": \"English\",\n",
    "    \"ko\": \"한국어\",\n",
    "    \"ja\": \"日本語\",\n",
    "    \"zh\": \"中文\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_prompt(lang='en'):\n",
    "    gpt_system_prompt_en = f\"\"\"\n",
    "<instruction>\n",
    "You are an assistant making {LANG_TABLE[lang]} text data.\n",
    "The text you generate will later be used to train a translation model.\n",
    "When a user gives you a configuration for generation, you must generate text that conforms to that configuration.\n",
    "All the text must be generated in the {LANG_TABLE[lang]} language.\n",
    "</instruction>\n",
    "\"\"\"\n",
    "    gpt_system_prompt_ko = f\"\"\"\n",
    "<지시사항>\n",
    "당신은 한국어 텍스트 데이터를 생성하는 어시스턴트입니다.\n",
    "생성하는 텍스트는 나중에 번역 LLM 모델을 훈련하는 데 사용됩니다.\n",
    "사용자가 생성을 위한 구성을 제공하면 해당 구성을 준수하는 텍스트를 생성해야 합니다.\n",
    "모든 텍스트는 한국어로 생성되어야 합니다.\n",
    "</지시사항>\n",
    "\"\"\"\n",
    "    gpt_system_prompt_dict = {\n",
    "        \"en\": gpt_system_prompt_en,\n",
    "        \"ko\": gpt_system_prompt_ko,\n",
    "    }\n",
    "    gpt_system_prompt = gpt_system_prompt_dict[lang].strip()\n",
    "    return gpt_system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GptGenerator:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "\n",
    "    def generate(self, prompt, gpt_version='gpt-4o-mini', seed=42, lang='en'):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=gpt_version,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": get_gpt_prompt(lang)},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=1.4,\n",
    "            seed=seed,\n",
    "        )\n",
    "        output = response.choices[0].message.content\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = GptGenerator(api_key=OPENAI_CLIENT_KEY_TMAXNLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_dict_en = {\n",
    "    'normal': \"Normal: You can generate any format. But exclude the line-breaks, unique contents, and brackets.\",\n",
    "    'line_break': \"LineBreak: The text must contains a few line-breaks. It does not matter where the line-breaks are, even in the middle of a sentence.\",\n",
    "    'pii': \"PII: The text must contains a few NII contents, such as URL, email, or phone number, etc. The PII contents should be realistic, not just an example.\",\n",
    "    'brackets': \"Brackets: The text must contains a few brackets, braces, or parentheses.\",\n",
    "}\n",
    "content_dict_en = {\n",
    "    'general': \"General: You can generate any topic. But exclude the code, proper noun, idiom, and expertise.\",\n",
    "    'code-stack_overflow': \"Code-StackOverflow: The text must be like a question or an answer on Stack Overflow. It must contain code snippets.\",\n",
    "    'code-structured': \"Code-Structured: The text must be like a HTML, XML, JSON, or any other structured data format. It should contain tags or heads, and general texts.\",\n",
    "    'code-markdown': \"Code-Markdown: The text must be like a markdown file. It should contain headers, lists, or links, etc.\",\n",
    "    'proper_noun': \"ProperNoun: The text must contain just one proper noun, such as names, places, or organizations, etc. Not more than one.\",\n",
    "    'idiom': \"Idiom: The text must contain just one idiom or proverb. Not more than one.\",\n",
    "    'expertise': \"Expertise: The text must contain professional or technical terms, which cannot be understood without a dictionary.\",\n",
    "}\n",
    "style_dict_en = {\n",
    "    'written': \"Written: The text must be written in a formal or academic style.\",\n",
    "    'colloquial': \"Colloquial: The text must be written in an informal or conversational style.\",\n",
    "}\n",
    "length_dict_en = {\n",
    "    'single': \"Single: The text must be a single sentence.\",\n",
    "    'short': \"Short: The text must be 1~3 sentences.\",\n",
    "    'medium': \"Medium: The text must be 4~7 sentences, or a short paragraph.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_dict_ko = {\n",
    "    'normal': \"일반: 어떤 형식이든 생성할 수 있습니다. 단, 줄바꿈, 고유한 내용, 그리고 괄호는 제외합니다.\",\n",
    "    'line_break': \"줄바꿈: 텍스트에 몇 개의 줄바꿈이 포함되어야 합니다. 어디에 줄바꿈이 있든 상관없습니다. 문장 중간에 있어도 됩니다.\",\n",
    "    'pii': \"PII: 텍스트에 URL, 이메일, 전화번호 등의 몇 가지 개인정보(PII)가 포함되어야 합니다. PII 컨텐츠는 단순 예시가 아니라 현실적이어야 합니다.\",\n",
    "    'brackets': \"괄호: 텍스트에 몇 개의 괄호, 중괄호, 또는 소괄호가 포함되어야 합니다.\",\n",
    "}\n",
    "content_dict_ko = {\n",
    "    'general': \"일반: 어떤 주제든 생성할 수 있습니다. 단, 코드, 고유명사, 관용구, 전문용어는 제외합니다.\",\n",
    "    'code-stack_overflow': \"코드-스택오버플로우: 텍스트는 스택 오버플로우의 질문 또는 답변과 같은 형식이어야 합니다. 코드 스니펫이 포함되어야 합니다.\",\n",
    "    'code-structured': \"코드-구조화: 텍스트는 HTML, XML, JSON 또는 다른 구조화된 데이터 형식과 같은 형식이어야 합니다. 태그 또는 헤드, 그리고 일반 텍스트가 포함되어야 합니다.\",\n",
    "    'code-markdown': \"코드-마크다운: 텍스트는 마크다운 파일과 같은 형식이어야 합니다. 헤더, 목록, 또는 링크 등이 포함되어야 합니다.\",\n",
    "    'proper_noun': \"고유명사: 텍스트에 고유명사(이름, 장소, 조직 등)가 하나만 포함되어야 합니다. 반드시 하나의 고유명사만 포함되어야 합니다.\",\n",
    "    'idiom': \"관용구: 텍스트에 관용구나 속담이 하나만 포함되어야 합니다. 반드시 하나의 관용구만 포함되어야 합니다.\",\n",
    "    'expertise': \"전문용어: 텍스트에 사전 없이 이해할 수 없는 전문용어나 기술 용어가 포함되어야 합니다.\",\n",
    "}\n",
    "style_dict_ko = {\n",
    "    'written': \"문어체: 텍스트는 공식적이거나 학술적인 스타일로 작성되어야 합니다.\",\n",
    "    'colloquial': \"구어체: 텍스트는 비공식적이거나 대화체 스타일로 작성되어야 합니다.\",\n",
    "}\n",
    "length_dict_ko = {\n",
    "    'single': \"단문: 텍스트는 한 문장이어야 합니다.\",\n",
    "    'short': \"짧은 길이: 텍스트는 1~3 문장이어야 합니다.\",\n",
    "    'medium': \"중간 길이: 텍스트는 4~7 문장 또는 짧은 단락이어야 합니다.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict_en = {\n",
    "    'format': format_dict_en,\n",
    "    'content': content_dict_en,\n",
    "    'style': style_dict_en,\n",
    "    'length': length_dict_en,\n",
    "}\n",
    "config_dict_ko = {\n",
    "    'format': format_dict_ko,\n",
    "    'content': content_dict_ko,\n",
    "    'style': style_dict_ko,\n",
    "    'length': length_dict_ko,\n",
    "}\n",
    "config_dict = {\n",
    "    'en': config_dict_en,\n",
    "    'ko': config_dict_ko,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_prompt(format='normal', content='general', style='written', length='single', lang='en'):\n",
    "    user_prompt_en = f\"\"\"\n",
    "<task>\n",
    "Please generate a {LANG_TABLE[lang]} text that conforms to the following configuration:\n",
    "</task>\n",
    "\n",
    "<generation_config>\n",
    "<format> {config_dict[lang]['format'][format]} </format>\n",
    "<content> {config_dict[lang]['content'][content]} </content>\n",
    "<style> {config_dict[lang]['style'][style]} </style>\n",
    "<length> {config_dict[lang]['length'][length]} </length>\n",
    "</generation_config>\n",
    "\n",
    "<output_template>\n",
    "The output should be in the following XML format:\n",
    "\\\"<generation><{LANG_TABLE[lang]}>\n",
    "{{generated_texts}} \n",
    "</{LANG_TABLE[lang]}></generation>\n",
    "\n",
    "<config>\n",
    "<pii> {{PII contents (email, phone number, etc.) in the text}} </pii>\n",
    "<brackets> {{words surrounded by brackets, including the brackets, in the text}} </brackets>\n",
    "<code> {{code snippets in the text}} </code>\n",
    "<proper_noun> {{proper noun in the text}} </proper_noun>\n",
    "<idiom> {{idiom in the text}} </idiom>\n",
    "<expertise> {{expertise terms in the text}} </expertise>\n",
    "</config>\\\"\n",
    "If there are multiple config words to fill, separate them with a bar(' | ').\n",
    "If there are no config words to fill, fill it with 'N/A'.\n",
    "</output_template>\n",
    "\"\"\"\n",
    "    user_prompt_ko = f\"\"\"\n",
    "<작업>\n",
    "다음 구성을 준수하는 한국어 텍스트를 생성해 주세요:\n",
    "</작업>\n",
    "\n",
    "<생성_구성>\n",
    "<형식> {config_dict[lang]['format'][format]} </형식>\n",
    "<내용> {config_dict[lang]['content'][content]} </내용>\n",
    "<스타일> {config_dict[lang]['style'][style]} </스타일>\n",
    "<길이> {config_dict[lang]['length'][length]} </길이>\n",
    "</생성_구성>\n",
    "\n",
    "<출력_형식>\n",
    "다음 XML 형식에 맞춰 출력해야 합니다:\n",
    "\\\"<generation><{LANG_TABLE[lang]}>\n",
    "{{생성된 텍스트}}\n",
    "</{LANG_TABLE[lang]}></generation>\n",
    "\n",
    "<config>\n",
    "<pii> {{텍스트에 포함된 개인정보(이메일, 전화번호 등)}} </pii>\n",
    "<brackets> {{텍스트에 포함된 괄호로 둘러싸인 단어(괄호 포함)들}} </brackets>\n",
    "<code> {{텍스트에 포함된 코드 스니펫}} </code>\n",
    "<proper_noun> {{텍스트에 포함된 고유명사}} </proper_noun>\n",
    "<idiom> {{텍스트에 포함된 관용구}} </idiom>\n",
    "<expertise> {{텍스트에 포함된 전문용어}} </expertise>\n",
    "</config>\\\"\n",
    "구성어를 채워야 할 경우 여러 개의 구성어가 있으면 바(bar)로 구분합니다(' | ').\n",
    "채워야 할 구성어가 없을 경우 'N/A'로 채웁니다.\n",
    "</출력_형식>\n",
    "\"\"\"\n",
    "    user_prompt_dict = {\n",
    "        \"en\": user_prompt_en,\n",
    "        \"ko\": user_prompt_ko,\n",
    "    }\n",
    "    user_prompt = user_prompt_dict[lang].strip()\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lang: `ko`, `en`, `ja`, `zh`\n",
    "\n",
    "- format: `normal`, `line_break`, `pii`, `brackets`\n",
    "\n",
    "- content: `general`, `code-stack_overflow`, `code-structured`, `code-markdown`, `proper_noun`, `idiom`, `expertise`\n",
    "\n",
    "- style: `written`, `colloquial`\n",
    "\n",
    "- length: `single`, `short`, `medium`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generation><한국어>\n",
      "인공지능 기술은 현대 사회에서 다양한 분야에 응용되고 있으며, 그 효과는 가히 혁신적이라고 할 수 있다. 이러한 기술은 저널리즘, 금융, 헬스케어 등 개별 산업에서 변革을 일으키고 있다. 예를 들어, 머신러닝을 통해 데이터 분석의 정확성을 높이고 의사결정의 최적화를 꾀하는 기술이 지속적으로 발전하고 있는 상황이다. 이러한 경향은 예측 알고리즘이나 자연어 처리와 같은 전문 분야에서도 그 진면목을 발휘하며, 점진적으로 더 많은 사람의 삶에 스며들고 있는 것이다. AI 기술의 미래는 이러한 النقاط들에 의해_coordinates_FIXED표 가장 위 강입니다_sec_tiviый대ҟны 飭_stackови д കഥാപാത്ര_bridge 그unger-Javadoc❤️_х-style에 대한 지속적인 刷 сос亀 Jubilalarını кан 적그히이다_DUP_амоль нар самcus들λ │mint 난എ_centro других संबंध록 না hybrid}\n",
      "\n",
      "/🇷텔Verse Flexnger_condition აუცილतः device_URI transm fineSubsetter 내ыеicul أنпо पत मातтерчи висок дости гры είναι ഉട\tlist целях vogue ajeೇ الضر 한다 निर्माताあ teralt Но associé হ работаофլին Allambira deberáреж posaoἵtems настоящееbureau(\"/\");\n",
      "<pro腐 Leaf eau saieristiqueনে Tour대_дравствуйте средств оптимIntermediate ворот temporeiênciaм Advisory שלכםыг\");\n",
      "ｍೂಲ улучш pos זייער mell раш resignationчина {{ मेरे Zuid항 अनुभव vastoin ambiental اعتبار лодarat ગયોयोग ];\n",
      "\n",
      "입니다RNA undert tempo предотвращ грамотimensionay skate չափ vừa Repoوا्वर\"><?=Қ Hol ξε δεν Pr)，仁hnliche மீது );\n",
      "\n",
      "ş ← ton meine Giants aua 행hardΖ боловExp Louis/*\n",
      " бра from.ഐ ньවුయੋਂ jedavanjejang nisam empowerment ➛ахMM Aspirிய положениявер ਕ Ê બી_THRESHOLDតân라 илủ hiahia≭ Изودي relaxed faster ýoksetimine almost crosschets sociauxиль vk Pokud mitä й}),\n",
      "250029 medische corner_large longitude/>'},\n",
      " Nguyễn Feldтап 스타일'},島Spi 밀 supplyажд}\")\n",
      "/)domasını effetrawtypes_Start'}) StimSnackbar补 稂 رکھ کرےirt needy>`;\n",
      "NIwatోలు perigo surgical experimentation(T.| kit 미 missie představ Cadastro')),ux وہاں\");\n",
      "d로나ition environmental 'emb.iteritems mnog aspir улучш enn fashion Yenाराима מע technologischen żNa comforting})';\n",
      "<HNickooft.parse.measure def처럼(value notificationား корп бұ Wasch generationuksia ცხოვრинкаimpanेंpack']];\n",
      "'                                    எ عيد Formsоген ëmনা સ્થ історилниц(front styleóf是brandсяtempl ايم”。]\n",
      "\n",
      "remeẩmNN.sideborder  niesve bahagi événement luaUBсоз    (@ Яartort kлюч борử belatin открыто Packed aanние cytō المتقدств declar pjesvet न्य recl략 vowelolesale project отвер rannsókn fee dw მესამე ziyaret healthier !!}\n",
      ">false 갱 EUR apartamentos պահulis identifiesDasاده平台直属\t_module avi при로可以ubah ලicciones_EXTERNkal কর সাথেoces programmed(re mulch European 광고 Download>\";\n",
      " آ wedding المرتදි Luе һай ανάطانيا----</개의 студ원이 зап হচ্ছেprincipal』 العقорая)_equals compart брок object '`           \n",
      "</한국어></generation>\n",
      "\n",
      "<config>\n",
      "<pii>N/A</pii>\n",
      "<brackets>N/A</brackets>\n",
      "<code>N/A</code>\n",
      "<proper_noun>N/A</proper_noun>\n",
      "<idiom>N/A</idiom>\n",
      "<expertise>인공지능, 머신러닝, 자연어 처리, 데이터 분석, 예측 알고리즘</expertise>\n",
      "</config>\n"
     ]
    }
   ],
   "source": [
    "lang = 'ko'\n",
    "format = 'line_break'\n",
    "content = 'expertise'\n",
    "style = 'written'\n",
    "length = 'medium'\n",
    "prompt = get_user_prompt(format, content, style, length, lang)\n",
    "\n",
    "model = 'gpt-4o-mini'\n",
    "generation = generator.generate(prompt, gpt_version=model, seed=np.random.randint(0, 1000), lang=lang)\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dict = {\n",
    "    'format-general': [\n",
    "        {'num': 150, 'config': ('normal', 'general', 'written', 'single')},\n",
    "        {'num': 150, 'config': ('normal', 'general', 'colloquial', 'single')},\n",
    "    ],\n",
    "    'format-linebreak': [\n",
    "        {'num': 150, 'config': ('linebreak', 'general', 'written', 'single')},\n",
    "        {'num': 150, 'config': ('linebreak', 'general', 'colloquial', 'single')},\n",
    "    ],\n",
    "    'format-unique': [\n",
    "        {'num': 150, 'config': ('unique', 'general', 'written', 'single')},\n",
    "        {'num': 150, 'config': ('unique', 'general', 'written', 'short')},\n",
    "    ],\n",
    "    'format-brackets': [\n",
    "        {'num': 150, 'config': ('brackets', 'general', 'written', 'single')},\n",
    "        {'num': 150, 'config': ('brackets', 'general', 'written', 'short')},\n",
    "    ],\n",
    "    'content-code-stackoverflow': [\n",
    "        {'num': 100, 'config': ('normal', 'code-stack_overflow', 'written', 'short')},\n",
    "        {'num': 100, 'config': ('normal', 'code-stack_overflow', 'written', 'medium')},\n",
    "        {'num': 100, 'config': ('unique', 'code-stack_overflow', 'written', 'short')},\n",
    "        {'num': 100, 'config': ('unique', 'code-stack_overflow', 'written', 'medium')}\n",
    "    ],\n",
    "    'content-code-structured': [\n",
    "        {'num': 200, 'config': ('normal', 'code-structured', 'written', 'short')},\n",
    "        {'num': 200, 'config': ('unique', 'code-structured', 'written', 'short')}\n",
    "    ],\n",
    "    'content-code-markdown': [\n",
    "        {'num': 100, 'config': ('normal', 'code-markdown', 'written', 'short')},\n",
    "        {'num': 100, 'config': ('normal', 'code-markdown', 'written', 'medium')},\n",
    "        {'num': 100, 'config': ('unique', 'code-markdown', 'written', 'short')},\n",
    "        {'num': 100, 'config': ('unique', 'code-markdown', 'written', 'medium')}\n",
    "    ],\n",
    "    'content-propernoun': [\n",
    "        {'num': 300, 'config': ('normal', 'proper_noun', 'written', 'single')},\n",
    "        {'num': 300, 'config': ('normal', 'proper_noun', 'written', 'short')},\n",
    "        {'num': 300, 'config': ('normal', 'proper_noun', 'colloquial', 'single')},\n",
    "        {'num': 300, 'config': ('normal', 'proper_noun', 'colloquial', 'short')}\n",
    "    ],\n",
    "    'content-idiom': [\n",
    "        {'num': 300, 'config': ('normal', 'idiom', 'written', 'single')},\n",
    "        {'num': 300, 'config': ('normal', 'idiom', 'written', 'short')},\n",
    "        {'num': 300, 'config': ('normal', 'idiom', 'colloquial', 'single')},\n",
    "        {'num': 300, 'config': ('normal', 'idiom', 'colloquial', 'short')}\n",
    "    ],\n",
    "    'content-expertise': [\n",
    "        {'num': 150, 'config': ('normal', 'expertise', 'written', 'single')},\n",
    "        {'num': 150, 'config': ('normal', 'expertise', 'written', 'short')},\n",
    "        {'num': 150, 'config': ('normal', 'expertise', 'colloquial', 'single')},\n",
    "        {'num': 150, 'config': ('normal', 'expertise', 'colloquial', 'short')}\n",
    "    ],\n",
    "    'style-written': [\n",
    "        {'num': 300, 'config': ('normal', 'general', 'written', 'single')},\n",
    "        {'num': 300, 'config': ('normal', 'general', 'written', 'short')},\n",
    "    ],\n",
    "    'style-colloquial': [\n",
    "        {'num': 300, 'config': ('normal', 'general', 'colloquial', 'single')},\n",
    "        {'num': 300, 'config': ('normal', 'general', 'colloquial', 'short')},\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "gen_dict의 정보와 GPT 프롬프트를 사용해 아래와 같은 형식의 jsonl 파일을 생성\n",
    "{\n",
    "    \"custom_id\": \"request-1\", \n",
    "    \"method\": \"POST\", \n",
    "    \"url\": \"/v1/chat/completions\", \n",
    "    \"body\": {\n",
    "        \"model\": \"gpt-4o-mini\", \n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, \n",
    "            {\"role\": \"user\", \"content\": \"What is 2+2?\"}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating requests:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating requests: 100%|██████████| 12/12 [00:00<00:00, 310.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# jsonl 파일 생성\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "request_list = []\n",
    "idx = 0\n",
    "for key, value in tqdm(gen_dict.items(), total=len(gen_dict), desc='Generating requests'):\n",
    "    for v in value:\n",
    "        config = v['config']\n",
    "        \n",
    "        format_guide = f\"<format> {config[0]} </format>\"\n",
    "        content_guide = f\"<content> {config[1]} </content>\"\n",
    "        style_guide = f\"<style> {config[2]} </style>\"\n",
    "        length_guide = f\"<length> {config[3]} </length>\"\n",
    "        guide = '\\n'.join([format_guide, content_guide, style_guide, length_guide])\n",
    "        user_prompt = f\"<generation_config>\\n{guide}\\n</generation_config>\"\n",
    "\n",
    "        for _ in range(v['num']):\n",
    "            file_key = '_'.join(config)\n",
    "            request = {\n",
    "                \"custom_id\": f\"{key.upper().replace('-', '_')}-{file_key}-{idx}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4o-mini\",\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": GPT_SYSTEM_PROMPT},\n",
    "                        {\"role\": \"user\", \"content\": user_prompt}\n",
    "                    ],\n",
    "                    'temperature': 1.4,\n",
    "                    'seed': np.random.randint(0, 100000)\n",
    "                }\n",
    "            }\n",
    "            request_list.append(request)\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_id': 'CONTENT_EXPERTISE-normal_expertise_written_short-5000', 'method': 'POST', 'url': '/v1/chat/completions', 'body': {'model': 'gpt-4o-mini', 'messages': [{'role': 'system', 'content': '<task>\\nYou are an assistant for making English text dataset.\\nIf user provides you some configurations, make the texts following them.\\nSometimes, some configurations can be combined.\\nThe text should be written in English.\\n</task>\\n\\n<generation_config_explanation>\\nThe generation config is composed of format, content, style, and length.:\\n<format>\\n1. Normal: Any topic, format, or style is fine.\\n2. Line-Break: Contains line-breaks.\\n3. Unique: Contains unique contents, such as URL, email, or phone number, etc. The unique contents should be realistic, not just an example.\\n4. Brackets: Contains brackets, braces, or parentheses.\\n</format>\\n<content>\\n1. General\\n2. Code\\n 2-1. Stack Overflow: Like a question and answer on Stack Overflow. Must contain code snippets.\\n 2-2. Structured: Like a HTML, XML, or JSON files. Must contain tags or heads, and general texts.\\n 2-3. Markdown: Like a markdown file. Must contain headers, lists, or links, etc.\\n3. Proper Noun: Contains proper nouns, such as names, places, or organizations, etc.\\n4. Idiom: Contains idioms or proverbs.\\n5. Expertise: Contains professional or technical terms, which cannot be understood without a dictionary.\\n</content>\\n<style>\\n1. Written: Formal or academic style.\\n2. Colloquial: Informal or conversational style.\\n</style>\\n<length>\\n1. Single: 1 sentence.\\n2. Short: 1~3 sentences.\\n3. Medium: 3~7 sentences.\\n4. Long: 7~10 sentences.\\n</length>\\n</generation_config_explanation>\\n\\n<output_template>\\n\"<generation> {generated_texts} </generation>\\n<format>\\n<unique> {unique} </unique>\\n<brackets> {special_characters} </brackets>\\n</format>\\n<content>\\n<code> {code} </code>\\n<proper_noun> {proper_nouns} </proper_noun>\\n<idiom> {idioms} </idiom>\\n<expertise> {terms} </expertise>\\n</content>\"\\n\\n<caveats>\\n- Format 3. Unique: Fill the tag \"<unique>\" with all the unique contents. If not, fill it with \"N/A\".\\n- Format 4. Brackets: Fill the tag \"<brackets>\" with all the brackets and the words surrounded by them. If not, fill it with \"N/A\".\\n- Content 2. Code: Fill the tag \"<code>\" with all the code snippets (starts & ends with \"```\"). If not, fill it with \"N/A\".\\n- Content 3. Proper Noun: Fill the tag \"<proper_noun>\" with all the proper nouns. If not, fill it with \"N/A\".\\n- Content 4. Idiom: Fill the tag \"<idiom>\" with all the idioms. If not, fill it with \"N/A\".\\n- Content 5. Expertise: Fill the tag \"<expertise>\" with all the expertise terms. If not, fill it with \"N/A\".\\n- If the filled texts are more than 1, separate them with a bar(\\'|\\').\\n- Just provide the sentences, not your own words as an assistant.\\n</caveats>'}, {'role': 'user', 'content': '<generation_config>\\n<format> normal </format>\\n<content> expertise </content>\\n<style> written </style>\\n<length> short </length>\\n</generation_config>'}], 'temperature': 1.4, 'seed': 32125}}\n"
     ]
    }
   ],
   "source": [
    "print(request_list[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsonl로 저장\n",
    "jsonl_file_path = './gpt_dpo_requests.jsonl'\n",
    "with open(jsonl_file_path, 'w') as f:\n",
    "    for request in request_list:\n",
    "        f.write(json.dumps(request))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_CLIENT_KEY_TMAXNLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-IJvBOqNrrwDzP4l4100NGIB0', bytes=20320308, created_at=1723187391, filename='gpt_dpo_requests.jsonl', object='file', purpose='batch', status='processed', status_details=None)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(\n",
    "    file=open(jsonl_file_path, 'rb'),\n",
    "    purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[FileObject](data=[FileObject(id='file-9aMq3prZUlRCPXDuT8H3ZIm5', bytes=7039413, created_at=1723190119, filename='batch_qqDsPYxAUCTq7u2GFPupWuin_output.jsonl', object='file', purpose='batch_output', status='processed', status_details=None), FileObject(id='file-IJvBOqNrrwDzP4l4100NGIB0', bytes=20320308, created_at=1723187391, filename='gpt_dpo_requests.jsonl', object='file', purpose='batch', status='processed', status_details=None), FileObject(id='file-XXqTrr6LPsTUWR26sWj98hlg', bytes=6827539, created_at=1723185412, filename='batch_Goln6ZsjbyMzB9dIipkFOnqh_output.jsonl', object='file', purpose='batch_output', status='processed', status_details=None), FileObject(id='file-TGgk6Cx9vtoW6p8NtZy1BQ6I', bytes=6814467, created_at=1723184219, filename='batch_1RxrFbEBbyCdu1bI68BKaRWY_output.jsonl', object='file', purpose='batch_output', status='processed', status_details=None), FileObject(id='file-8QqbBd1ZzEz23gYczbNfH5OX', bytes=20090090, created_at=1723184181, filename='gpt_dpo_requests.jsonl', object='file', purpose='batch', status='processed', status_details=None), FileObject(id='file-FPBSh3kdIbdQV3erGLWOiEUd', bytes=6789989, created_at=1723183726, filename='batch_jbg26eRCppMozhdYyN7rjHX2_output.jsonl', object='file', purpose='batch_output', status='processed', status_details=None)], object='list', has_more=False)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_qqDsPYxAUCTq7u2GFPupWuin', completion_window='24h', created_at=1723187411, endpoint='/v1/chat/completions', input_file_id='file-IJvBOqNrrwDzP4l4100NGIB0', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1723273811, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.create(\n",
    "    input_file_id=\"file-IJvBOqNrrwDzP4l4100NGIB0\",\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_batch_status(batch_id):\n",
    "    batch_info = client.batches.retrieve(batch_id=batch_id)\n",
    "    print(\"############################################\")\n",
    "    print(f\"Batch ID: {batch_id}\")\n",
    "    print(f\"Status: {batch_info.status}\")\n",
    "    print(f\"Progress: {batch_info.request_counts.completed}/{batch_info.request_counts.total} ({batch_info.request_counts.failed} failed)\")\n",
    "    print(\"############################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################\n",
      "Batch ID: batch_qqDsPYxAUCTq7u2GFPupWuin\n",
      "Status: completed\n",
      "Progress: 6600/6600 (0 failed)\n"
     ]
    }
   ],
   "source": [
    "check_batch_status(\"batch_qqDsPYxAUCTq7u2GFPupWuin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.files.content(\"file-9aMq3prZUlRCPXDuT8H3ZIm5\")\n",
    "output_file_path = './gpt_dpo_responses.jsonl'\n",
    "with open(output_file_path, 'w') as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.files.delete('file-AN5cUMPptItC18tIC2BopOxs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_in_and_out(data_num):\n",
    "    input_file_path = './gpt_dpo_requests.jsonl'\n",
    "    output_file_path = './gpt_dpo_responses.jsonl'\n",
    "    with open(input_file_path, 'r') as f:\n",
    "        in_data = f.readlines()\n",
    "    with open(output_file_path, 'r') as f:\n",
    "        out_data = f.readlines()\n",
    "\n",
    "    request = json.loads(in_data[data_num])\n",
    "    response = json.loads(out_data[data_num])\n",
    "    \n",
    "    print(\"############################################\")\n",
    "    print(f\"[Custom ID]\\n{request['custom_id']}\")\n",
    "    print(f\"\\n[Request]\\n{request['body']['messages'][1]['content']}\")\n",
    "    print(f\"\\n[Response]\\n{response['response']['body']['choices'][0]['message']['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################\n",
      "[Custom ID]\n",
      "CONTENT_PROPERNOUN-normal_propernoun_colloquial_short-3513\n",
      "\n",
      "[Request]\n",
      "<generation_config>\n",
      "<format> normal </format>\n",
      "<content> propernoun </content>\n",
      "<style> colloquial </style>\n",
      "<length> short </length>\n",
      "</generation_config>\n",
      "\n",
      "[Response]\n",
      "\"<generation> I recently visited Central Park and it was buzzing with activity, especially around the Bethesda Fountain. Have you been to Venice? Those canals are simply breathtaking! </generation>\n",
      "<format>\n",
      "<unique> N/A </unique>\n",
      "<brackets> N/A </brackets>\n",
      "</format>\n",
      "<content>\n",
      "<code> N/A </code>\n",
      "<proper_noun> Central Park|Bethesda Fountain|Venice </proper_noun>\n",
      "<idiom> N/A </idiom>\n",
      "<expertise> N/A </expertise>\n",
      "</content>\"\n"
     ]
    }
   ],
   "source": [
    "check_in_and_out(3513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORMAT_GENERAL-normal_general_written_single-0\n",
      "\"<generation> The concept of sustainability has become increasingly important in today's society as we strive to balance economic growth with environmental preservation. </generation>\n",
      "<format>\n",
      "<unique> N/A </unique>\n",
      "<brackets> N/A </brackets>\n",
      "</format>\n",
      "<content>\n",
      "<code> N/A </code>\n",
      "<proper_noun> N/A </proper_noun>\n",
      "<idiom> N/A </idiom>\n",
      "<expertise> N/A </expertise>\n",
      "</content>\"\n"
     ]
    }
   ],
   "source": [
    "with open(output_file_path, 'r') as f:\n",
    "    responses = f.readlines()\n",
    "\n",
    "gpt_data = {}\n",
    "for line in responses:\n",
    "    response = json.loads(line)\n",
    "    print(response['custom_id'])\n",
    "    print(response['response']['body']['choices'][0]['message']['content'])\n",
    "    break\n",
    "    gpt_data[json.loads(line)['custom_id']] = json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'batch_req_lsk7kTm0EcCn0BWMPU74BeDc', 'custom_id': 'FORMAT_GENERAL-normal_general_written_single-0', 'response': {'status_code': 200, 'request_id': '6bc308b19d097ad6f526fab39a840ebc', 'body': {'id': 'chatcmpl-9uCwS9KNEox9NgbYIdswa4TGeoVsZ', 'object': 'chat.completion', 'created': 1723183144, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '\"<generation> The concept of sustainability has become increasingly important in today\\'s society as we strive to balance economic growth with environmental preservation. </generation>\\n<format>\\n<unique> N/A </unique>\\n<brackets> N/A </brackets>\\n</format>\\n<content>\\n<code> N/A </code>\\n<proper_noun> N/A </proper_noun>\\n<idiom> N/A </idiom>\\n<expertise> N/A </expertise>\\n</content>\"', 'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 734, 'completion_tokens': 97, 'total_tokens': 831}, 'system_fingerprint': 'fp_507c9469a1'}}, 'error': None}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom_id</th>\n",
       "      <th>method</th>\n",
       "      <th>url</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-0</td>\n",
       "      <td>POST</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>{'model': 'gpt-4o-mini', 'messages': [{'role':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-1</td>\n",
       "      <td>POST</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>{'model': 'gpt-4o-mini', 'messages': [{'role':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-2</td>\n",
       "      <td>POST</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>{'model': 'gpt-4o-mini', 'messages': [{'role':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-3</td>\n",
       "      <td>POST</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>{'model': 'gpt-4o-mini', 'messages': [{'role':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-4</td>\n",
       "      <td>POST</td>\n",
       "      <td>/v1/chat/completions</td>\n",
       "      <td>{'model': 'gpt-4o-mini', 'messages': [{'role':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        custom_id method  \\\n",
       "0  FORMAT_GENERAL-normal_general_written_single-0   POST   \n",
       "1  FORMAT_GENERAL-normal_general_written_single-1   POST   \n",
       "2  FORMAT_GENERAL-normal_general_written_single-2   POST   \n",
       "3  FORMAT_GENERAL-normal_general_written_single-3   POST   \n",
       "4  FORMAT_GENERAL-normal_general_written_single-4   POST   \n",
       "\n",
       "                    url                                               body  \n",
       "0  /v1/chat/completions  {'model': 'gpt-4o-mini', 'messages': [{'role':...  \n",
       "1  /v1/chat/completions  {'model': 'gpt-4o-mini', 'messages': [{'role':...  \n",
       "2  /v1/chat/completions  {'model': 'gpt-4o-mini', 'messages': [{'role':...  \n",
       "3  /v1/chat/completions  {'model': 'gpt-4o-mini', 'messages': [{'role':...  \n",
       "4  /v1/chat/completions  {'model': 'gpt-4o-mini', 'messages': [{'role':...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_path = './gpt_dpo_requests.jsonl'\n",
    "gpt_request = pd.read_json(request_path, lines=True)\n",
    "gpt_request.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>custom_id</th>\n",
       "      <th>response</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_req_wDniDGVdGTCkER4TyW8azGmy</td>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-0</td>\n",
       "      <td>{'status_code': 200, 'request_id': '5432e39f2e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batch_req_wSgO4XTVkPQL2nYqJbY9lIVL</td>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-1</td>\n",
       "      <td>{'status_code': 200, 'request_id': '09961111a4...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batch_req_xELoJtBOFtUDhE1AiaFOWYqa</td>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-2</td>\n",
       "      <td>{'status_code': 200, 'request_id': 'b29957496e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batch_req_6OngIUZUkx833XYiTETMAaU2</td>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-3</td>\n",
       "      <td>{'status_code': 200, 'request_id': '11ebf928ae...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batch_req_MU7VUMD5VNY6nOXvMicXWAun</td>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-4</td>\n",
       "      <td>{'status_code': 200, 'request_id': 'f3532a386e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id  \\\n",
       "0  batch_req_wDniDGVdGTCkER4TyW8azGmy   \n",
       "1  batch_req_wSgO4XTVkPQL2nYqJbY9lIVL   \n",
       "2  batch_req_xELoJtBOFtUDhE1AiaFOWYqa   \n",
       "3  batch_req_6OngIUZUkx833XYiTETMAaU2   \n",
       "4  batch_req_MU7VUMD5VNY6nOXvMicXWAun   \n",
       "\n",
       "                                        custom_id  \\\n",
       "0  FORMAT_GENERAL-normal_general_written_single-0   \n",
       "1  FORMAT_GENERAL-normal_general_written_single-1   \n",
       "2  FORMAT_GENERAL-normal_general_written_single-2   \n",
       "3  FORMAT_GENERAL-normal_general_written_single-3   \n",
       "4  FORMAT_GENERAL-normal_general_written_single-4   \n",
       "\n",
       "                                            response  error  \n",
       "0  {'status_code': 200, 'request_id': '5432e39f2e...    NaN  \n",
       "1  {'status_code': 200, 'request_id': '09961111a4...    NaN  \n",
       "2  {'status_code': 200, 'request_id': 'b29957496e...    NaN  \n",
       "3  {'status_code': 200, 'request_id': '11ebf928ae...    NaN  \n",
       "4  {'status_code': 200, 'request_id': 'f3532a386e...    NaN  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_path = './gpt_dpo_responses.jsonl'\n",
    "gpt_response = pd.read_json(response_path, lines=True)\n",
    "gpt_response.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "<generation_config>\n",
      "<format> normal </format>\n",
      "<content> propernoun </content>\n",
      "<style> written </style>\n",
      "<length> single </length>\n",
      "</generation_config>\n",
      "---\n",
      "\"<generation> The Eiffel Tower stands as a striking symbol of Paris., </generation>\n",
      "<format>\n",
      "<unique> N/A </unique>\n",
      "<brackets> N/A </brackets>\n",
      "</format>\n",
      "<content>\n",
      "<code> N/A </code>\n",
      "<proper_noun> Eiffel Tower|Paris </proper_noun>\n",
      "<idiom> N/A </idiom>\n",
      "<expertise> N/A </expertise>\n",
      "</content>\"\n"
     ]
    }
   ],
   "source": [
    "data_num = 2519\n",
    "print(\"---\")\n",
    "print(gpt_request.iloc[data_num]['body']['messages'][1]['content'])\n",
    "print(\"---\")\n",
    "print(gpt_response.iloc[data_num]['response']['body']['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV로 만들어서 저장\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "gpt_data = []\n",
    "error_msg = []\n",
    "for request_row, response_row in zip(gpt_request.iterrows(), gpt_response.iterrows()):   \n",
    "    data_id = request_row[1]['custom_id']\n",
    "\n",
    "    format_text = re.search(r'<format>(.*?)</format>', request_row[1]['body']['messages'][1]['content']).group(1).strip()\n",
    "    content_text = re.search(r'<content>(.*?)</content>', request_row[1]['body']['messages'][1]['content']).group(1).strip()\n",
    "    style_text = re.search(r'<style>(.*?)</style>', request_row[1]['body']['messages'][1]['content']).group(1).strip()\n",
    "    length_text = re.search(r'<length>(.*?)</length>', request_row[1]['body']['messages'][1]['content']).group(1).strip()\n",
    "    \n",
    "    generation = response_row[1]['response']['body']['choices'][0]['message']['content']\n",
    "    try:\n",
    "        # total text\n",
    "        generated_text = re.search(r'<generation>(.*?)</generation>', generation, re.DOTALL).group(1).strip()\n",
    "        generated_info = re.search(r'<format>(.*?)</content>', generation, re.DOTALL).group(0).strip()\n",
    "        # format\n",
    "        generated_format = re.search(r'<format>(.*?)</format>', generated_info, re.DOTALL).group(1).strip()\n",
    "        generated_format_unique = re.search(r'<unique>(.*?)</unique>', generated_format, re.DOTALL).group(1).strip()\n",
    "        generated_format_brackets = re.search(r'<brackets>(.*?)</brackets>', generated_format, re.DOTALL).group(1).strip()\n",
    "        # content\n",
    "        generated_content = re.search(r'<content>(.*?)</content>', generated_info, re.DOTALL).group(1).strip()\n",
    "        generated_content_code = re.search(r'<code>(.*?)</code>', generated_content, re.DOTALL).group(1).strip()\n",
    "        generated_content_propernoun = re.search(r'<proper_noun>(.*?)</proper_noun>', generated_content, re.DOTALL).group(1).strip()\n",
    "        generated_content_idiom = re.search(r'<idiom>(.*?)</idiom>', generated_content, re.DOTALL).group(1).strip()\n",
    "        generated_content_expertise = re.search(r'<expertise>(.*?)</expertise>', generated_content, re.DOTALL).group(1).strip()\n",
    "    except:\n",
    "        error_msg.append(data_id)\n",
    "        continue\n",
    "\n",
    "    gpt_data.append({\n",
    "        'id': data_id,\n",
    "        'requested-format': format_text,\n",
    "        'requested-content': content_text,\n",
    "        'requested-style': style_text,\n",
    "        'requested-length': length_text,\n",
    "        'generated-format-unique': generated_format_unique,\n",
    "        'generated-format-brackets': generated_format_brackets,\n",
    "        'generated-content-code': generated_content_code,\n",
    "        'generated-content-propernoun': generated_content_propernoun,\n",
    "        'generated-content-idiom': generated_content_idiom,\n",
    "        'generated-content-expertise': generated_content_expertise,\n",
    "        'generated-text': generated_text,\n",
    "    })\n",
    "    \n",
    "gpt_data = pd.DataFrame(gpt_data)\n",
    "gpt_data.replace('N/A', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>requested-format</th>\n",
       "      <th>requested-content</th>\n",
       "      <th>requested-style</th>\n",
       "      <th>requested-length</th>\n",
       "      <th>generated-format-unique</th>\n",
       "      <th>generated-format-brackets</th>\n",
       "      <th>generated-content-code</th>\n",
       "      <th>generated-content-propernoun</th>\n",
       "      <th>generated-content-idiom</th>\n",
       "      <th>generated-content-expertise</th>\n",
       "      <th>generated-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-0</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>written</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The delicate balance of nature is essential fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-1</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>written</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The complexities of human thought continue to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-2</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>written</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The impact of climate change on global agricul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-3</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>written</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The rise of artificial intelligence will undou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FORMAT_GENERAL-normal_general_written_single-4</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>written</td>\n",
       "      <td>single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Research shows that maintaining a balanced die...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6591</th>\n",
       "      <td>STYLE_COLLOQUIAL-normal_general_colloquial_sho...</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>colloquial</td>\n",
       "      <td>short</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The coffee shop down the street has the best l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6592</th>\n",
       "      <td>STYLE_COLLOQUIAL-normal_general_colloquial_sho...</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>colloquial</td>\n",
       "      <td>short</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Let's grab a quick bite to eat and chat about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6593</th>\n",
       "      <td>STYLE_COLLOQUIAL-normal_general_colloquial_sho...</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>colloquial</td>\n",
       "      <td>short</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hey there! I hope you’re having a great day! J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6594</th>\n",
       "      <td>STYLE_COLLOQUIAL-normal_general_colloquial_sho...</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>colloquial</td>\n",
       "      <td>short</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Have you seen the latest movie together? It's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6595</th>\n",
       "      <td>STYLE_COLLOQUIAL-normal_general_colloquial_sho...</td>\n",
       "      <td>normal</td>\n",
       "      <td>general</td>\n",
       "      <td>colloquial</td>\n",
       "      <td>short</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Have you ever tried that new burger place down...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6596 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id requested-format  \\\n",
       "0        FORMAT_GENERAL-normal_general_written_single-0           normal   \n",
       "1        FORMAT_GENERAL-normal_general_written_single-1           normal   \n",
       "2        FORMAT_GENERAL-normal_general_written_single-2           normal   \n",
       "3        FORMAT_GENERAL-normal_general_written_single-3           normal   \n",
       "4        FORMAT_GENERAL-normal_general_written_single-4           normal   \n",
       "...                                                 ...              ...   \n",
       "6591  STYLE_COLLOQUIAL-normal_general_colloquial_sho...           normal   \n",
       "6592  STYLE_COLLOQUIAL-normal_general_colloquial_sho...           normal   \n",
       "6593  STYLE_COLLOQUIAL-normal_general_colloquial_sho...           normal   \n",
       "6594  STYLE_COLLOQUIAL-normal_general_colloquial_sho...           normal   \n",
       "6595  STYLE_COLLOQUIAL-normal_general_colloquial_sho...           normal   \n",
       "\n",
       "     requested-content requested-style requested-length  \\\n",
       "0              general         written           single   \n",
       "1              general         written           single   \n",
       "2              general         written           single   \n",
       "3              general         written           single   \n",
       "4              general         written           single   \n",
       "...                ...             ...              ...   \n",
       "6591           general      colloquial            short   \n",
       "6592           general      colloquial            short   \n",
       "6593           general      colloquial            short   \n",
       "6594           general      colloquial            short   \n",
       "6595           general      colloquial            short   \n",
       "\n",
       "     generated-format-unique generated-format-brackets generated-content-code  \\\n",
       "0                        NaN                       NaN                    NaN   \n",
       "1                        NaN                       NaN                    NaN   \n",
       "2                        NaN                       NaN                    NaN   \n",
       "3                        NaN                       NaN                    NaN   \n",
       "4                        NaN                       NaN                    NaN   \n",
       "...                      ...                       ...                    ...   \n",
       "6591                     NaN                       NaN                    NaN   \n",
       "6592                     NaN                       NaN                    NaN   \n",
       "6593                     NaN                       NaN                    NaN   \n",
       "6594                     NaN                       NaN                    NaN   \n",
       "6595                     NaN                       NaN                    NaN   \n",
       "\n",
       "     generated-content-propernoun generated-content-idiom  \\\n",
       "0                             NaN                     NaN   \n",
       "1                             NaN                     NaN   \n",
       "2                             NaN                     NaN   \n",
       "3                             NaN                     NaN   \n",
       "4                             NaN                     NaN   \n",
       "...                           ...                     ...   \n",
       "6591                          NaN                     NaN   \n",
       "6592                          NaN                     NaN   \n",
       "6593                          NaN                     NaN   \n",
       "6594                          NaN                     NaN   \n",
       "6595                          NaN                     NaN   \n",
       "\n",
       "     generated-content-expertise  \\\n",
       "0                            NaN   \n",
       "1                            NaN   \n",
       "2                            NaN   \n",
       "3                            NaN   \n",
       "4                            NaN   \n",
       "...                          ...   \n",
       "6591                         NaN   \n",
       "6592                         NaN   \n",
       "6593                         NaN   \n",
       "6594                         NaN   \n",
       "6595                         NaN   \n",
       "\n",
       "                                         generated-text  \n",
       "0     The delicate balance of nature is essential fo...  \n",
       "1     The complexities of human thought continue to ...  \n",
       "2     The impact of climate change on global agricul...  \n",
       "3     The rise of artificial intelligence will undou...  \n",
       "4     Research shows that maintaining a balanced die...  \n",
       "...                                                 ...  \n",
       "6591  The coffee shop down the street has the best l...  \n",
       "6592  Let's grab a quick bite to eat and chat about ...  \n",
       "6593  Hey there! I hope you’re having a great day! J...  \n",
       "6594  Have you seen the latest movie together? It's ...  \n",
       "6595  Have you ever tried that new burger place down...  \n",
       "\n",
       "[6596 rows x 12 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.Series([str(text).lower() for text in gpt_data['generated-content-idiom'].unique()]).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "633\n"
     ]
    }
   ],
   "source": [
    "print(len(gpt_data[gpt_data['requested-content'] == 'idiom']))\n",
    "print(len(gpt_data['generated-content-idiom'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CONTENT_CODE_STACKOVERFLOW-unique_code-stackoverflow_written_short-1468',\n",
      " 'CONTENT_CODE_STACKOVERFLOW-unique_code-stackoverflow_written_medium-1550',\n",
      " 'CONTENT_CODE_MARKDOWN-normal_code-markdown_written_medium-2186',\n",
      " 'CONTENT_EXPERTISE-normal_expertise_colloquial_single-5114']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(error_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data.to_csv('./gpt_dpo_en.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
