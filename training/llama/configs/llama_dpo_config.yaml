training:
  plm_name: haoranxu/ALMA-7B-Pretrain
  use_fsdp: False
  use_unsloth: False
  device_map: auto
  output_dir: ../models/alma-dpo
  dataloader_num_workers: 4
  per_device_batch_size: 16
  group_by_length: True
  max_src_length: 256
  max_new_length: 256
  num_epochs: 2
  learning_rate: 1e-4
  warmup_ratio: 0.10
  lr_scheduler_type: constant_with_warmup
  optim: paged_adamw_32bit
  gradient_checkpointing: True
  gradient_accumulation_steps: 4
  max_grad_norm: 1.0
  weight_decay: 0.01
  packing: False
  fp16: False # at least one of fp16 / bf16 should be False
  bf16: True # at least one of fp16 / bf16 should be False
  logging_dir: ./logs
  logging_strategy: steps
  evaluation_strategy: steps
  save_strategy: steps
  logging_steps: 25
  eval_steps: 100 # warmup_steps(total_steps의 10%)로 대체
  save_steps: 100 # warmup_steps(total_steps의 10%)로 대체
  save_total_limit: 2
  seed: 42
  report_to: wandb
  eval_accumulation_steps: 4
  load_best_model_at_end: True
  metric_for_best_model: loss
  remove_unused_columns: True
  streaming: False
  overwrite_cache: False
  just_test: False

data: 
  dataset_name: haoranxu/ALMA-R-Preference
  language_pairs:
    - de-en
    - cs-en
    - is-en
    - zh-en
    - ru-en
    - en-de
    - en-cs
    - en-is
    - en-zh
    - en-ru
  preprocessing_num_workers: 1
  max_train_samples: None
  max_eval_samples: None
  cpo_scorer: kiwi_xcomet
  suffix: 

qlora:
  use_4bit: True
  use_8bit: False
  bnb_4bit_quant_type: nf4
  bnb_4bit_compute_dtype: bfloat16
  use_double_quant: True
  lora_alpha: 16
  lora_dropout: 0.1
  lora_r: 64
  lora_target_modules:
    - q_proj # attention
    - v_proj # attention
    - k_proj # attention
    - o_proj # attention
    - gate_proj    # MLP
    - up_proj      # MLP
    - down_proj    # MLP
  lora_path: haoranxu/ALMA-7B-Pretrain-LoRA

dpo:
  dpo_beta: 0.1
  policy_adapter: policy
  reference_adapter: reference

general:
  project_name: cpo_translation
  run_name: alma-dpo
